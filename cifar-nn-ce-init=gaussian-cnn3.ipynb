{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "DATASET = 'cifar10'\n",
    "class_num   = 10\n",
    "test_size   = None\n",
    "train_size  = 45000\n",
    "image_shape = None\n",
    "\n",
    "if DATASET =='mnist':\n",
    "    image_shape = (28, 28, 1)\n",
    "elif DATASET == 'cifar10':\n",
    "    image_shape = (32, 32, 3)\n",
    "\n",
    "#training\n",
    "batch_size = 256\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    }
   ],
   "source": [
    "x_train_all, y_train_all, x_test_all, y_test_all = tuple(onp.array(x) for x in get_dataset(DATASET, None, None, \n",
    "                                                                                  do_flatten_and_normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "seed = 0\n",
    "x_train_all, y_train_all = shaffle(x_train_all, y_train_all, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sample\n",
    "x_train = x_train_all[:train_size]\n",
    "y_train = y_train_all[:train_size]\n",
    "\n",
    "x_valid = x_train_all[train_size:]\n",
    "y_valid = y_train_all[train_size:]\n",
    "\n",
    "x_test = x_test_all[:test_size]\n",
    "y_test = y_test_all[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test = x_train.reshape((-1, *image_shape)), x_valid.reshape((-1, *image_shape)), x_test.reshape((-1, *image_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will not automatically renormalize input data since input and output dtypes are both floating point formats.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will not automatically renormalize input data since input and output dtypes are both floating point formats.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will not automatically renormalize input data since input and output dtypes are both floating point formats.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will not automatically renormalize input data since input and output dtypes are both floating point formats.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.map(\n",
    "    lambda image, label: (tf.image.random_flip_left_right(image), label)\n",
    ").map(\n",
    "    lambda image, label: (tf.image.resize_with_crop_or_pad(image, image_shape[0]+6, image_shape[1]+6), label)\n",
    ").map(\n",
    "    lambda image, label: (tf.image.random_crop(image, (image_shape[0], image_shape[1], image_shape[2])), label)\n",
    ").map(\n",
    "    lambda image, label: (tf.image.random_contrast(image, lower=0.2, upper=1.0), label)\n",
    ").shuffle(\n",
    "    100000\n",
    ").batch(\n",
    "    batch_size\n",
    ").prefetch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = layers.Input(shape=image_shape)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', \n",
    "                  kernel_initializer=tf.keras.initializers.GlorotNormal())(img_input)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "                 kernel_initializer=tf.keras.initializers.GlorotNormal())(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "                 kernel_initializer=tf.keras.initializers.GlorotNormal())(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal())(x)\n",
    "out = layers.Dense(10, kernel_initializer=tf.keras.initializers.GlorotNormal())(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=img_input, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return 1e-3\n",
    "    elif epoch < 90:\n",
    "        return 1e-2\n",
    "    elif epoch < 150:\n",
    "        return 1e-3\n",
    "    else:\n",
    "        return 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(momentum=0.9),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "176/176 [==============================] - 31s 175ms/step - loss: 2.1439 - accuracy: 0.2074 - val_loss: 1.9726 - val_accuracy: 0.3020\n",
      "Epoch 2/200\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 1.9715 - accuracy: 0.2893 - val_loss: 1.8535 - val_accuracy: 0.3436\n",
      "Epoch 3/200\n",
      "176/176 [==============================] - 26s 145ms/step - loss: 1.8897 - accuracy: 0.3283 - val_loss: 1.7868 - val_accuracy: 0.3734\n",
      "Epoch 4/200\n",
      "176/176 [==============================] - 20s 116ms/step - loss: 1.8374 - accuracy: 0.3470 - val_loss: 1.7390 - val_accuracy: 0.3916\n",
      "Epoch 5/200\n",
      "176/176 [==============================] - 20s 116ms/step - loss: 1.8009 - accuracy: 0.3617 - val_loss: 1.7089 - val_accuracy: 0.3938\n",
      "Epoch 6/200\n",
      "176/176 [==============================] - 20s 116ms/step - loss: 1.7754 - accuracy: 0.3709 - val_loss: 1.7194 - val_accuracy: 0.3956\n",
      "Epoch 7/200\n",
      "176/176 [==============================] - 20s 116ms/step - loss: 1.7564 - accuracy: 0.3784 - val_loss: 1.6538 - val_accuracy: 0.4160\n",
      "Epoch 8/200\n",
      "176/176 [==============================] - 20s 116ms/step - loss: 1.7291 - accuracy: 0.3882 - val_loss: 1.7097 - val_accuracy: 0.4126\n",
      "Epoch 9/200\n",
      "176/176 [==============================] - 19s 109ms/step - loss: 1.7053 - accuracy: 0.3983 - val_loss: 1.6502 - val_accuracy: 0.4276\n",
      "Epoch 10/200\n",
      "176/176 [==============================] - 19s 109ms/step - loss: 1.6803 - accuracy: 0.4026 - val_loss: 1.6335 - val_accuracy: 0.4392\n",
      "Epoch 11/200\n",
      "176/176 [==============================] - 19s 109ms/step - loss: 1.7420 - accuracy: 0.3768 - val_loss: 1.5768 - val_accuracy: 0.4528\n",
      "Epoch 12/200\n",
      "176/176 [==============================] - 19s 109ms/step - loss: 1.5930 - accuracy: 0.4267 - val_loss: 1.6208 - val_accuracy: 0.4438\n",
      "Epoch 13/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 1.5023 - accuracy: 0.4582 - val_loss: 1.4792 - val_accuracy: 0.4942\n",
      "Epoch 14/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 1.4203 - accuracy: 0.4923 - val_loss: 1.3904 - val_accuracy: 0.5244\n",
      "Epoch 15/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 1.3467 - accuracy: 0.5165 - val_loss: 1.3714 - val_accuracy: 0.5288\n",
      "Epoch 16/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 1.2921 - accuracy: 0.5373 - val_loss: 1.2841 - val_accuracy: 0.5522\n",
      "Epoch 17/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 1.2521 - accuracy: 0.5521 - val_loss: 1.2787 - val_accuracy: 0.5628\n",
      "Epoch 18/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 1.1950 - accuracy: 0.5729 - val_loss: 1.1827 - val_accuracy: 0.5850\n",
      "Epoch 19/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 1.1381 - accuracy: 0.5984 - val_loss: 1.1362 - val_accuracy: 0.6120\n",
      "Epoch 20/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 1.0873 - accuracy: 0.6153 - val_loss: 1.0838 - val_accuracy: 0.6232\n",
      "Epoch 21/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 1.0284 - accuracy: 0.6385 - val_loss: 1.0639 - val_accuracy: 0.6468\n",
      "Epoch 22/200\n",
      "176/176 [==============================] - 19s 109ms/step - loss: 0.9935 - accuracy: 0.6502 - val_loss: 1.0127 - val_accuracy: 0.6576\n",
      "Epoch 23/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.9549 - accuracy: 0.6641 - val_loss: 0.9993 - val_accuracy: 0.6720\n",
      "Epoch 24/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.9244 - accuracy: 0.6755 - val_loss: 0.9627 - val_accuracy: 0.6800\n",
      "Epoch 25/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.8922 - accuracy: 0.6867 - val_loss: 0.9529 - val_accuracy: 0.6894\n",
      "Epoch 26/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.8615 - accuracy: 0.6957 - val_loss: 0.8953 - val_accuracy: 0.7068\n",
      "Epoch 27/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.8356 - accuracy: 0.7066 - val_loss: 0.9203 - val_accuracy: 0.6988\n",
      "Epoch 28/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.8143 - accuracy: 0.7125 - val_loss: 0.9711 - val_accuracy: 0.6886\n",
      "Epoch 29/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.7934 - accuracy: 0.7224 - val_loss: 0.8925 - val_accuracy: 0.7128\n",
      "Epoch 30/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.7663 - accuracy: 0.7327 - val_loss: 0.9100 - val_accuracy: 0.7084\n",
      "Epoch 31/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.7510 - accuracy: 0.7380 - val_loss: 0.8866 - val_accuracy: 0.7232\n",
      "Epoch 32/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.7286 - accuracy: 0.7455 - val_loss: 0.8518 - val_accuracy: 0.7264\n",
      "Epoch 33/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.7075 - accuracy: 0.7531 - val_loss: 0.7820 - val_accuracy: 0.7386\n",
      "Epoch 34/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.6883 - accuracy: 0.7598 - val_loss: 0.9013 - val_accuracy: 0.7162\n",
      "Epoch 35/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.6735 - accuracy: 0.7632 - val_loss: 0.8059 - val_accuracy: 0.7410\n",
      "Epoch 36/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.6529 - accuracy: 0.7705 - val_loss: 0.7889 - val_accuracy: 0.7414\n",
      "Epoch 37/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.6354 - accuracy: 0.7768 - val_loss: 0.7887 - val_accuracy: 0.7382\n",
      "Epoch 38/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.6204 - accuracy: 0.7838 - val_loss: 0.8157 - val_accuracy: 0.7376\n",
      "Epoch 39/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.6095 - accuracy: 0.7862 - val_loss: 0.7758 - val_accuracy: 0.7526\n",
      "Epoch 40/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.5891 - accuracy: 0.7943 - val_loss: 0.7917 - val_accuracy: 0.7514\n",
      "Epoch 41/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.5792 - accuracy: 0.7989 - val_loss: 0.8159 - val_accuracy: 0.7506\n",
      "Epoch 42/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.5625 - accuracy: 0.8013 - val_loss: 0.8079 - val_accuracy: 0.7542\n",
      "Epoch 43/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.5481 - accuracy: 0.8080 - val_loss: 0.7818 - val_accuracy: 0.7618\n",
      "Epoch 44/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.5321 - accuracy: 0.8168 - val_loss: 0.7434 - val_accuracy: 0.7664\n",
      "Epoch 45/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.5253 - accuracy: 0.8153 - val_loss: 0.7234 - val_accuracy: 0.7672\n",
      "Epoch 46/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.5135 - accuracy: 0.8199 - val_loss: 0.7366 - val_accuracy: 0.7710\n",
      "Epoch 47/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.4989 - accuracy: 0.8271 - val_loss: 0.7452 - val_accuracy: 0.7702\n",
      "Epoch 48/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.4914 - accuracy: 0.8299 - val_loss: 0.7632 - val_accuracy: 0.7652\n",
      "Epoch 49/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.4810 - accuracy: 0.8321 - val_loss: 0.7551 - val_accuracy: 0.7690\n",
      "Epoch 50/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.4677 - accuracy: 0.8366 - val_loss: 0.7540 - val_accuracy: 0.7708\n",
      "Epoch 51/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.4495 - accuracy: 0.8450 - val_loss: 0.7911 - val_accuracy: 0.7680\n",
      "Epoch 52/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.4441 - accuracy: 0.8462 - val_loss: 0.7293 - val_accuracy: 0.7714\n",
      "Epoch 53/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.4302 - accuracy: 0.8502 - val_loss: 0.7378 - val_accuracy: 0.7826\n",
      "Epoch 54/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.4202 - accuracy: 0.8539 - val_loss: 0.7745 - val_accuracy: 0.7746\n",
      "Epoch 55/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.4052 - accuracy: 0.8602 - val_loss: 0.8069 - val_accuracy: 0.7718\n",
      "Epoch 56/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.3943 - accuracy: 0.8634 - val_loss: 0.7998 - val_accuracy: 0.7718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.3874 - accuracy: 0.8638 - val_loss: 0.7565 - val_accuracy: 0.7870\n",
      "Epoch 58/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.3766 - accuracy: 0.8691 - val_loss: 0.8002 - val_accuracy: 0.7796\n",
      "Epoch 59/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.3737 - accuracy: 0.8717 - val_loss: 0.8018 - val_accuracy: 0.7766\n",
      "Epoch 60/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.3623 - accuracy: 0.8736 - val_loss: 0.8181 - val_accuracy: 0.7808\n",
      "Epoch 61/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.3582 - accuracy: 0.8744 - val_loss: 0.8450 - val_accuracy: 0.7764\n",
      "Epoch 62/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.3469 - accuracy: 0.8795 - val_loss: 0.8240 - val_accuracy: 0.7814\n",
      "Epoch 63/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.3315 - accuracy: 0.8849 - val_loss: 0.8423 - val_accuracy: 0.7778\n",
      "Epoch 64/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.3296 - accuracy: 0.8842 - val_loss: 0.7935 - val_accuracy: 0.7950\n",
      "Epoch 65/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.3208 - accuracy: 0.8896 - val_loss: 0.8293 - val_accuracy: 0.7856\n",
      "Epoch 66/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.3145 - accuracy: 0.8918 - val_loss: 0.8245 - val_accuracy: 0.7948\n",
      "Epoch 67/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.3088 - accuracy: 0.8933 - val_loss: 0.8153 - val_accuracy: 0.7926\n",
      "Epoch 68/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2939 - accuracy: 0.8974 - val_loss: 0.8435 - val_accuracy: 0.7868\n",
      "Epoch 69/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2895 - accuracy: 0.8994 - val_loss: 0.8154 - val_accuracy: 0.7906\n",
      "Epoch 70/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2778 - accuracy: 0.9044 - val_loss: 0.8694 - val_accuracy: 0.7780\n",
      "Epoch 71/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2717 - accuracy: 0.9048 - val_loss: 0.8793 - val_accuracy: 0.7870\n",
      "Epoch 72/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2756 - accuracy: 0.9041 - val_loss: 0.8221 - val_accuracy: 0.7906\n",
      "Epoch 73/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.2599 - accuracy: 0.9106 - val_loss: 0.8503 - val_accuracy: 0.7918\n",
      "Epoch 74/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2498 - accuracy: 0.9128 - val_loss: 0.9158 - val_accuracy: 0.7870\n",
      "Epoch 75/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2436 - accuracy: 0.9163 - val_loss: 0.8508 - val_accuracy: 0.7918\n",
      "Epoch 76/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2409 - accuracy: 0.9185 - val_loss: 0.8933 - val_accuracy: 0.7916\n",
      "Epoch 77/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2348 - accuracy: 0.9191 - val_loss: 0.9064 - val_accuracy: 0.7914\n",
      "Epoch 78/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2249 - accuracy: 0.9229 - val_loss: 0.8893 - val_accuracy: 0.7986\n",
      "Epoch 79/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.2250 - accuracy: 0.9219 - val_loss: 0.9174 - val_accuracy: 0.7950\n",
      "Epoch 80/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2178 - accuracy: 0.9261 - val_loss: 0.8963 - val_accuracy: 0.7900\n",
      "Epoch 81/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2174 - accuracy: 0.9249 - val_loss: 0.8897 - val_accuracy: 0.7934\n",
      "Epoch 82/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2086 - accuracy: 0.9275 - val_loss: 0.9269 - val_accuracy: 0.7938\n",
      "Epoch 83/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2083 - accuracy: 0.9270 - val_loss: 0.9255 - val_accuracy: 0.7894\n",
      "Epoch 84/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.2005 - accuracy: 0.9300 - val_loss: 0.9562 - val_accuracy: 0.7864\n",
      "Epoch 85/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.1960 - accuracy: 0.9328 - val_loss: 0.9169 - val_accuracy: 0.7976\n",
      "Epoch 86/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.1885 - accuracy: 0.9341 - val_loss: 0.9764 - val_accuracy: 0.7932\n",
      "Epoch 87/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.1842 - accuracy: 0.9364 - val_loss: 0.9848 - val_accuracy: 0.7858\n",
      "Epoch 88/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.1831 - accuracy: 0.9383 - val_loss: 0.9866 - val_accuracy: 0.7926\n",
      "Epoch 89/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.1725 - accuracy: 0.9416 - val_loss: 0.9912 - val_accuracy: 0.8060\n",
      "Epoch 90/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.1708 - accuracy: 0.9418 - val_loss: 1.0039 - val_accuracy: 0.7954\n",
      "Epoch 91/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.1461 - accuracy: 0.9506 - val_loss: 0.9772 - val_accuracy: 0.7982\n",
      "Epoch 92/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.1178 - accuracy: 0.9616 - val_loss: 0.9833 - val_accuracy: 0.7996\n",
      "Epoch 93/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.1138 - accuracy: 0.9626 - val_loss: 0.9920 - val_accuracy: 0.8012\n",
      "Epoch 94/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.1099 - accuracy: 0.9638 - val_loss: 0.9868 - val_accuracy: 0.8038\n",
      "Epoch 95/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.1063 - accuracy: 0.9658 - val_loss: 0.9936 - val_accuracy: 0.8014\n",
      "Epoch 96/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.1017 - accuracy: 0.9666 - val_loss: 1.0042 - val_accuracy: 0.8044\n",
      "Epoch 97/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0980 - accuracy: 0.9679 - val_loss: 1.0042 - val_accuracy: 0.8048\n",
      "Epoch 98/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0968 - accuracy: 0.9674 - val_loss: 1.0181 - val_accuracy: 0.8036\n",
      "Epoch 99/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0959 - accuracy: 0.9683 - val_loss: 1.0237 - val_accuracy: 0.8032\n",
      "Epoch 100/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0980 - accuracy: 0.9688 - val_loss: 1.0199 - val_accuracy: 0.8034\n",
      "Epoch 101/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0922 - accuracy: 0.9698 - val_loss: 1.0196 - val_accuracy: 0.8040\n",
      "Epoch 102/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0920 - accuracy: 0.9708 - val_loss: 1.0389 - val_accuracy: 0.8022\n",
      "Epoch 103/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0890 - accuracy: 0.9711 - val_loss: 1.0366 - val_accuracy: 0.8042\n",
      "Epoch 104/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0853 - accuracy: 0.9723 - val_loss: 1.0391 - val_accuracy: 0.8056\n",
      "Epoch 105/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0856 - accuracy: 0.9718 - val_loss: 1.0498 - val_accuracy: 0.8048\n",
      "Epoch 106/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0863 - accuracy: 0.9724 - val_loss: 1.0400 - val_accuracy: 0.8062\n",
      "Epoch 107/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0837 - accuracy: 0.9726 - val_loss: 1.0462 - val_accuracy: 0.8074\n",
      "Epoch 108/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0839 - accuracy: 0.9727 - val_loss: 1.0614 - val_accuracy: 0.8034\n",
      "Epoch 109/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0826 - accuracy: 0.9731 - val_loss: 1.0612 - val_accuracy: 0.8014\n",
      "Epoch 110/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0793 - accuracy: 0.9739 - val_loss: 1.0655 - val_accuracy: 0.8038\n",
      "Epoch 111/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0814 - accuracy: 0.9736 - val_loss: 1.0626 - val_accuracy: 0.8034\n",
      "Epoch 112/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0777 - accuracy: 0.9750 - val_loss: 1.0774 - val_accuracy: 0.8042\n",
      "Epoch 113/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0757 - accuracy: 0.9761 - val_loss: 1.0689 - val_accuracy: 0.8046\n",
      "Epoch 114/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0768 - accuracy: 0.9755 - val_loss: 1.0962 - val_accuracy: 0.8042\n",
      "Epoch 115/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0759 - accuracy: 0.9755 - val_loss: 1.0855 - val_accuracy: 0.8032\n",
      "Epoch 116/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0750 - accuracy: 0.9757 - val_loss: 1.0820 - val_accuracy: 0.8064\n",
      "Epoch 117/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0763 - accuracy: 0.9759 - val_loss: 1.0880 - val_accuracy: 0.8086\n",
      "Epoch 118/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0727 - accuracy: 0.9769 - val_loss: 1.0842 - val_accuracy: 0.8058\n",
      "Epoch 119/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0736 - accuracy: 0.9772 - val_loss: 1.0845 - val_accuracy: 0.8080\n",
      "Epoch 120/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0740 - accuracy: 0.9768 - val_loss: 1.1056 - val_accuracy: 0.8054\n",
      "Epoch 121/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0706 - accuracy: 0.9774 - val_loss: 1.1019 - val_accuracy: 0.8050\n",
      "Epoch 122/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0710 - accuracy: 0.9769 - val_loss: 1.1097 - val_accuracy: 0.8056\n",
      "Epoch 123/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0662 - accuracy: 0.9789 - val_loss: 1.1159 - val_accuracy: 0.8084\n",
      "Epoch 124/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0679 - accuracy: 0.9790 - val_loss: 1.1096 - val_accuracy: 0.8072\n",
      "Epoch 125/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0691 - accuracy: 0.9778 - val_loss: 1.1086 - val_accuracy: 0.8072\n",
      "Epoch 126/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0657 - accuracy: 0.9790 - val_loss: 1.1057 - val_accuracy: 0.8118\n",
      "Epoch 127/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0654 - accuracy: 0.9788 - val_loss: 1.1061 - val_accuracy: 0.8054\n",
      "Epoch 128/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0651 - accuracy: 0.9799 - val_loss: 1.1225 - val_accuracy: 0.8056\n",
      "Epoch 129/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0657 - accuracy: 0.9793 - val_loss: 1.1280 - val_accuracy: 0.8054\n",
      "Epoch 130/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0641 - accuracy: 0.9803 - val_loss: 1.1198 - val_accuracy: 0.8076\n",
      "Epoch 131/200\n",
      "176/176 [==============================] - 19s 109ms/step - loss: 0.0677 - accuracy: 0.9779 - val_loss: 1.1222 - val_accuracy: 0.8054\n",
      "Epoch 132/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0635 - accuracy: 0.9804 - val_loss: 1.1162 - val_accuracy: 0.8094\n",
      "Epoch 133/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0632 - accuracy: 0.9802 - val_loss: 1.1405 - val_accuracy: 0.8050\n",
      "Epoch 134/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0597 - accuracy: 0.9814 - val_loss: 1.1439 - val_accuracy: 0.8060\n",
      "Epoch 135/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0608 - accuracy: 0.9804 - val_loss: 1.1478 - val_accuracy: 0.8064\n",
      "Epoch 136/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0579 - accuracy: 0.9816 - val_loss: 1.1377 - val_accuracy: 0.8090\n",
      "Epoch 137/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0594 - accuracy: 0.9815 - val_loss: 1.1436 - val_accuracy: 0.8064\n",
      "Epoch 138/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0571 - accuracy: 0.9821 - val_loss: 1.1502 - val_accuracy: 0.8066\n",
      "Epoch 139/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0573 - accuracy: 0.9822 - val_loss: 1.1471 - val_accuracy: 0.8084\n",
      "Epoch 140/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0579 - accuracy: 0.9822 - val_loss: 1.1487 - val_accuracy: 0.8092\n",
      "Epoch 141/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0601 - accuracy: 0.9809 - val_loss: 1.1543 - val_accuracy: 0.8106\n",
      "Epoch 142/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0538 - accuracy: 0.9836 - val_loss: 1.1823 - val_accuracy: 0.8062\n",
      "Epoch 143/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0546 - accuracy: 0.9828 - val_loss: 1.1772 - val_accuracy: 0.8076\n",
      "Epoch 144/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0532 - accuracy: 0.9832 - val_loss: 1.1667 - val_accuracy: 0.8118\n",
      "Epoch 145/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0547 - accuracy: 0.9832 - val_loss: 1.1816 - val_accuracy: 0.8074\n",
      "Epoch 146/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0539 - accuracy: 0.9830 - val_loss: 1.1723 - val_accuracy: 0.8088\n",
      "Epoch 147/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0548 - accuracy: 0.9834 - val_loss: 1.1690 - val_accuracy: 0.8082\n",
      "Epoch 148/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0513 - accuracy: 0.9845 - val_loss: 1.1716 - val_accuracy: 0.8132\n",
      "Epoch 149/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0522 - accuracy: 0.9835 - val_loss: 1.1866 - val_accuracy: 0.8096\n",
      "Epoch 150/200\n",
      "176/176 [==============================] - 19s 109ms/step - loss: 0.0506 - accuracy: 0.9840 - val_loss: 1.1908 - val_accuracy: 0.8094\n",
      "Epoch 151/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0504 - accuracy: 0.9838 - val_loss: 1.1857 - val_accuracy: 0.8106\n",
      "Epoch 152/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0486 - accuracy: 0.9849 - val_loss: 1.1915 - val_accuracy: 0.8092\n",
      "Epoch 153/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0495 - accuracy: 0.9852 - val_loss: 1.1917 - val_accuracy: 0.8094\n",
      "Epoch 154/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0489 - accuracy: 0.9849 - val_loss: 1.1909 - val_accuracy: 0.8102\n",
      "Epoch 155/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0505 - accuracy: 0.9842 - val_loss: 1.1912 - val_accuracy: 0.8088\n",
      "Epoch 156/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0480 - accuracy: 0.9850 - val_loss: 1.1913 - val_accuracy: 0.8098\n",
      "Epoch 157/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0485 - accuracy: 0.9850 - val_loss: 1.1927 - val_accuracy: 0.8096\n",
      "Epoch 158/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0470 - accuracy: 0.9861 - val_loss: 1.1909 - val_accuracy: 0.8094\n",
      "Epoch 159/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0479 - accuracy: 0.9860 - val_loss: 1.1938 - val_accuracy: 0.8106\n",
      "Epoch 160/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0484 - accuracy: 0.9857 - val_loss: 1.1955 - val_accuracy: 0.8094\n",
      "Epoch 161/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0519 - accuracy: 0.9838 - val_loss: 1.1939 - val_accuracy: 0.8082\n",
      "Epoch 162/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0487 - accuracy: 0.9851 - val_loss: 1.1949 - val_accuracy: 0.8100\n",
      "Epoch 163/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0483 - accuracy: 0.9855 - val_loss: 1.1973 - val_accuracy: 0.8084\n",
      "Epoch 164/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0471 - accuracy: 0.9861 - val_loss: 1.1954 - val_accuracy: 0.8088\n",
      "Epoch 165/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0484 - accuracy: 0.9851 - val_loss: 1.1946 - val_accuracy: 0.8102\n",
      "Epoch 166/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 1.1989 - val_accuracy: 0.8092\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0471 - accuracy: 0.9854 - val_loss: 1.1945 - val_accuracy: 0.8096\n",
      "Epoch 168/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0478 - accuracy: 0.9847 - val_loss: 1.1953 - val_accuracy: 0.8100\n",
      "Epoch 169/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0485 - accuracy: 0.9855 - val_loss: 1.1947 - val_accuracy: 0.8098\n",
      "Epoch 170/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0498 - accuracy: 0.9853 - val_loss: 1.1968 - val_accuracy: 0.8098\n",
      "Epoch 171/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 1.1950 - val_accuracy: 0.8110\n",
      "Epoch 172/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0468 - accuracy: 0.9857 - val_loss: 1.1980 - val_accuracy: 0.8102\n",
      "Epoch 173/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0466 - accuracy: 0.9857 - val_loss: 1.1951 - val_accuracy: 0.8102\n",
      "Epoch 174/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0459 - accuracy: 0.9871 - val_loss: 1.1982 - val_accuracy: 0.8104\n",
      "Epoch 175/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0476 - accuracy: 0.9857 - val_loss: 1.2030 - val_accuracy: 0.8100\n",
      "Epoch 176/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0456 - accuracy: 0.9863 - val_loss: 1.2045 - val_accuracy: 0.8096\n",
      "Epoch 177/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0471 - accuracy: 0.9862 - val_loss: 1.2029 - val_accuracy: 0.8100\n",
      "Epoch 178/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0470 - accuracy: 0.9861 - val_loss: 1.2033 - val_accuracy: 0.8098\n",
      "Epoch 179/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0459 - accuracy: 0.9858 - val_loss: 1.2050 - val_accuracy: 0.8088\n",
      "Epoch 180/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0485 - accuracy: 0.9854 - val_loss: 1.2036 - val_accuracy: 0.8114\n",
      "Epoch 181/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0460 - accuracy: 0.9861 - val_loss: 1.2020 - val_accuracy: 0.8096\n",
      "Epoch 182/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0452 - accuracy: 0.9861 - val_loss: 1.2068 - val_accuracy: 0.8102\n",
      "Epoch 183/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0466 - accuracy: 0.9861 - val_loss: 1.2063 - val_accuracy: 0.8108\n",
      "Epoch 184/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0468 - accuracy: 0.9860 - val_loss: 1.2053 - val_accuracy: 0.8114\n",
      "Epoch 185/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0474 - accuracy: 0.9855 - val_loss: 1.2038 - val_accuracy: 0.8110\n",
      "Epoch 186/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0464 - accuracy: 0.9861 - val_loss: 1.2064 - val_accuracy: 0.8108\n",
      "Epoch 187/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0445 - accuracy: 0.9866 - val_loss: 1.2093 - val_accuracy: 0.8108\n",
      "Epoch 188/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0478 - accuracy: 0.9856 - val_loss: 1.2081 - val_accuracy: 0.8106\n",
      "Epoch 189/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0445 - accuracy: 0.9870 - val_loss: 1.2067 - val_accuracy: 0.8114\n",
      "Epoch 190/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0485 - accuracy: 0.9851 - val_loss: 1.2076 - val_accuracy: 0.8106\n",
      "Epoch 191/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0458 - accuracy: 0.9864 - val_loss: 1.2093 - val_accuracy: 0.8092\n",
      "Epoch 192/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0443 - accuracy: 0.9870 - val_loss: 1.2123 - val_accuracy: 0.8092\n",
      "Epoch 193/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0461 - accuracy: 0.9858 - val_loss: 1.2121 - val_accuracy: 0.8104\n",
      "Epoch 194/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0456 - accuracy: 0.9863 - val_loss: 1.2146 - val_accuracy: 0.8092\n",
      "Epoch 195/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0452 - accuracy: 0.9862 - val_loss: 1.2109 - val_accuracy: 0.8106\n",
      "Epoch 196/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0441 - accuracy: 0.9871 - val_loss: 1.2156 - val_accuracy: 0.8106\n",
      "Epoch 197/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0459 - accuracy: 0.9862 - val_loss: 1.2147 - val_accuracy: 0.8106\n",
      "Epoch 198/200\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0467 - accuracy: 0.9862 - val_loss: 1.2105 - val_accuracy: 0.8106\n",
      "Epoch 199/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0447 - accuracy: 0.9867 - val_loss: 1.2155 - val_accuracy: 0.8098\n",
      "Epoch 200/200\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0459 - accuracy: 0.9867 - val_loss: 1.2142 - val_accuracy: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcc104ce898>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_ds, validation_data=valid_ds, epochs=epochs, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model_weights/simple_cnn_train=all_ce.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2271720170974731, 0.8075000643730164]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test_all, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model_weights/simple_cnn_train=all_ce.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========NTK============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7618050575256348, 0.6875]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./npy/cifar-eps-time-any-npy/cifar-fgsm-eps-0.03-time-None.npy')\n",
    "print(\"==========NTK============\")\n",
    "model.evaluate(tmp, y_test[:128], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========CE============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.594173789024353, 0.73583984375]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./npy/cifar-untargeted-cifar-nn-grey-box-train=4096-ce.npy')\n",
    "print(\"==========CE============\")\n",
    "model.evaluate(tmp, y_test[:2048], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========MSE============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.59250009059906, 0.71728515625]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./npy/cifar-untargeted-cifar-nn-grey-box-train=4096-mse.npy')\n",
    "print(\"==========MSE============\")\n",
    "model.evaluate(tmp, y_test[:2048], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3792508840560913, 0.71875]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./npy/cifar-fgsm-eps-0.03-time-None-nngp.npy')\n",
    "model.evaluate(tmp, y_test[:128], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.647125005722046, 0.65478515625]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./batch_NTK_simple.npy')\n",
    "model.evaluate(tmp, y_test[:2048], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========small============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.4256112575531006, 0.58740234375]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./npy/cifar-untargeted-cifar-nn-grey-box-train=all-ce.npy')\n",
    "print(\"==========small============\")\n",
    "model.evaluate(tmp, y_test[:2048], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========small============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.802112340927124, 0.720703125]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./npy/cifar-untargeted-cifar-nn-grey-box-cnn19-train=all-ce.npy')\n",
    "print(\"==========small============\")\n",
    "model.evaluate(tmp, y_test[:2048], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8956958055496216, 0.720703125]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./batch_NTK_cnn_19.npy')\n",
    "model.evaluate(tmp, y_test[:2048], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
