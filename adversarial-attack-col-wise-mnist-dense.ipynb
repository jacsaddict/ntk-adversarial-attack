{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "\n",
    "from jax import lax, random\n",
    "from jax.api import grad, jit, vmap\n",
    "from jax.config import config\n",
    "from jax.experimental import optimizers\n",
    "\n",
    "config.update('jax_enable_x64', True)\n",
    "\n",
    "from functools import partial\n",
    "from jax import random\n",
    "\n",
    "from neural_tangents import stax\n",
    "\n",
    "# Attacking\n",
    "from jax.experimental.stax import logsoftmax\n",
    "from cleverhans.utils import clip_eta, one_hot\n",
    "\n",
    "# Plotting\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from utils import *\n",
    "sns.set_style(style='white')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\"\"\"\n",
    "diag_reg:\n",
    "    a scalar representing the strength of the diagonal regularization for\n",
    "    `k_train_train`, i.e. computing `k_train_train + diag_reg * I` during\n",
    "    Cholesky factorization or eigendecomposition.\n",
    "\"\"\"\n",
    "diag_reg = 1e-4\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all, y_train_all, x_test_all, y_test_all = tuple(onp.array(x) for x in get_dataset('mnist', None, None, \n",
    "                                                                                  do_flatten_and_normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "\n",
    "seed = 0\n",
    "x_train_all, y_train_all = shaffle(x_train_all, y_train_all, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sample\n",
    "\n",
    "train_size = 256\n",
    "x_train = x_train_all[:train_size]\n",
    "y_train = y_train_all[:train_size]\n",
    "\n",
    "test_size = 256\n",
    "x_test = x_test_all[:test_size]\n",
    "y_test = y_test_all[:test_size]\n",
    "\n",
    "shape = (x_train.shape[0], 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to gpu\n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "\n",
    "x_test = np.asarray(x_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(mean, ys):\n",
    "    return np.mean(np.argmax(mean, axis=-1) == np.argmax(ys, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseBlock(neurons, W_std, b_std):\n",
    "    return stax.serial(stax.Dense(neurons, W_std, b_std), \n",
    "                       stax.Erf())\n",
    "\n",
    "def DenseGroup(n, neurons, W_std, b_std):\n",
    "    blocks = []\n",
    "    for _ in range(n):\n",
    "        blocks += [DenseBlock(neurons, W_std, b_std)]\n",
    "    return stax.serial(*blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0.18\n",
    "W = 1.76\n",
    "\n",
    "phase_list = 'Critical'\n",
    "\n",
    "layer = 50\n",
    "num_classes = 10\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "b_std = np.sqrt(b)\n",
    "\n",
    "W_std = np.sqrt(W)\n",
    "\n",
    "init_fn, apply_fn, kernel_fn = stax.serial(DenseGroup(layer, 1024, W_std, b_std))\n",
    "    \n",
    "# Inference with a single infinite width / linearized network\n",
    "kernel_fn = jit(kernel_fn, static_argnums=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(kernel_fn, obj_fn, x_train=None, x_test=None, fx_train_0=0., fx_test_0=0., t=None):\n",
    "    # Kernel\n",
    "    ntk_train_train = kernel_fn(x_train, x_train, 'ntk')\n",
    "    \n",
    "    if obj_fn == 'train':\n",
    "        return ntk_train_train\n",
    "    elif obj_fn == 'test':\n",
    "        ntk_test_train = kernel_fn(x_test, x_train, 'ntk')\n",
    "        # Prediction\n",
    "        predict_fn = nt.predict.gradient_descent_mse(ntk_train_train, y_train, diag_reg=diag_reg) # no convariance\n",
    "        return predict_fn(t, fx_train_0, fx_test_0, ntk_test_train) # fx_train_0, fx_test_0 = (0, 0) for infinite width\n",
    "    else:\n",
    "        raise ValueError(\"Objective function must be either train(ntk_train_train) or test(predict_fn)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv(k):\n",
    "        #inverse with diag_reg\n",
    "        return np.linalg.inv(k + diag_reg * np.eye(k.shape[0]))\n",
    "\n",
    "ntk_train_train = kernel_fn(x_train, x_train, 'ntk')\n",
    "ntk_train_train_inv = inv(ntk_train_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def l2_loss_v1(logits, labels, weighting=1):\n",
    "    \"\"\"\n",
    "    Tensorflow version of L2 loss (without sqrt)\n",
    "    \"\"\"\n",
    "    return np.sum(((logits - labels)**2) * weighting) / 2\n",
    "    \n",
    "@jit\n",
    "def l2_loss_v2(logits, lables):\n",
    "    \"\"\"\n",
    "    Normal L2 loss\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(logits - labels)\n",
    "\n",
    "@jit\n",
    "def cross_entropy_loss(logits, lables):\n",
    "    return -np.sum(logsoftmax(logits) * lables)\n",
    "    \n",
    "@jit\n",
    "def mse_loss(logits, lables):\n",
    "    return 0.5 * np.mean((logits - lables) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loss_adv(x_train, y, kernel_fn, weighting):\n",
    "    # Compute NTK on training data\n",
    "    ntk_train_train = kernel_fn(x_train, x_train, 'ntk')\n",
    "    loss = - l2_loss_v1(ntk_train_train, y, weighting) # y = matrix of 1 / diagnal\n",
    "    return loss\n",
    "\n",
    "train_grads_fn = jit(grad(train_loss_adv), static_argnums=(2,)) # static arg: expanding {if / else} loops for graph mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss_adv_matrix(x_train, x_test, kernel_fn, c, t=None, \n",
    "                         ntk_train_train_inv=ntk_train_train_inv):\n",
    "    # Kernel -> matrix of constant c\n",
    "    assert type(c) == int\n",
    "    \n",
    "    ntk_test_train = kernel_fn(x_test, x_train, 'ntk')\n",
    "    # Θ(test, train)Θ(train, train)^-1\n",
    "    # def inv(k):\n",
    "        #inverse with diag_reg\n",
    "    #    return np.linalg.inv(k + diag_reg * np.eye(k.shape[0]))\n",
    "    \n",
    "    mean_predictor = np.einsum('ij,jk->ik', ntk_test_train, ntk_train_train_inv)\n",
    "    \n",
    "    # Loss\n",
    "    loss = - l2_loss_v1(mean_predictor, np.ones_like(mean_predictor)*c)\n",
    "    return loss\n",
    "\n",
    "test_grads_fn = jit(grad(test_loss_adv_matrix, argnums=1), static_argnums=(0, 2))\n",
    "test_c_grads_fn = jit(grad(test_loss_adv_matrix, argnums=3), static_argnums=(0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss_adv_col(x_train, x_test, kernel_fn, c, t=None,\n",
    "                     ntk_train_train_inv=ntk_train_train_inv):\n",
    "    \"\"\"\n",
    "    Kernel -> matrix with constant cols\n",
    "    \n",
    "    c is a vector of constant. c.shape should be (1, ndim)\n",
    "    \n",
    "    \"\"\" \n",
    "    assert c.shape[0] == 1\n",
    "    assert len(c.shape) == 2\n",
    "    \n",
    "    ntk_train_train = kernel_fn(x_train, x_train, 'ntk')\n",
    "    ntk_test_train = kernel_fn(x_test, x_train, 'ntk')\n",
    "    \n",
    "    # Θ(test, train)Θ(train, train)^-1\n",
    "    #inverse with diag_reg\n",
    "    def inv(k):\n",
    "        return np.linalg.inv(k + diag_reg * np.eye(k.shape[0]))\n",
    "    \n",
    "    mean_predictor = np.einsum('ij,jk->ik', ntk_test_train, inv(ntk_train_train))\n",
    "    \n",
    "    # Loss\n",
    "    loss = - l2_loss_v1(mean_predictor, np.ones_like(mean_predictor)*c)\n",
    "    return loss\n",
    "\n",
    "test_col_wise_grads_fn = jit(grad(test_loss_adv_col, argnums=1), static_argnums=(0, 2))\n",
    "test_col_wise_c_grads_fn = jit(grad(test_loss_adv_col, argnums=3), static_argnums=(0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss_adv_row(x_train, x_test, kernel_fn, c, t=None,\n",
    "                     ntk_train_train_inv=ntk_train_train_inv):\n",
    "    \"\"\"\n",
    "    Kernel -> matrix with constant rows\n",
    "    \n",
    "    c is a vector of constant. c.shape should be (1, ndim)\n",
    "    \n",
    "    \"\"\" \n",
    "    assert c.shape[0] == 1\n",
    "    assert len(c.shape) == 2\n",
    "    \n",
    "    ntk_train_train = kernel_fn(x_train, x_train, 'ntk')\n",
    "    ntk_test_train = kernel_fn(x_test, x_train, 'ntk')\n",
    "    \n",
    "    # Θ(test, train)Θ(train, train)^-1\n",
    "    # inverse with diag_reg\n",
    "    def inv(k):\n",
    "        return np.linalg.inv(k + diag_reg * np.eye(k.shape[0]))\n",
    "    \n",
    "    mean_predictor = np.einsum('ij,jk->ik', ntk_test_train, inv(ntk_train_train))\n",
    "    \n",
    "    # Loss\n",
    "    loss = - l2_loss_v1(mean_predictor, np.ones_like(mean_predictor)*c.T)\n",
    "    return loss\n",
    "\n",
    "test_row_wise_grads_fn = jit(grad(test_loss_adv_row, argnums=1), static_argnums=(0, 2))\n",
    "test_row_wise_c_grads_fn = jit(grad(test_loss_adv_row, argnums=3), static_argnums=(0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pred_loss_adv(x_train, x_test, y_train, y, kernel_fn, loss='mse', t=None, ntk_train_train=ntk_train_train):\n",
    "    \"\"\" update {Kernel_M,N x Kernel_N,N x (dynamic of t)} \"\"\"\n",
    "    \n",
    "    # ntk_train_train = kernel_fn(x_train, x_train, 'ntk')\n",
    "    ntk_test_train = kernel_fn(x_test, x_train, 'ntk')\n",
    "    \n",
    "    # Prediction\n",
    "    predict_fn = nt.predict.gradient_descent_mse(ntk_train_train, y_train, diag_reg=diag_reg) # diag_reg: add to easier inverse\n",
    "    fx = predict_fn(t, 0., 0., ntk_test_train)[1]\n",
    "    \n",
    "    # Loss\n",
    "    if loss == 'cross-entropy':\n",
    "        loss = cross_entropy_loss(fx, y)\n",
    "    elif loss == 'mse':\n",
    "        loss = mse_loss(fx, y)\n",
    "    return loss\n",
    "\n",
    "test_pred_grads_fn = jit(grad(test_pred_loss_adv, argnums=1), static_argnums=(0, 4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_gradient_method(model_fn, kernel_fn, obj_fn, grads_fn, grads_c_fn=None, x_train=None, y_train=None, x_test=None, \n",
    "                         y=None, t=None, c=None, update_c=False, loss='cross-entropy', loss_weighting=None, phase=None, \n",
    "                         fx_train_0=0., fx_test_0=0., eps=0.3, norm=np.inf, clip_min=None, clip_max=None, targeted=False):\n",
    "    \"\"\"\n",
    "    JAX implementation of the Fast Gradient Method.\n",
    "    :param model_fn: a callable that takes an input tensor and returns the model logits.\n",
    "    :param x: input tensor.\n",
    "    :param eps: epsilon (input variation parameter); see https://arxiv.org/abs/1412.6572.\n",
    "    :param norm: Order of the norm (mimics NumPy). Possible values: np.inf or 2.\n",
    "    :param clip_min: (optional) float. Minimum float value for adversarial example components.\n",
    "    :param clip_max: (optional) float. Maximum float value for adversarial example components.\n",
    "    :param y: (optional) Tensor with one-hot true labels. If targeted is true, then provide the\n",
    "            target one-hot label. Otherwise, only provide this parameter if you'd like to use true\n",
    "            labels when crafting adversarial samples. Otherwise, model predictions are used\n",
    "            as labels to avoid the \"label leaking\" effect (explained in this paper:\n",
    "            https://arxiv.org/abs/1611.01236). Default is None. This argument does not have\n",
    "            to be a binary one-hot label (e.g., [0, 1, 0, 0]), it can be floating points values\n",
    "            that sum up to 1 (e.g., [0.05, 0.85, 0.05, 0.05]).\n",
    "    :param targeted: (optional) bool. Is the attack targeted or untargeted?\n",
    "            Untargeted, the default, will try to make the label incorrect.\n",
    "            Targeted will instead try to move in the direction of being more like y.\n",
    "    :return: a tensor for the adversarial example\n",
    "    \"\"\"\n",
    "    if norm not in [np.inf, 2]:\n",
    "        raise ValueError(\"Norm order must be either np.inf or 2.\")\n",
    "        \n",
    "    x = x_test\n",
    "    # Obtain y\n",
    "    if obj_fn == 'test':\n",
    "        if y is None:\n",
    "            # Using model predictions as ground truth to avoid label leaking\n",
    "            x_labels = np.argmax(model_fn(kernel_fn, 'test', x_train, x_test, fx_train_0, fx_test_0)[1], 1)\n",
    "            y = one_hot(x_labels, 10)\n",
    "            \n",
    "    elif obj_fn == 'train':\n",
    "        if y is None:\n",
    "            # Compute NTK on training data\n",
    "            ntk_train_train = model_fn(kernel_fn=kernel_fn, obj_fn='train', x_train=x_train)\n",
    "            \n",
    "            # Construct diagonal\n",
    "            if phase == 'ordered':\n",
    "                y = np.ones(ntk_train_train.shape)*100\n",
    "            elif phase == 'chaotic':\n",
    "                y = np.eye(ntk_train_train.shape[0])*100\n",
    "            else:\n",
    "                raise ValueError(\"Phase must be either 'ordered' or 'critical'\")\n",
    "    \n",
    "    # Obtain gradient\n",
    "    # Obj - Θ(train, train)\n",
    "    if obj_fn == 'train':\n",
    "        grads = grads_fn(x_train, y, kernel_fn, loss_weighting)\n",
    "        \n",
    "    # Obj - Θ(test, train)Θ(train, train)^-1\n",
    "    elif obj_fn == 'test_col':\n",
    "        grads = 0\n",
    "        grads_c = 0\n",
    "        for i in range(int(len(x_test)/batch_size)):\n",
    "            grads += grads_fn(x_train[batch_size*i:batch_size*(i+1)], x_test, kernel_fn, c, t)\n",
    "            if update_c is True:\n",
    "                grads_c += grads_c_fn(x_train[batch_size*i:batch_size*(i+1)], x_test, kernel_fn, \n",
    "                                      c[batch_size*i:batch_size*(i+1)], t)\n",
    "                \n",
    "        grads_c = 3e-6 * np.sign(grads_c) # grads_c = 5e-2 * np.sign(grads_c)\n",
    "        \n",
    "        \n",
    "    # Obj - Θ(test, train)Θ(train, train)^-1 y_train\n",
    "    elif obj_fn == 'test':\n",
    "        grads = 0\n",
    "        for i in range(int(len(x_test)/batch_size)):\n",
    "            batch_grads = grads_fn(x_train, \n",
    "                                   x_test[batch_size*i:batch_size*(i+1)], \n",
    "                                   y_train, \n",
    "                                   y[batch_size*i:batch_size*(i+1)], \n",
    "                                   kernel_fn, \n",
    "                                   loss,\n",
    "                                   t)\n",
    "            grads += batch_grads\n",
    "    else:\n",
    "        raise ValueError(\"Objective function must be either train(ntk_train_train) or test(predict_fn)\")\n",
    "\n",
    "    axis = list(range(1, len(grads.shape)))\n",
    "    eps_div = 1e-12\n",
    "    \n",
    "    if norm == np.inf:\n",
    "        perturbation = eps * np.sign(grads)\n",
    "    elif norm == 1:\n",
    "        raise NotImplementedError(\"L_1 norm has not been implemented yet.\")\n",
    "    elif norm == 2:\n",
    "        square = np.maximum(eps_div, np.sum(np.square(grads), axis=axis, keepdims=True))\n",
    "        perturbation = grads / np.sqrt(square)\n",
    "    \n",
    "    # TODO\n",
    "    adv_x = x + perturbation\n",
    "    \n",
    "    # If clipping is needed, reset all values outside of [clip_min, clip_max]\n",
    "    if (clip_min is not None) or (clip_max is not None):\n",
    "        # We don't currently support one-sided clipping\n",
    "        assert clip_min is not None and clip_max is not None\n",
    "        adv_x = np.clip(adv_x, a_min=clip_min, a_max=clip_max)\n",
    "    \n",
    "    if obj_fn == 'test_c':\n",
    "        c += grads_c\n",
    "        \n",
    "        return adv_x, c\n",
    "    \n",
    "    return adv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projected_gradient_descent(model_fn, kernel_fn, obj_fn, grads_fn, grads_c_fn=None, x_train=None, y_train=None,\n",
    "                               x_test=None, y=None, t=None, c=None, update_c=None, loss='cross-entropy', loss_weighting=None, \n",
    "                               phase=None, fx_train_0=0., fx_test_0=0., eps=0.3, eps_iter=0.03, nb_iter=10, norm=np.inf, \n",
    "                               clip_min=None, clip_max=None, targeted=False, rand_init=None, rand_minmax=0.3):\n",
    "    \"\"\"\n",
    "    This class implements either the Basic Iterative Method\n",
    "    (Kurakin et al. 2016) when rand_init is set to 0. or the\n",
    "    Madry et al. (2017) method when rand_minmax is larger than 0.\n",
    "    Paper link (Kurakin et al. 2016): https://arxiv.org/pdf/1607.02533.pdf\n",
    "    Paper link (Madry et al. 2017): https://arxiv.org/pdf/1706.06083.pdf\n",
    "    :param model_fn: a callable that takes an input tensor and returns the model logits.\n",
    "    :param x: input tensor.\n",
    "    :param eps: epsilon (input variation parameter); see https://arxiv.org/abs/1412.6572.\n",
    "    :param eps_iter: step size for each attack iteration\n",
    "    :param nb_iter: Number of attack iterations.\n",
    "    :param norm: Order of the norm (mimics NumPy). Possible values: np.inf or 2.\n",
    "    :param clip_min: (optional) float. Minimum float value for adversarial example components.\n",
    "    :param clip_max: (optional) float. Maximum float value for adversarial example components.\n",
    "    :param y: (optional) Tensor with true labels. If targeted is true, then provide the\n",
    "            target label. Otherwise, only provide this parameter if you'd like to use true\n",
    "            labels when crafting adversarial samples. Otherwise, model predictions are used\n",
    "            as labels to avoid the \"label leaking\" effect (explained in this paper:\n",
    "            https://arxiv.org/abs/1611.01236). Default is None.\n",
    "    :param targeted: (optional) bool. Is the attack targeted or untargeted?\n",
    "            Untargeted, the default, will try to make the label incorrect.\n",
    "            Targeted will instead try to move in the direction of being more like y.\n",
    "    :return: a tensor for the adversarial example\n",
    "    \"\"\"\n",
    "\n",
    "    assert eps_iter <= eps, (eps_iter, eps)\n",
    "    if norm == 1:\n",
    "        raise NotImplementedError(\"It's not clear that FGM is a good inner loop\"\n",
    "                                  \" step for PGD when norm=1, because norm=1 FGM \"\n",
    "                                  \" changes only one pixel at a time. We need \"\n",
    "                                  \" to rigorously test a strong norm=1 PGD \"\n",
    "                                  \"before enabling this feature.\")\n",
    "    if norm not in [np.inf, 2]:\n",
    "        raise ValueError(\"Norm order must be either np.inf or 2.\")\n",
    "        \n",
    "    x = x_test\n",
    "    # Obtain y\n",
    "    if obj_fn == 'test':\n",
    "        if y is None:\n",
    "            # Using model predictions as ground truth to avoid label leaking\n",
    "            x_labels = np.argmax(model_fn(kernel_fn, 'test', x_train, x_test, fx_train_0, fx_test_0)[1], 1)\n",
    "            y = one_hot(x_labels, 10)\n",
    "            \n",
    "    elif obj_fn == 'train':\n",
    "        if y is None:\n",
    "            # Compute NTK on training data\n",
    "            ntk_train_train = model_fn(kernel_fn=kernel_fn, obj_fn='train', x_train=x_train)\n",
    "            \n",
    "            # Construct diagonal\n",
    "            if phase == 'ordered':\n",
    "                y = np.ones(ntk_train_train.shape)*100\n",
    "            elif phase == 'chaotic':\n",
    "                y = np.eye(ntk_train_train.shape[0])*100\n",
    "            else:\n",
    "                raise ValueError(\"Phase must be either 'ordered' or 'critical'\")\n",
    "        \n",
    "    # Initialize loop variables\n",
    "    if rand_init:\n",
    "        rand_minmax = eps\n",
    "        eta = random.uniform(new_key, x.shape, minval=-rand_minmax, maxval=rand_minmax)\n",
    "    else:\n",
    "        eta = np.zeros_like(x)\n",
    "\n",
    "    # Clip eta\n",
    "    eta = clip_eta(eta, norm, eps)\n",
    "    adv_x = x + eta\n",
    "    if clip_min is not None or clip_max is not None:\n",
    "        adv_x = np.clip(adv_x, a_min=clip_min, a_max=clip_max)\n",
    "        \n",
    "    for i in range(nb_iter):\n",
    "        if update_c is not None and (i+1) % update_c == 0:\n",
    "            adv_x = fast_gradient_method(model_fn, kernel_fn, obj_fn, grads_fn, grads_c_fn, x_train, y_train, adv_x, \n",
    "                                         y, t, c, True, loss, loss_weighting, phase, fx_train_0, fx_test_0, eps_iter, norm, \n",
    "                                         clip_min, clip_max, targeted)\n",
    "        else:\n",
    "            adv_x = fast_gradient_method(model_fn, kernel_fn, obj_fn, grads_fn, grads_c_fn, x_train, y_train, adv_x, \n",
    "                                         y, t, c, False, loss, loss_weighting, phase, fx_train_0, fx_test_0, eps_iter, norm, \n",
    "                                         clip_min, clip_max, targeted)\n",
    "        \n",
    "        if obj_fn == 'test_c':\n",
    "            adv_x, c = adv_x\n",
    "\n",
    "        # Clipping perturbation eta to norm norm ball\n",
    "        eta = adv_x - x\n",
    "        eta = clip_eta(eta, norm, eps)\n",
    "        adv_x = x + eta\n",
    "\n",
    "        # Redo the clipping.\n",
    "        # FGM already did it, but subtracting and re-adding eta can add some\n",
    "        # small numerical error.\n",
    "        if clip_min is not None or clip_max is not None:\n",
    "            adv_x = np.clip(adv_x, a_min=clip_min, a_max=clip_max)\n",
    "\n",
    "    if obj_fn == 'test_c':\n",
    "        return adv_x, c\n",
    "    \n",
    "    return adv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, kernel_fn in enumerate(kernel_list):\n",
    "#     print(phase_list[idx])\n",
    "#     print(kernel_fn(x_train, x_train, 'ntk')[:4, :4])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_type = [\"Clean\", \"FGSM\", \"PGD-10\", \"PGD-100\"]\n",
    "\n",
    "####### MNIST #######\n",
    "eps = 0.3\n",
    "eps_iter_10 = 0.04\n",
    "eps_iter_100 = 0.004\n",
    "####### MNIST #######\n",
    "\n",
    "####### CIFAR #######\n",
    "# eps = 16/255\n",
    "# eps_iter_10 = (eps/10)*1.1\n",
    "# eps_iter_100 = (eps/100)*1.1\n",
    "####### CIFAR #######\n",
    "\n",
    "val_size = 1200\n",
    "\n",
    "# x_train_all is on host device\n",
    "x_val = x_train_all[train_size:train_size+val_size]\n",
    "y_val = y_train_all[train_size:train_size+val_size]\n",
    "\n",
    "# to gpu\n",
    "x_val = np.asarray(x_val)\n",
    "y_val = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_predictor(x_train, x_test, kernel_fn, c=None):\n",
    "    \"\"\"\n",
    "    return Θ(test, train)Θ(train, train)^-1 and \n",
    "    || # Θ(test, train)Θ(train, train)^-1 - target ||\n",
    "    \n",
    "    \"\"\"\n",
    "    # Kernel\n",
    "    ntk_train_train = kernel_fn(x_train, x_train, 'ntk')\n",
    "    ntk_test_train = kernel_fn(x_test, x_train, 'ntk')\n",
    "    \n",
    "    # Θ(test, train)Θ(train, train)^-1\n",
    "    def inv(k):\n",
    "        return np.linalg.inv(k + diag_reg * np.eye(k.shape[0]))\n",
    "    mean_predictor = np.einsum('ij,jk->ik', ntk_test_train, inv(ntk_train_train))\n",
    "    \n",
    "    if c is None:\n",
    "        c = np.mean(mean_predictor)\n",
    "    \n",
    "    # Loss\n",
    "    loss = l2_loss_v1(mean_predictor, np.ones_like(mean_predictor)*c)\n",
    "    return loss, mean_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_predictor_row_col_wise(x_train, x_test, kernel_fn, c=None, row=False, col=False):\n",
    "    \"\"\"\n",
    "    return Θ(test, train)Θ(train, train)^-1 and \n",
    "    || # Θ(test, train)Θ(train, train)^-1 - target ||\n",
    "    \n",
    "    \"\"\"\n",
    "    if not row and not col:\n",
    "        raise ValueError(\"at least one of row or col should be true\")\n",
    "    # Kernel\n",
    "    ntk_train_train = kernel_fn(x_train, x_train, 'ntk')\n",
    "    ntk_test_train = kernel_fn(x_test, x_train, 'ntk')\n",
    "    \n",
    "    # Θ(test, train)Θ(train, train)^-1\n",
    "    def inv(k):\n",
    "        return np.linalg.inv(k + diag_reg * np.eye(k.shape[0]))\n",
    "    mean_predictor = np.einsum('ij,jk->ik', ntk_test_train, inv(ntk_train_train))\n",
    "    loss = 0.0\n",
    "    if c is None:\n",
    "        if row:\n",
    "            c = np.mean(mean_predictor, axis=1)\n",
    "            c = np.reshape(c, (1, -1))\n",
    "            loss = l2_loss_v1(mean_predictor, np.ones_like(mean_predictor)*c.T)\n",
    "        else:\n",
    "            c = np.mean(mean_predictor, axis=0)\n",
    "            loss = l2_loss_v1(mean_predictor, np.ones_like(mean_predictor)*c)\n",
    "    \n",
    "    return loss, mean_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x_train, x_test, model_fn, kernel_fn, t=None, c=0, attack_type=None):\n",
    "    y_train_predict, y_test_predict = model_fn(kernel_fn, 'test', x_train, x_test, t=t)\n",
    "    print(len(y_test_predict))\n",
    "    acc = accuracy(y_test_predict, y_test)\n",
    "    print(\"Robustness({:s}): {:.2f}\".format(attack_type, acc))\n",
    "    \n",
    "    # Mean predictor\n",
    "    l, m = mean_predictor(x_train, x_test, kernel_fn, c)\n",
    "    # print(\"c:{:.8f}, Mean: {:.8f}, Loss: {:.8f}\".format(c_list[idx], np.mean(m), l))\n",
    "    print(m[:5, :5])\n",
    "    print()\n",
    "    print('shape: ', m.shape)\n",
    "    print('row: ', np.mean(np.std(m, axis=0)))\n",
    "    print('col: ', np.mean(np.std(m, axis=1)))\n",
    "    return np.mean(m, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train list gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = None\n",
    "loss_type = ['cross-entropy', 'mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "Robustness(Clean): 0.86\n",
      "[[ 0.00112736  0.01011385  0.00287164  0.001241    0.00544948]\n",
      " [-0.0015968   0.00132874  0.01696907 -0.00243109 -0.00083482]\n",
      " [-0.00199748  0.01193599 -0.00562409 -0.00149281  0.00288802]\n",
      " [-0.00396522  0.012832    0.0027059  -0.00103998  0.00695626]\n",
      " [ 0.04279609 -0.00182015 -0.00166272 -0.00105851 -0.00062796]]\n",
      "\n",
      "shape:  (256, 256)\n",
      "row:  0.013633210044645383\n",
      "col:  0.014114156922545015\n"
     ]
    }
   ],
   "source": [
    "x_test_list = []\n",
    "c_list = []\n",
    "\n",
    "c_sample = evaluate(x_train, x_test, model_fn=model_fn, kernel_fn=kernel_list[1], t=t, c=0, attack_type='Clean')\n",
    "x_test_list.append(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c_sample.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "Robustness(Clean): 0.86\n",
      "[[ 0.00112736  0.01011385  0.00287164  0.001241    0.00544948]\n",
      " [-0.0015968   0.00132874  0.01696907 -0.00243109 -0.00083482]\n",
      " [-0.00199748  0.01193599 -0.00562409 -0.00149281  0.00288802]\n",
      " [-0.00396522  0.012832    0.0027059  -0.00103998  0.00695626]\n",
      " [ 0.04279609 -0.00182015 -0.00166272 -0.00105851 -0.00062796]]\n",
      "\n",
      "shape:  (256, 256)\n",
      "row:  0.013633210044645383\n",
      "col:  0.014114156922545015\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mul got incompatible shapes for broadcasting: (256, 30), (1, 256).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-d0c569cb254e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                     \u001b[0mgrads_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_col_wise_grads_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_c_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_col_wise_c_grads_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                     \u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                     loss=loss_type[0], eps=eps, clip_min=0, clip_max=1)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'FGSM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-640d75693afe>\u001b[0m in \u001b[0;36mfast_gradient_method\u001b[0;34m(model_fn, kernel_fn, obj_fn, grads_fn, grads_c_fn, x_train, y_train, x_test, y, t, c, update_c, loss, loss_weighting, phase, fx_train_0, fx_test_0, eps, norm, clip_min, clip_max, targeted)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mgrads_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgrads_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdate_c\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 grads_c += grads_c_fn(x_train[batch_size*i:batch_size*(i+1)], x_test, kernel_fn, \n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/api.py\u001b[0m in \u001b[0;36mf_jitted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_fun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         donated_invars=donated_invars)\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtop_trace\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnew_sublevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m       \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_xla_call_impl\u001b[0;34m(fun, device, backend, name, donated_invars, *args)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_xla_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWrappedFun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdonated_invars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m   compiled_fun = _xla_callable(fun, device, backend, name, donated_invars,\n\u001b[0;32m--> 530\u001b[0;31m                                *unsafe_map(arg_spec, args))\n\u001b[0m\u001b[1;32m    531\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mmemoized_fun\u001b[0;34m(fun, *args)\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_stores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m       \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_xla_callable\u001b[0;34m(fun, device, backend, name, donated_invars, *arg_specs)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0mpvals\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPartialVal\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPartialVal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mabstract_args\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     jaxpr, pvals, consts = pe.trace_to_jaxpr(\n\u001b[0;32m--> 601\u001b[0;31m         fun, pvals, instantiate=False, stage_out=True, bottom=True)\n\u001b[0m\u001b[1;32m    602\u001b[0m   \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr_literals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m   \u001b[0mjaxpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_outfeed_rewriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr\u001b[0;34m(fun, pvals, instantiate, stage_out, bottom, trace_type)\u001b[0m\n\u001b[1;32m    420\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/api.py\u001b[0m in \u001b[0;36mgrad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    749\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mapi_boundary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgrad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_and_grad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/api.py\u001b[0m in \u001b[0;36mvalue_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0mtree_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_check_input_dtype_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholomorphic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdyn_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m       \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_py\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdyn_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_py\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdyn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/api.py\u001b[0m in \u001b[0;36m_vjp\u001b[0;34m(fun, *primals, **kwargs)\u001b[0m\n\u001b[1;32m   1854\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun_nokwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0mout_primal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_vjp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m     \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m   \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tangents_pvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_primal_pval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout_primal_pval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr\u001b[0;34m(fun, pvals, instantiate, stage_out, bottom, trace_type)\u001b[0m\n\u001b[1;32m    420\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-31ea1d0626f8>\u001b[0m in \u001b[0;36mtest_loss_adv_col\u001b[0;34m(x_train, x_test, kernel_fn, c, t)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ml2_loss_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_predictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_predictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/core.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    484\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__sub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__rmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__div__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdeferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4473\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_scalar_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_arraylike_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTracer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4474\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4475\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4476\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeferring_binary_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    368\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_promote_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbool_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbool_lax_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_wraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlax_doc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/lax/lax.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m   \u001b[0;34mr\"\"\"Elementwise multiplication: :math:`x \\times y`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmul_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m     \u001b[0mout_tracer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tracer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Differentiation rule for '{primitive}' not implemented\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0mprimal_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtangent_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimals_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtangents_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mJVPTracer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimal_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtangent_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mstandard_jvp\u001b[0;34m(jvprules, primitive, primals, tangents, **params)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstandard_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvprules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtangents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m   \u001b[0mval_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m   tangents_out = [rule(t, *primals, **params) for rule, t in zip(jvprules, tangents)\n\u001b[1;32m    398\u001b[0m                   if rule is not None and type(t) is not Zero]\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m     \u001b[0mout_tracer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tracer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_partial_eval_rules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_process_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdefault_process_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mdefault_process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstantiate_const\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mavals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mout_aval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstract_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mavals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_info_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/lax/lax.py\u001b[0m in \u001b[0;36mstandard_abstract_eval\u001b[0;34m(prim, shape_rule, dtype_rule, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mConcreteArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mleast_specialized\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mShapedArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mShapedArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1929\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mleast_specialized\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mUnshapedArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mUnshapedArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jax/lax/lax.py\u001b[0m in \u001b[0;36m_broadcasting_shape_rule\u001b[0;34m(name, *avals)\u001b[0m\n\u001b[1;32m   1981\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mresult_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{} got incompatible shapes for broadcasting: {}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1983\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1984\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: mul got incompatible shapes for broadcasting: (256, 30), (1, 256)."
     ]
    }
   ],
   "source": [
    "for _ in range(1):\n",
    "    x_test_list = []\n",
    "    c_list = []\n",
    "    \n",
    "    evaluate(x_train, x_test, model_fn=model_fn, kernel_fn=kernel_list[1], t=t, c=0, attack_type='Clean')\n",
    "    x_test_list.append(x_test)\n",
    "    c_list.append(c)\n",
    "\n",
    "    # FGSM\n",
    "    adv_x, c = fast_gradient_method(model_fn=model_fn, kernel_fn=kernel_list[1], obj_fn='test_c', \n",
    "                                    grads_fn=test_col_wise_grads_fn, grads_c_fn=test_col_wise_c_grads_fn,\n",
    "                                    x_train=x_train, y_train=y_train, x_test=x_test, y=y_test, t=t, c=c,\n",
    "                                    loss=loss_type[0], eps=eps, clip_min=0, clip_max=1)\n",
    "    \n",
    "    evaluate(x_train, adv_x, model_fn=model_fn, kernel_fn=kernel_list[1], t=t, c=c, attack_type='FGSM')\n",
    "    x_test_list.append(adv_x)\n",
    "    c_list.append(c)\n",
    "    \n",
    "    # PGD 10\n",
    "    key, new_key = random.split(key)\n",
    "    c = c_sample.reshape((1, -1))\n",
    "    adv_x, c = projected_gradient_descent(model_fn=model_fn, kernel_fn=kernel_list[1], obj_fn='test_c', \n",
    "                                          grads_fn=test_col_wise_grads_fn, grads_c_fn=test_col_wise_c_grads_fn,\n",
    "                                          x_train=x_train, y_train=y_train, x_test=x_test, y=y_test, t=t, c=c, update_c=3, \n",
    "                                          loss=loss_type[0], eps=eps, eps_iter=eps_iter_10, nb_iter=10, \n",
    "                                          clip_min=0, clip_max=1, rand_init=None, rand_minmax=eps)\n",
    "    \n",
    "    evaluate(x_train, adv_x, model_fn=model_fn, kernel_fn=kernel_list[1], t=t, c=c, attack_type='PGD-10')\n",
    "    x_test_list.append(adv_x)\n",
    "    c_list.append(c)\n",
    "    \n",
    "    # PGD 100\n",
    "    key, new_key = random.split(key)\n",
    "    c = c_sample.reshape((1, -1))\n",
    "    adv_x, c = projected_gradient_descent(model_fn=model_fn, kernel_fn=kernel_list[1], obj_fn='test_c', \n",
    "                                          grads_fn=test_col_wise_grads_fn, grads_c_fn=test_col_wise_c_grads_fn,\n",
    "                                          x_train=x_train, y_train=y_train, x_test=x_test, y=y_test, t=t, c=c, update_c=3, \n",
    "                                          loss=loss_type[0], eps=eps, eps_iter=eps_iter_100, nb_iter=100, \n",
    "                                          clip_min=0, clip_max=1, rand_init=None, rand_minmax=eps)\n",
    "    \n",
    "    evaluate(x_train, adv_x, model_fn=model_fn, kernel_fn=kernel_list[1], t=t, c=c, attack_type='PGD-100')\n",
    "    x_test_list.append(adv_x)\n",
    "    c_list.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f61cef26cf8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test_list[0][0].reshape((28 ,28)), cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f61cec2f1d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test_list[1][0].reshape((28, 28)), cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f61ce790470>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAARrklEQVR4nO3df4jVdboH8PdkXlA3Mn8ypDPtHeUxEddNq4GdNi3QumqjBLJuLCPEblQGUlBigfXHDf9o6wp3C9bN0sgsclst4rphQVfUEi0mRR/RyXGLyR+UrGm1jp77xzkTc3W+zzN9v+d7ztHn/YLwzHn8nvOZb/P2e+Y85/P51BUKBRDR5e+Kag+AiCqDYScKgmEnCoJhJwqCYScK4spKPllTU1Ohu7u7kk9JFMqVV16JQ4cO1fVZy/LAInIHgJUABgD4i6qusP5+d3c3jhw5kuUpicjQ0NCQWEv9Ml5EBgD4E4A7AUwEsFBEJqZ9PCLKV5bf2W8CcFBVO1T1XwDWA2gtz7CIqNyyhP1aAP/o9fUXpfuIqAbx3XiiILKE/UsAY3t9PaZ0HxHVoCzvxu8EMF5Efo5iyH8D4LdlGRURlV3qsKtqt4gsBrAZxdbbalXdW7aRETnmzJlj1ru6uhJrgwYNMo/dunVrqjHVskx9dlV9F8C7ZRoLEeWIb9ARBcGwEwXBsBMFwbATBcGwEwXBsBMFUdH57FFZ0w4B4PrrrzfrJ06cMOvHjx//yWPqcebMGbM+YsSI1I8NAOPGjUusWX1wANi1a5dZf+edd1KNCQBaWlpSH3up4pWdKAiGnSgIhp0oCIadKAiGnSgIhp0oCLbe+slqQXmtMW9FXa8157Wgqmnq1KlmfceOHYk177x552XkyJFmPUvb0Js+e/bsWbO+efPm1M+dF17ZiYJg2ImCYNiJgmDYiYJg2ImCYNiJgmDYiYKoKxQKFXuyxsbGQq3u4ur1Vdvb2xNrWfvoXr/49OnTZt16fm8Ka1be9zZ58uTEmnVOAf+8ZuGN23tu7+fFY03vzfK5ioaGBnR2dva5ZTOv7ERBMOxEQTDsREEw7ERBMOxEQTDsREEw7ERBhJnPPmHCBLPuLWucpedr9ZrLwVqu+eTJk+ax3pzy/fv3m3XvvGQ5by+88IJZr6+vN+vWnPPnn3/ePNYbt7eMtbdUtbdldB4yhV1EDgM4BeAcgG5VnVaGMRFRDspxZZ+hqvblgYiqjr+zEwWRNewFAH8XkV0i8odyDIiI8pE17C2qegOAOwE8KCK/LsOYiCgHmcKuql+W/jwG4C0AN5VjUERUfqnDLiJDROSqntsAZgLYU66BEVF5ZXk3fjSAt0Sk53HWqer/lGVUOfDWEP/uu+9SP/asWbPMetatifOUdT2DPXvsf98nTZqU+rE3bdpk1u+66y6zvnHjxsTa2rVrzWOfeeYZs75y5Uqz7n1+wfpshLcWf9qfl9RhV9UOAL9IezwRVRZbb0RBMOxEQTDsREEw7ERBMOxEQVxSS0lby/d6Uzk9XqvE4i3XPHjwYLPuTSPNwmsRzZw506x7U4Oz8L7vKVOmZHr8p556KrG2aNEi89jRo0eb9bq6Pldr/lGWpaYPHjxo1q3zxqWkiYhhJ4qCYScKgmEnCoJhJwqCYScKgmEnCuKyWUp66NChZn3Hjh1m3euzW71yr88+Y8YMs+7x+tEPPfRQYq2xsdE89sCBA2ZdVc368OHDzfr999+fWOvu7jaP/eGHH8y6Z8CAAYk17+fB6/Fn3bLZMmTIkFwel1d2oiAYdqIgGHaiIBh2oiAYdqIgGHaiIBh2oiAumz67N5/dW0ra67N7vXSL1ze1lhUGgFdffdWs33DDDYk17/vyzos3bztPXi/b2zZ52LBhibXW1lbz2E8++cSsZ9Xe3p5Yy2uLb17ZiYJg2ImCYNiJgmDYiYJg2ImCYNiJgmDYiYK4pPrsVl/V68l6893zXLs9q71795p1a233jo4O89i5c+ea9TznbWdlbckM+Fs6W9avX2/Wvc91bN261aw3NDSkfuy03LCLyGoAcwAcU9VJpfuGAXgdwHUADgNYoKrf5DJCIiqL/ryMfxnAHRfctxTAFlUdD2BL6WsiqmFu2FX1QwBfX3B3K4A1pdtrAMwr87iIqMzSvkE3WlW7Sre/AmBvjEVEVZf53XhVLQCo3O6QRJRK2rAfFZF6ACj9eax8QyKiPKQN+yYAbaXbbQDsHggRVV1/Wm+vAZgOYISIfAFgOYAVAN4QkXsBdAJYkOcgKyHL3OmsvWhvXnZXV5dZf/jhhxNrU6dONY/15rPXsix9dM/OnTtze2zA3ofA69Gn5YZdVRcmlG4v81iIKEf8uCxREAw7URAMO1EQDDtREAw7URCX1BTXLLwteq1WCGBPI83Ka48dP37crFtjGzhwYKox1YKbb77ZrJ8/f96sX3FF8rVs7dq15rHe8t9eu9RTjZYnr+xEQTDsREEw7ERBMOxEQTDsREEw7ERBMOxEQYTps3u9bG9r43379iXWvC2XPV4f/ciRI2Y9yxa/3ucPmpubUz+2x5u6O3bsWLNu9dE9bW1tZt37ecm6nXRe01gtvLITBcGwEwXBsBMFwbATBcGwEwXBsBMFwbATBRGmz+7N6/bmF585cyax5vVUH3vsMbP+xBNPmHXv8WfOnJlYu+WWWzI9dtZlsq3PCHzwwQfmsd58ds+tt96a+tjTp09nem6vT79r165Mj58Gr+xEQTDsREEw7ERBMOxEQTDsREEw7ERBMOxEQYTps3u8PvyoUaMSa/fcc495rLWlMgBs377drE+bNs2sf/3114m1jRs3msfW1dWZde/4YcOGmXWrzz979mzz2G3btpn1G2+80ax/++23ibWGhgbzWG/d+LNnz5r1avTRPf3Zn301gDkAjqnqpNJ9TwL4PYCeVReWqeq7eQ2SiLLrz5X9ZQD/DeDCLTSeU9Vnyj4iIsqF+zu7qn4IIPl1IhFdErK8QbdYRNpFZLWIXFO2ERFRLtKG/QUATQCmAOgC8MeyjYiIcpHq3XhVPdpzW0RWAci2pSUR5S7VlV1E6nt9OR/AnvIMh4jy0p/W22sApgMYISJfAFgOYLqITAFQAHAYwH05jrEi7r77brP+9ttvJ9b27LH/rSsUCmbdWzf+xRdfNOvff/99Yu3TTz81j/X2nX/vvffM+pgxY8y61advamoyj/VYfXSPtxa/J+t8d0tLS4tZT7vmvBt2VV3Yx932Tx8R1Rx+XJYoCIadKAiGnSgIhp0oCIadKIhLaoqr1SY6efKkeeykSZPM+qJFi9IMCQDw+OOPm/UDBw6Y9f3796d+bo/XWnvllVfMepbWmsf7f9LR0WHW586da9atdqnH2wbbW4Lbm0Jrtf686bVp8cpOFATDThQEw04UBMNOFATDThQEw04UBMNOFESdN/2ynBobGwtZphZaPWNrS2UA6OzsTP28gD2t0NsW2eu5jhw50qx7yxLfd1/yDGNvO+isffSPPvrIrJ87dy6x5k3tnTdvnln3fnaXLFmSWDt8+LB5rMfb4turnzhxIrE2ePBg81grQw0NDejs7OxzfXBe2YmCYNiJgmDYiYJg2ImCYNiJgmDYiYJg2ImCuKTms48bNy6x9v7775vHer1q7/hHH33UrFuyzo325tqvWLEiseb1wb0++9NPP23W58yZY9Y//vjjxFpXV5d57NKlS826tw7A/PnzE2vPPfeceWzWz0bU19ebdWvO+qBBg8xj035WhVd2oiAYdqIgGHaiIBh2oiAYdqIgGHaiIBh2oiAuqT67xdtC15uXvW7dutTPbc2bBoDbb7/drGdZ3xywv7fW1lbz2La2NrM+atQos2710QHg4MGDZt0iImZ91apVZv3ZZ59NrC1fvtw8trm52ax7n9vwzJo1K9PxafRnf/axANYCGI3ifux/VtWVIjIMwOsArkNxj/YFqvpNfkMloiz68zK+G8AjqjoRQDOAB0VkIoClALao6ngAW0pfE1GNcsOuql2qurt0+xSAfQCuBdAKYE3pr60BYK8hRERV9ZPeoBOR6wD8EsBHAEaras+Hm79C8WU+EdWofoddRH4GYAOAJar6z941VS2g+Ps8EdWofoVdRAaiGPRXVfWvpbuPikh9qV4P4Fg+QySicujPu/F1AF4EsE9Ve/cyNgFoA7Ci9Gf6vXsrwFue99577zXrixcvLudwfpKdO3ea9b179ybWvOWYPd4U1ixbF3v/TzxZlkG/+uqrzfrs2bPNetZttjdv3pzp+DT602f/FYDfAfhMRD4t3bcMxZC/ISL3AugEsCCfIRJRObhhV9WtAPpcdB6A/WkRIqoZ/LgsURAMO1EQDDtREAw7URAMO1EQl9SWzZajR4+a9eHDh5v1AQMGpH7uzz//3Ky/9NJLZn3NmjVm3etHZ+35WrL22S3e9+Vte+wdv23btsTaNddcYx67fft2s+4tse3Jct4s3LKZiBh2oigYdqIgGHaiIBh2oiAYdqIgGHaiIC6bpaQfeOABs97U1JTp8d98883E2sSJE81j29vbzbrXL7a2qgay9dnz7KN7vG2RPV4f/pFHHkmseVsuHzp0KNWYemRZQjsvvLITBcGwEwXBsBMFwbATBcGwEwXBsBMFwbATBXHZ9Nk3bNhg1r2e7uTJk816R0dHqhqQfV62x+uVZ+GN3aufOXMmsTZkyBDz2Pr6erPufQZg6NChibXjx4+bx2aV52cj0uKVnSgIhp0oCIadKAiGnSgIhp0oCIadKAiGnSiI/uzPPhbAWgCjARQA/FlVV4rIkwB+D6CnYblMVd/Na6BZeX10r2fb0tKSWPPWwj9x4oRZ93qynpMnTybWrF5zOWQdu6Wrqyu3x7bOGZD/eauG/nyophvAI6q6W0SuArBLRN4r1Z5T1WfyGx4RlUt/9mfvAtBVun1KRPYBuDbvgRFRef2k39lF5DoAvwTwUemuxSLSLiKrRcTeT4eIqqrfYReRnwHYAGCJqv4TwAsAmgBMQfHK/8dcRkhEZdGviTAiMhDFoL+qqn8FAFU92qu+CkB+KxMSUWbulV1E6gC8CGCfqj7b6/7eU5LmA9hT/uERUbn058r+KwC/A/CZiHxaum8ZgIUiMgXFdtxhAPflMsIyybokstU+89p6Hm/ZYa9119zcnOn5szx3lhaW11rbt2+fWZ86dapZz3MZ7EtRf96N3wqgr/2ea7anTkQX4yfoiIJg2ImCYNiJgmDYiYJg2ImCYNiJgqgrFAoVe7LGxsaCNx2UKstbCnrChAlmfffu3Wb9tttuS6ydPXvWPHbgwIFmnX30izU0NKCzs7OvVjmv7ERRMOxEQTDsREEw7ERBMOxEQTDsREEw7ERBVLTPLiLHAXRW7AmJ4mlU1ZF9FSoadiKqHr6MJwqCYScKgmEnCoJhJwqCYScKgmEnCqJfO8KUm4jcAWAlgAEA/qKqK6oxjr6IyGEApwCcA9CtqtOqOJbVAOYAOKaqk0r3DQPwOoDrUFyvf4GqflMjY3sSNbCNt7HNeFXPXbW3P6/4lV1EBgD4E4A7AUxEcbOJiZUeh2OGqk6pZtBLXgZwxwX3LQWwRVXHA9hS+roaXsbFYwOK23hPKf1Xrb0FerYZnwigGcCDpZ+xap+7pHEBFThv1XgZfxOAg6raoar/ArAeQGsVxlHzVPVDAF9fcHcrgDWl22sAzKvooEoSxlYTVLVLVXeXbp8C0LPNeFXPnTGuiqhG2K8F8I9eX3+B2trvvQDg7yKyS0T+UO3B9GG0qvbsm/QVii8Ja0lNbeN9wTbjNXPuqrH9Od+gu1iLqt6A4q8ZD4rIr6s9oCSqWkDxH6daUVPbePexzfiPqnnuqrX9eTXC/iWAsb2+HlO6ryao6pelP48BeAvFXztqydGeHXRLfx6r8nh+pKpHVfWcqp4HsApVPHd9bTOOGjh3SdufV+K8VSPsOwGMF5Gfi8i/AfgNgE1VGMdFRGSIiFzVcxvATNTeVtSbALSVbrcB2FjFsfw/tbKNd9I246jyuav29udVmfUmIv8B4L9QbL2tVtX/rPgg+iAi/47i1RwotiXXVXNsIvIagOkARgA4CmA5gL8BeANAA4rThReoasXfKEsY23QUX4r+uI13r9+RKzm2FgD/C+AzAOdLdy9D8ffjqp07Y1wLUYHzximuREHwDTqiIBh2oiAYdqIgGHaiIBh2oiAYdqIgGHaiIP4PqJZnv+CporoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test_list[2][0].reshape((28, 28)), cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f61ce73c240>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test_list[3][0].reshape((28, 28)), cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "Robustness(Clean): 0.86\n",
      "[[ 0.00112736  0.01011385  0.00287164  0.001241    0.00544948]\n",
      " [-0.0015968   0.00132874  0.01696907 -0.00243109 -0.00083482]\n",
      " [-0.00199748  0.01193599 -0.00562409 -0.00149281  0.00288802]\n",
      " [-0.00396522  0.012832    0.0027059  -0.00103998  0.00695626]\n",
      " [ 0.04279609 -0.00182015 -0.00166272 -0.00105851 -0.00062796]]\n",
      "\n",
      "256\n",
      "Robustness(FGSM): 0.76\n",
      "[[-7.31078699e-04  2.92903614e-03  5.43250651e-03  6.67594540e-04\n",
      "   2.25524591e-03]\n",
      " [-1.96649544e-03 -8.66053704e-04  1.40917228e-02 -1.44332758e-03\n",
      "  -1.68834972e-03]\n",
      " [-1.60995693e-03  8.38280497e-03 -1.84292881e-03 -2.41019468e-03\n",
      "   3.41287823e-03]\n",
      " [-9.78804255e-04  1.15932265e-02  6.06483282e-03 -3.99598156e-03\n",
      "   6.17756399e-03]\n",
      " [ 2.24459080e-02  5.36157801e-05 -2.52951109e-03 -2.44209142e-03\n",
      "  -3.94823496e-03]]\n",
      "\n",
      "update_c: 1\n",
      "256\n",
      "Robustness(PGD-10): 0.78\n",
      "[[-4.26988120e-03  5.04486080e-03  8.86506402e-03 -5.67124272e-05\n",
      "   3.58916334e-03]\n",
      " [-2.03793332e-03 -2.66613768e-03  1.48294663e-02 -1.70671905e-03\n",
      "  -1.44862185e-03]\n",
      " [-1.92157298e-03  8.91376827e-03  2.74549616e-03 -1.89186644e-03\n",
      "   7.56701282e-04]\n",
      " [-3.09007220e-03  9.22607686e-03  9.98459872e-03 -2.91234233e-03\n",
      "   5.38304388e-03]\n",
      " [ 4.65576209e-02 -4.69364258e-03 -3.97419663e-03  9.19339227e-04\n",
      "   5.44150136e-03]]\n",
      "\n",
      "update_c: 2\n",
      "256\n",
      "Robustness(PGD-10): 0.79\n",
      "[[-4.23890643e-03  5.00793209e-03  9.01556432e-03 -8.31752146e-05\n",
      "   3.54937612e-03]\n",
      " [-2.11184395e-03 -2.85493452e-03  1.52173603e-02 -1.81917791e-03\n",
      "  -1.44862247e-03]\n",
      " [-2.00062343e-03  9.05618524e-03  2.89466672e-03 -1.84878319e-03\n",
      "   8.08477212e-04]\n",
      " [-3.21715270e-03  9.13640904e-03  1.04618002e-02 -2.97854894e-03\n",
      "   5.52078185e-03]\n",
      " [ 4.67493395e-02 -4.75178897e-03 -3.88549446e-03  8.00766522e-04\n",
      "   5.30035378e-03]]\n",
      "\n",
      "update_c: 4\n",
      "256\n",
      "Robustness(PGD-10): 0.79\n",
      "[[-4.30449133e-03  5.09744317e-03  8.98970467e-03 -7.10082384e-05\n",
      "   3.62691650e-03]\n",
      " [-2.09970186e-03 -2.82112209e-03  1.52381998e-02 -1.81803101e-03\n",
      "  -1.44262621e-03]\n",
      " [-2.01511406e-03  9.07160562e-03  2.93156739e-03 -1.94548526e-03\n",
      "   8.12340118e-04]\n",
      " [-3.34015358e-03  9.14335360e-03  1.04837958e-02 -2.89827412e-03\n",
      "   5.42406386e-03]\n",
      " [ 4.66274211e-02 -4.78049277e-03 -3.91254671e-03  7.55464460e-04\n",
      "   5.20295050e-03]]\n",
      "\n",
      "update_c: 8\n",
      "256\n",
      "Robustness(PGD-10): 0.79\n",
      "[[-4.27901894e-03  5.11996813e-03  9.01032512e-03 -5.15367829e-05\n",
      "   3.60930627e-03]\n",
      " [-2.08461823e-03 -2.78891584e-03  1.53403469e-02 -1.79821123e-03\n",
      "  -1.45205895e-03]\n",
      " [-1.95834147e-03  9.16331273e-03  2.94486954e-03 -2.00664169e-03\n",
      "   8.58974457e-04]\n",
      " [-3.35762308e-03  9.05507455e-03  1.04768743e-02 -2.90605518e-03\n",
      "   5.41072238e-03]\n",
      " [ 4.66775449e-02 -4.74771012e-03 -3.87424073e-03  7.53414041e-04\n",
      "   5.25770315e-03]]\n",
      "\n",
      "update_c: 16\n",
      "256\n",
      "Robustness(PGD-10): 0.79\n",
      "[[-4.27901894e-03  5.11996813e-03  9.01032512e-03 -5.15367829e-05\n",
      "   3.60930627e-03]\n",
      " [-2.09015473e-03 -2.78919172e-03  1.53347966e-02 -1.79972713e-03\n",
      "  -1.45281543e-03]\n",
      " [-1.95834147e-03  9.16331273e-03  2.94486954e-03 -2.00664169e-03\n",
      "   8.58974457e-04]\n",
      " [-3.35598291e-03  9.05261816e-03  1.04781300e-02 -2.90572508e-03\n",
      "   5.41068106e-03]\n",
      " [ 4.66775449e-02 -4.74771012e-03 -3.87424073e-03  7.53414041e-04\n",
      "   5.25770315e-03]]\n",
      "\n",
      "update_c: 32\n",
      "256\n",
      "Robustness(PGD-10): 0.79\n",
      "[[-4.27901894e-03  5.11996813e-03  9.01032512e-03 -5.15367829e-05\n",
      "   3.60930627e-03]\n",
      " [-2.09015473e-03 -2.78919172e-03  1.53347966e-02 -1.79972713e-03\n",
      "  -1.45281543e-03]\n",
      " [-1.95834147e-03  9.16331273e-03  2.94486954e-03 -2.00664169e-03\n",
      "   8.58974457e-04]\n",
      " [-3.35598291e-03  9.05261816e-03  1.04781300e-02 -2.90572508e-03\n",
      "   5.41068106e-03]\n",
      " [ 4.66775449e-02 -4.74771012e-03 -3.87424073e-03  7.53414041e-04\n",
      "   5.25770315e-03]]\n",
      "\n",
      "update_c: 64\n",
      "256\n",
      "Robustness(PGD-10): 0.79\n",
      "[[-4.27901894e-03  5.11996813e-03  9.01032512e-03 -5.15367829e-05\n",
      "   3.60930627e-03]\n",
      " [-2.09015473e-03 -2.78919172e-03  1.53347966e-02 -1.79972713e-03\n",
      "  -1.45281543e-03]\n",
      " [-1.95834147e-03  9.16331273e-03  2.94486954e-03 -2.00664169e-03\n",
      "   8.58974457e-04]\n",
      " [-3.35598291e-03  9.05261816e-03  1.04781300e-02 -2.90572508e-03\n",
      "   5.41068106e-03]\n",
      " [ 4.66775449e-02 -4.74771012e-03 -3.87424073e-03  7.53414041e-04\n",
      "   5.25770315e-03]]\n",
      "\n",
      "update_c: 1\n",
      "256\n",
      "Robustness(PGD-100): 0.77\n",
      "[[-0.00379634  0.004873    0.00920179 -0.0001084   0.00369985]\n",
      " [-0.00205058 -0.00293253  0.0149287  -0.00153152 -0.00136389]\n",
      " [-0.00203944  0.00922     0.00358305 -0.00179971  0.00099833]\n",
      " [-0.0027543   0.00869902  0.00972733 -0.00280783  0.00487334]\n",
      " [ 0.04555639 -0.00518328 -0.0036908   0.00017563  0.00487758]]\n",
      "\n",
      "update_c: 2\n",
      "256\n",
      "Robustness(PGD-100): 0.77\n",
      "[[-0.0038381   0.00494069  0.00922167 -0.00018848  0.00363441]\n",
      " [-0.00215703 -0.0031069   0.0151841  -0.0016551  -0.00130205]\n",
      " [-0.00205443  0.00953181  0.00361906 -0.00186893  0.00099636]\n",
      " [-0.00299801  0.00866338  0.00987098 -0.00290066  0.00494965]\n",
      " [ 0.04589252 -0.00513145 -0.00390918 -0.00030252  0.00495618]]\n",
      "\n",
      "update_c: 4\n",
      "256\n",
      "Robustness(PGD-100): 0.77\n",
      "[[-0.00382899  0.00493865  0.00927264 -0.00020785  0.00363281]\n",
      " [-0.00218852 -0.0031856   0.01543218 -0.00171109 -0.00125164]\n",
      " [-0.00207775  0.00962425  0.00364682 -0.00183234  0.00096962]\n",
      " [-0.00302352  0.00849012  0.00973703 -0.00288255  0.00478772]\n",
      " [ 0.04549268 -0.00515077 -0.00390251 -0.0003046   0.00505462]]\n",
      "\n",
      "update_c: 8\n",
      "256\n",
      "Robustness(PGD-100): 0.77\n",
      "[[-0.00381911  0.00501875  0.00930746 -0.00023109  0.003635  ]\n",
      " [-0.00219616 -0.003303    0.0157598  -0.0017953  -0.00119907]\n",
      " [-0.0020495   0.00969527  0.00359163 -0.00176872  0.0009942 ]\n",
      " [-0.00304263  0.00843654  0.0098035  -0.00287393  0.00489788]\n",
      " [ 0.04576252 -0.00513862 -0.00394466 -0.00013327  0.00516404]]\n",
      "\n",
      "update_c: 16\n",
      "256\n",
      "Robustness(PGD-100): 0.77\n",
      "[[-0.00382373  0.00497752  0.00936606 -0.00022318  0.00365272]\n",
      " [-0.00220579 -0.00331299  0.01585182 -0.00182191 -0.00118829]\n",
      " [-0.00204699  0.00976228  0.00361869 -0.0017937   0.00101154]\n",
      " [-0.00305109  0.00829408  0.00953219 -0.00288099  0.00468737]\n",
      " [ 0.04561516 -0.005193   -0.00395485 -0.00017675  0.00518039]]\n",
      "\n",
      "update_c: 32\n",
      "256\n",
      "Robustness(PGD-100): 0.77\n",
      "[[-0.00381086  0.00496071  0.00935992 -0.00022003  0.00365876]\n",
      " [-0.00221109 -0.00332996  0.01585289 -0.00184543 -0.00118151]\n",
      " [-0.00207583  0.00980521  0.00362698 -0.00178276  0.00101474]\n",
      " [-0.00303913  0.00833587  0.00960523 -0.00288978  0.00478575]\n",
      " [ 0.04556293 -0.00516235 -0.00395271 -0.00016509  0.00512274]]\n",
      "\n",
      "update_c: 64\n",
      "256\n",
      "Robustness(PGD-100): 0.77\n",
      "[[-0.00379231  0.00499878  0.00935022 -0.00023672  0.00367542]\n",
      " [-0.00221304 -0.00333053  0.01585969 -0.00184167 -0.001178  ]\n",
      " [-0.00207505  0.00982344  0.00361201 -0.00178757  0.00101577]\n",
      " [-0.00307438  0.00837018  0.00967654 -0.00285265  0.00483599]\n",
      " [ 0.04555642 -0.00515465 -0.003959   -0.00015984  0.0051606 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = None\n",
    "c = np.zeros((1, train_size)) + 0.00387526\n",
    "update_c_list = [1, 2, 4, 8, 16, 32, 64]\n",
    "loss_type = ['cross-entropy', 'mse']\n",
    "\n",
    "x_test_list = []\n",
    "c_list = []\n",
    "    \n",
    "\n",
    "# Clean    \n",
    "evaluate(x_train, x_test, model_fn=model_fn, kernel_fn=kernel_list[1], t=t, c=0, attack_type='Clean')\n",
    "x_test_list.append(x_test)\n",
    "c_list.append(c)\n",
    "\n",
    "\n",
    "# FGSM\n",
    "adv_x, c = fast_gradient_method(model_fn=model_fn, kernel_fn=kernel_list[1], obj_fn='test_c', \n",
    "                                grads_fn=test_col_wise_grads_fn, grads_c_fn=test_col_wise_c_grads_fn,\n",
    "                                x_train=x_train, y_train=y_train, x_test=x_test, y=y_test, t=t, c=c,\n",
    "                                loss=loss_type[0], eps=eps, clip_min=0, clip_max=1)\n",
    "\n",
    "evaluate(x_train, adv_x, model_fn=model_fn, kernel_fn=kernel_list[1], t=t, c=c, attack_type='FGSM')\n",
    "x_test_list.append(adv_x)\n",
    "c_list.append(c)\n",
    "\n",
    "for update_c in update_c_list:\n",
    "    # PGD 10\n",
    "    print('update_c:', update_c)\n",
    "    key, new_key = random.split(key)\n",
    "    c = np.zeros((1, train_size)) + 0.00387526\n",
    "    adv_x, c = projected_gradient_descent(model_fn=model_fn, kernel_fn=kernel_list[1], obj_fn='test_c', \n",
    "                                          grads_fn=test_col_wise_grads_fn, grads_c_fn=test_col_wise_c_grads_fn,\n",
    "                                          x_train=x_train, y_train=y_train, x_test=x_test, y=y_test, t=t, c=c, update_c=update_c, \n",
    "                                          loss=loss_type[0], eps=eps, eps_iter=eps_iter_10, nb_iter=10, \n",
    "                                          clip_min=0, clip_max=1, rand_init=None, rand_minmax=eps)\n",
    "    \n",
    "    evaluate(x_train, adv_x, model_fn=model_fn, kernel_fn=kernel_list[1], t=t, c=c, attack_type='PGD-10')\n",
    "    x_test_list.append(adv_x)\n",
    "    c_list.append(c)\n",
    "\n",
    "for update_c in update_c_list:\n",
    "    # PGD 100\n",
    "    print('update_c:', update_c)\n",
    "    key, new_key = random.split(key)\n",
    "    c = np.zeros((1, train_size)) + 0.00387526\n",
    "    adv_x, c = projected_gradient_descent(model_fn=model_fn, kernel_fn=kernel_list[1], obj_fn='test_c', \n",
    "                                          grads_fn=test_col_wise_grads_fn, grads_c_fn=test_col_wise_c_grads_fn,\n",
    "                                          x_train=x_train, y_train=y_train, x_test=x_test, y=y_test, t=t, c=c, update_c=update_c, \n",
    "                                          loss=loss_type[0], eps=eps, eps_iter=eps_iter_100, nb_iter=100, \n",
    "                                          clip_min=0, clip_max=1, rand_init=None, rand_minmax=eps)\n",
    "    \n",
    "    evaluate(x_train, adv_x, model_fn=model_fn, kernel_fn=kernel_list[1], t=t, c=c, attack_type='PGD-100')\n",
    "    x_test_list.append(adv_x)\n",
    "    c_list.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
