{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import tensorflow as tf\n",
    "\n",
    "from neural_tangents import stax\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "# Attacking\n",
    "from cleverhans.utils import clip_eta, one_hot\n",
    "\n",
    "# Plotting\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from utils import *\n",
    "\n",
    "sns.set_style(style='white')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\"\"\"\n",
    "diag_reg:\n",
    "    a scalar representing the strength of the diagonal regularization for\n",
    "    `k_train_train`, i.e. computing `k_train_train + diag_reg * I` during\n",
    "    Cholesky factorization or eigendecomposition.\n",
    "\"\"\"\n",
    "diag_reg = 1e-5\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.0\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'mnist'\n",
    "class_num   = 10\n",
    "image_shape = None\n",
    "\n",
    "train_size = 10000\n",
    "valid_size = 1024\n",
    "test_size  = 10000\n",
    "\n",
    "if DATASET =='mnist':\n",
    "    image_shape = (28, 28)\n",
    "elif DATASET == 'cifar10':\n",
    "    image_shape = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    }
   ],
   "source": [
    "x_train_all, y_train_all, x_test_all, y_test_all = tuple(onp.array(x) for x in get_dataset(DATASET, None, None, \n",
    "                                                                                  do_flatten_and_normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "seed = 0\n",
    "x_train_all, y_train_all = shaffle(x_train_all, y_train_all, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sample\n",
    "x_train = x_train_all[:train_size]\n",
    "y_train = y_train_all[:train_size]\n",
    "\n",
    "x_valid = x_train_all[train_size:train_size+valid_size]\n",
    "y_valid = y_train_all[train_size:train_size+valid_size]\n",
    "\n",
    "x_test = x_test_all[:test_size]\n",
    "y_test = y_test_all[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_valid, x_test = x_train.reshape((-1, *image_shape)), x_valid.reshape((-1, *image_shape)), x_test.reshape((-1, *image_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finite width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 64\n",
    "width = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_tick = [2**i for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "valid_ds = valid_ds.shuffle(5000)\n",
    "valid_ds = valid_ds.batch(batch)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.shuffle(20000)\n",
    "train_ds = train_ds.batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "re_lu_88 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_89 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_90 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_91 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_92 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_93 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_94 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_95 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 33,898\n",
      "Trainable params: 33,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.3002 - accuracy: 0.1350 - val_loss: 2.2982 - val_accuracy: 0.1152\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2938 - accuracy: 0.1440 - val_loss: 2.2894 - val_accuracy: 0.1895\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 2.2789 - accuracy: 0.1979 - val_loss: 2.2679 - val_accuracy: 0.2197\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2433 - accuracy: 0.2107 - val_loss: 2.2087 - val_accuracy: 0.2236\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.1296 - accuracy: 0.2129 - val_loss: 2.0227 - val_accuracy: 0.2246\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.9268 - accuracy: 0.2254 - val_loss: 1.8414 - val_accuracy: 0.2520\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.7596 - accuracy: 0.3088 - val_loss: 1.6666 - val_accuracy: 0.3535\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5584 - accuracy: 0.4081 - val_loss: 1.4455 - val_accuracy: 0.4336\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3089 - accuracy: 0.5170 - val_loss: 1.1830 - val_accuracy: 0.5381\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0444 - accuracy: 0.6632 - val_loss: 1.1673 - val_accuracy: 0.5459\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8187 - accuracy: 0.7402 - val_loss: 0.7798 - val_accuracy: 0.7588\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.7889 - val_loss: 0.6478 - val_accuracy: 0.7988\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.8303 - val_loss: 0.5687 - val_accuracy: 0.8418\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.8592 - val_loss: 0.4874 - val_accuracy: 0.8633\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8741 - val_loss: 0.4871 - val_accuracy: 0.8594\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8891 - val_loss: 0.5478 - val_accuracy: 0.8369\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.9012 - val_loss: 0.4020 - val_accuracy: 0.8965\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.9077 - val_loss: 0.3971 - val_accuracy: 0.8838\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.9158 - val_loss: 0.6229 - val_accuracy: 0.8330\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.9200 - val_loss: 0.3547 - val_accuracy: 0.9062\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.9306 - val_loss: 0.3450 - val_accuracy: 0.9121\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9333 - val_loss: 0.3627 - val_accuracy: 0.9023\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9382 - val_loss: 0.8041 - val_accuracy: 0.7832\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9405 - val_loss: 0.3594 - val_accuracy: 0.8984\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9448 - val_loss: 0.4259 - val_accuracy: 0.8896\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9468 - val_loss: 0.2979 - val_accuracy: 0.9238\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9517 - val_loss: 0.3505 - val_accuracy: 0.9141\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9535 - val_loss: 0.3351 - val_accuracy: 0.9180\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 0.9581 - val_loss: 0.3158 - val_accuracy: 0.9258\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1425 - accuracy: 0.9576 - val_loss: 0.2927 - val_accuracy: 0.9180\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9620 - val_loss: 0.3517 - val_accuracy: 0.9121\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9616 - val_loss: 0.3028 - val_accuracy: 0.9238\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9640 - val_loss: 1.4399 - val_accuracy: 0.7031\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1343 - accuracy: 0.9646 - val_loss: 0.4094 - val_accuracy: 0.8906\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.9690 - val_loss: 0.4160 - val_accuracy: 0.8975\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9731 - val_loss: 0.4910 - val_accuracy: 0.8818\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9705 - val_loss: 0.3291 - val_accuracy: 0.9238\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9770 - val_loss: 0.4447 - val_accuracy: 0.8936\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9749 - val_loss: 0.4287 - val_accuracy: 0.9141\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.9771 - val_loss: 0.3301 - val_accuracy: 0.9199\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9792 - val_loss: 0.3273 - val_accuracy: 0.9268\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9835 - val_loss: 0.4836 - val_accuracy: 0.9004\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9813 - val_loss: 0.3805 - val_accuracy: 0.9150\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9819 - val_loss: 1.3978 - val_accuracy: 0.7393\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9533 - val_loss: 0.3792 - val_accuracy: 0.9180\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9842 - val_loss: 0.4052 - val_accuracy: 0.9180\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9857 - val_loss: 0.3900 - val_accuracy: 0.9170\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9868 - val_loss: 0.3862 - val_accuracy: 0.9199\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9887 - val_loss: 0.3498 - val_accuracy: 0.9248\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9900 - val_loss: 0.3620 - val_accuracy: 0.9258\n",
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "re_lu_96 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_97 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_98 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_99 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_100 (ReLU)             (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_101 (ReLU)             (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_102 (ReLU)             (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_103 (ReLU)             (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 84,170\n",
      "Trainable params: 84,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.2983 - accuracy: 0.1126 - val_loss: 2.2930 - val_accuracy: 0.1250\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2817 - accuracy: 0.1587 - val_loss: 2.2689 - val_accuracy: 0.2236\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 2.2308 - accuracy: 0.2566 - val_loss: 2.1692 - val_accuracy: 0.2646\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.9640 - accuracy: 0.3321 - val_loss: 1.7085 - val_accuracy: 0.3740\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4433 - accuracy: 0.4877 - val_loss: 1.2752 - val_accuracy: 0.5459\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.1348 - accuracy: 0.6115 - val_loss: 1.0175 - val_accuracy: 0.6455\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8502 - accuracy: 0.7199 - val_loss: 0.7774 - val_accuracy: 0.7588\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.7919 - val_loss: 0.7344 - val_accuracy: 0.7646\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.8268 - val_loss: 0.7895 - val_accuracy: 0.7402\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8619 - val_loss: 0.6529 - val_accuracy: 0.7725\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8758 - val_loss: 0.4552 - val_accuracy: 0.8652\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8923 - val_loss: 0.4943 - val_accuracy: 0.8467\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.9001 - val_loss: 0.4467 - val_accuracy: 0.8740\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.9125 - val_loss: 0.4009 - val_accuracy: 0.8926\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.9197 - val_loss: 0.7749 - val_accuracy: 0.7637\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.9274 - val_loss: 0.7307 - val_accuracy: 0.7871\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9327 - val_loss: 0.3265 - val_accuracy: 0.9014\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9397 - val_loss: 0.2988 - val_accuracy: 0.9062\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9462 - val_loss: 0.2931 - val_accuracy: 0.9092\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9455 - val_loss: 0.3127 - val_accuracy: 0.9248\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9514 - val_loss: 0.2791 - val_accuracy: 0.9297\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9564 - val_loss: 0.2920 - val_accuracy: 0.9111\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9562 - val_loss: 0.3285 - val_accuracy: 0.9199\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9609 - val_loss: 0.2865 - val_accuracy: 0.9209\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.9628 - val_loss: 0.2673 - val_accuracy: 0.9307\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1133 - accuracy: 0.9670 - val_loss: 0.2734 - val_accuracy: 0.9326\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9710 - val_loss: 0.4764 - val_accuracy: 0.8828\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9684 - val_loss: 0.2597 - val_accuracy: 0.9326\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.9737 - val_loss: 0.8089 - val_accuracy: 0.8164\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9735 - val_loss: 0.3469 - val_accuracy: 0.9180\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9764 - val_loss: 0.3513 - val_accuracy: 0.9004\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9804 - val_loss: 0.3293 - val_accuracy: 0.9238\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9815 - val_loss: 0.3146 - val_accuracy: 0.9326\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9854 - val_loss: 0.3649 - val_accuracy: 0.9268\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9869 - val_loss: 0.3067 - val_accuracy: 0.9307\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9833 - val_loss: 0.2972 - val_accuracy: 0.9316\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9897 - val_loss: 0.2999 - val_accuracy: 0.9336\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9894 - val_loss: 0.3250 - val_accuracy: 0.9248\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9882 - val_loss: 0.3127 - val_accuracy: 0.9355\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9915 - val_loss: 0.3129 - val_accuracy: 0.9404\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9919 - val_loss: 0.4934 - val_accuracy: 0.8838\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9907 - val_loss: 0.3294 - val_accuracy: 0.9346\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9943 - val_loss: 0.3590 - val_accuracy: 0.9307\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9959 - val_loss: 0.3451 - val_accuracy: 0.9336\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9961 - val_loss: 0.3275 - val_accuracy: 0.9346\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9968 - val_loss: 0.6134 - val_accuracy: 0.8916\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.3614 - val_accuracy: 0.9385\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9978 - val_loss: 0.3679 - val_accuracy: 0.9385\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9975 - val_loss: 0.3645 - val_accuracy: 0.9395\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9742 - val_loss: 0.3220 - val_accuracy: 0.9316\n",
      "Model: \"functional_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "re_lu_104 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_105 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_106 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_107 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_108 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_109 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_110 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_111 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 233,866\n",
      "Trainable params: 233,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.2906 - accuracy: 0.1693 - val_loss: 2.2793 - val_accuracy: 0.2080\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2486 - accuracy: 0.2886 - val_loss: 2.2030 - val_accuracy: 0.3203\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 1.9668 - accuracy: 0.4147 - val_loss: 1.5558 - val_accuracy: 0.4922\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.1752 - accuracy: 0.6009 - val_loss: 1.3066 - val_accuracy: 0.5449\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.7765 - accuracy: 0.7435 - val_loss: 1.0907 - val_accuracy: 0.6494\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.8062 - val_loss: 0.8674 - val_accuracy: 0.7002\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8517 - val_loss: 0.6448 - val_accuracy: 0.8018\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8728 - val_loss: 0.4811 - val_accuracy: 0.8545\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8942 - val_loss: 0.4598 - val_accuracy: 0.8516\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.9061 - val_loss: 0.3606 - val_accuracy: 0.8926\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.9139 - val_loss: 0.4375 - val_accuracy: 0.8594\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.9225 - val_loss: 0.3315 - val_accuracy: 0.9004\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9289 - val_loss: 0.3379 - val_accuracy: 0.9092\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9377 - val_loss: 0.3724 - val_accuracy: 0.8896\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9424 - val_loss: 0.3142 - val_accuracy: 0.9033\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9483 - val_loss: 0.2729 - val_accuracy: 0.9199\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9524 - val_loss: 0.2895 - val_accuracy: 0.9150\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9569 - val_loss: 0.4830 - val_accuracy: 0.8662\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.9566 - val_loss: 0.2751 - val_accuracy: 0.9219\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9618 - val_loss: 0.2806 - val_accuracy: 0.9170\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9633 - val_loss: 0.2385 - val_accuracy: 0.9346\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9708 - val_loss: 0.7613 - val_accuracy: 0.8418\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9716 - val_loss: 0.2360 - val_accuracy: 0.9404\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9750 - val_loss: 0.3822 - val_accuracy: 0.8984\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9789 - val_loss: 0.2173 - val_accuracy: 0.9463\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9815 - val_loss: 0.3103 - val_accuracy: 0.9238\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9809 - val_loss: 0.2418 - val_accuracy: 0.9395\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9834 - val_loss: 0.2145 - val_accuracy: 0.9531\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9851 - val_loss: 0.2329 - val_accuracy: 0.9482\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9850 - val_loss: 0.2483 - val_accuracy: 0.9404\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9879 - val_loss: 0.3712 - val_accuracy: 0.9121\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9902 - val_loss: 0.2303 - val_accuracy: 0.9453\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9918 - val_loss: 0.2658 - val_accuracy: 0.9346\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9934 - val_loss: 0.2457 - val_accuracy: 0.9424\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9719 - val_loss: 0.3392 - val_accuracy: 0.9150\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9930 - val_loss: 0.2796 - val_accuracy: 0.9375\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9951 - val_loss: 0.2523 - val_accuracy: 0.9424\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9962 - val_loss: 0.2456 - val_accuracy: 0.9482\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9962 - val_loss: 0.2527 - val_accuracy: 0.9453\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9978 - val_loss: 0.2402 - val_accuracy: 0.9512\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.9980 - val_loss: 0.2384 - val_accuracy: 0.9512\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9986 - val_loss: 0.2566 - val_accuracy: 0.9482\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9984 - val_loss: 0.2538 - val_accuracy: 0.9473\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.2633 - val_accuracy: 0.9453\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9987 - val_loss: 0.2679 - val_accuracy: 0.9492\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9987 - val_loss: 0.2737 - val_accuracy: 0.9463\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.2751 - val_accuracy: 0.9502\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.2817 - val_accuracy: 0.9502\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.2873 - val_accuracy: 0.9492\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9997 - val_loss: 0.3009 - val_accuracy: 0.9482\n",
      "Model: \"functional_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "re_lu_112 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_113 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_114 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_115 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_116 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_117 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_118 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_119 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 729,866\n",
      "Trainable params: 729,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.2937 - accuracy: 0.1690 - val_loss: 2.2840 - val_accuracy: 0.2373\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2594 - accuracy: 0.3405 - val_loss: 2.2247 - val_accuracy: 0.3799\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 2.0382 - accuracy: 0.4519 - val_loss: 1.6499 - val_accuracy: 0.5049\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.1436 - accuracy: 0.6504 - val_loss: 0.8184 - val_accuracy: 0.7432\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.7722 - val_loss: 0.6477 - val_accuracy: 0.7988\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.8465 - val_loss: 0.6478 - val_accuracy: 0.7910\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8713 - val_loss: 0.4944 - val_accuracy: 0.8428\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8898 - val_loss: 0.4022 - val_accuracy: 0.8682\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.9084 - val_loss: 0.4135 - val_accuracy: 0.8740\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.9187 - val_loss: 0.3834 - val_accuracy: 0.8857\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.9251 - val_loss: 0.4113 - val_accuracy: 0.8818\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9326 - val_loss: 0.3013 - val_accuracy: 0.9072\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9416 - val_loss: 0.7250 - val_accuracy: 0.7764\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9457 - val_loss: 0.2918 - val_accuracy: 0.9131\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1573 - accuracy: 0.9540 - val_loss: 0.2261 - val_accuracy: 0.9375\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9560 - val_loss: 0.2352 - val_accuracy: 0.9268\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.9656 - val_loss: 0.2198 - val_accuracy: 0.9375\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9662 - val_loss: 0.2308 - val_accuracy: 0.9297\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.9683 - val_loss: 1.4818 - val_accuracy: 0.6738\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9696 - val_loss: 0.3413 - val_accuracy: 0.9043\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.9762 - val_loss: 0.2378 - val_accuracy: 0.9346\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.9784 - val_loss: 0.2874 - val_accuracy: 0.9150\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9819 - val_loss: 0.1945 - val_accuracy: 0.9482\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9831 - val_loss: 0.2002 - val_accuracy: 0.9463\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9865 - val_loss: 0.2794 - val_accuracy: 0.9219\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9874 - val_loss: 0.2088 - val_accuracy: 0.9463\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9882 - val_loss: 0.2159 - val_accuracy: 0.9404\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9898 - val_loss: 0.1881 - val_accuracy: 0.9541\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9902 - val_loss: 0.1925 - val_accuracy: 0.9551\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9937 - val_loss: 0.2087 - val_accuracy: 0.9424\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9941 - val_loss: 0.2113 - val_accuracy: 0.9473\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9960 - val_loss: 0.2151 - val_accuracy: 0.9443\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9962 - val_loss: 0.1960 - val_accuracy: 0.9551\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9970 - val_loss: 0.1968 - val_accuracy: 0.9531\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 0.2189 - val_accuracy: 0.9473\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9981 - val_loss: 0.9591 - val_accuracy: 0.8076\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9640 - val_loss: 0.1881 - val_accuracy: 0.9482\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9959 - val_loss: 0.1899 - val_accuracy: 0.9531\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9988 - val_loss: 0.4001 - val_accuracy: 0.9004\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.2097 - val_accuracy: 0.9551\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9994 - val_loss: 0.2203 - val_accuracy: 0.9502\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.2111 - val_accuracy: 0.9531\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.2225 - val_accuracy: 0.9531\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.2200 - val_accuracy: 0.9521\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.2229 - val_accuracy: 0.9531\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.2243 - val_accuracy: 0.9541\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.2274 - val_accuracy: 0.9512\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.2383 - val_accuracy: 0.9541\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.2410 - val_accuracy: 0.9541\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.2377 - val_accuracy: 0.9521\n",
      "Model: \"functional_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "re_lu_120 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_121 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_122 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_123 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_124 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_125 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_126 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_127 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,508,298\n",
      "Trainable params: 2,508,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 2.2825 - accuracy: 0.2333 - val_loss: 2.2565 - val_accuracy: 0.4902\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 2.1509 - accuracy: 0.4839 - val_loss: 1.9040 - val_accuracy: 0.5361\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.3109 - accuracy: 0.6573 - val_loss: 0.7944 - val_accuracy: 0.7412\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.7937 - val_loss: 0.6146 - val_accuracy: 0.8018\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.8489 - val_loss: 1.2339 - val_accuracy: 0.5664\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8826 - val_loss: 0.5142 - val_accuracy: 0.8418\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8973 - val_loss: 0.7334 - val_accuracy: 0.7793\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.9126 - val_loss: 0.3417 - val_accuracy: 0.9014\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.9248 - val_loss: 0.3167 - val_accuracy: 0.9141\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.2185 - accuracy: 0.9335 - val_loss: 0.2765 - val_accuracy: 0.9180\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9415 - val_loss: 0.3155 - val_accuracy: 0.9043\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1713 - accuracy: 0.9486 - val_loss: 0.2307 - val_accuracy: 0.9297\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9570 - val_loss: 0.2230 - val_accuracy: 0.9316\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9599 - val_loss: 0.2265 - val_accuracy: 0.9375\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1173 - accuracy: 0.9667 - val_loss: 0.2240 - val_accuracy: 0.9326\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.9698 - val_loss: 0.1983 - val_accuracy: 0.9414\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0943 - accuracy: 0.9722 - val_loss: 0.1979 - val_accuracy: 0.9473\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.9757 - val_loss: 0.1871 - val_accuracy: 0.9473\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9811 - val_loss: 0.1914 - val_accuracy: 0.9482\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9824 - val_loss: 0.2300 - val_accuracy: 0.9365\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9868 - val_loss: 0.3172 - val_accuracy: 0.9160\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9874 - val_loss: 1.3904 - val_accuracy: 0.7061\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9617 - val_loss: 0.1758 - val_accuracy: 0.9512\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9909 - val_loss: 0.1749 - val_accuracy: 0.9531\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9939 - val_loss: 0.1864 - val_accuracy: 0.9492\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9946 - val_loss: 0.1912 - val_accuracy: 0.9502\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9965 - val_loss: 0.1924 - val_accuracy: 0.9492\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9966 - val_loss: 0.2444 - val_accuracy: 0.9414\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9972 - val_loss: 0.2042 - val_accuracy: 0.9541\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9982 - val_loss: 0.2295 - val_accuracy: 0.9463\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 0.2079 - val_accuracy: 0.9551\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9993 - val_loss: 0.2182 - val_accuracy: 0.9521\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9996 - val_loss: 0.2216 - val_accuracy: 0.9502\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.2194 - val_accuracy: 0.9561\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9997 - val_loss: 0.2182 - val_accuracy: 0.9512\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.2258 - val_accuracy: 0.9541\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.2326 - val_accuracy: 0.9531\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.2358 - val_accuracy: 0.9512\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.2506 - val_accuracy: 0.9541\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.2433 - val_accuracy: 0.9561\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.2408 - val_accuracy: 0.9570\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.2443 - val_accuracy: 0.9541\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.2531 - val_accuracy: 0.9551\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9492\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9551\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9512\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9541\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9541\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9541\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9551\n",
      "Model: \"functional_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "re_lu_128 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_129 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_130 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_131 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_132 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_133 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_134 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_135 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 9,210,890\n",
      "Trainable params: 9,210,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 2.2783 - accuracy: 0.3117 - val_loss: 2.2434 - val_accuracy: 0.4375\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 2.0847 - accuracy: 0.4940 - val_loss: 1.7426 - val_accuracy: 0.5322\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.1281 - accuracy: 0.6858 - val_loss: 0.7109 - val_accuracy: 0.8115\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.5845 - accuracy: 0.8234 - val_loss: 0.5029 - val_accuracy: 0.8389\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.4031 - accuracy: 0.8787 - val_loss: 0.4570 - val_accuracy: 0.8691\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8979 - val_loss: 0.3679 - val_accuracy: 0.8916\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.9135 - val_loss: 0.3150 - val_accuracy: 0.9072\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.2461 - accuracy: 0.9257 - val_loss: 0.3220 - val_accuracy: 0.9141\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.2124 - accuracy: 0.9386 - val_loss: 0.4945 - val_accuracy: 0.8311\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.2007 - accuracy: 0.9403 - val_loss: 0.3721 - val_accuracy: 0.8916\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1678 - accuracy: 0.9514 - val_loss: 0.2453 - val_accuracy: 0.9346\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1510 - accuracy: 0.9554 - val_loss: 0.2623 - val_accuracy: 0.9219\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1384 - accuracy: 0.9601 - val_loss: 0.2154 - val_accuracy: 0.9385\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1173 - accuracy: 0.9693 - val_loss: 0.2369 - val_accuracy: 0.9307\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1060 - accuracy: 0.9708 - val_loss: 0.2633 - val_accuracy: 0.9287\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0882 - accuracy: 0.9771 - val_loss: 0.3383 - val_accuracy: 0.9111\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9767 - val_loss: 0.2175 - val_accuracy: 0.9365\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0696 - accuracy: 0.9807 - val_loss: 0.2020 - val_accuracy: 0.9482\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9839 - val_loss: 0.1893 - val_accuracy: 0.9502\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0501 - accuracy: 0.9878 - val_loss: 0.1920 - val_accuracy: 0.9521\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0429 - accuracy: 0.9903 - val_loss: 0.1891 - val_accuracy: 0.9463\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0381 - accuracy: 0.9909 - val_loss: 0.1902 - val_accuracy: 0.9482\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.9932 - val_loss: 0.1932 - val_accuracy: 0.9482\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0269 - accuracy: 0.9946 - val_loss: 0.2981 - val_accuracy: 0.9336\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0228 - accuracy: 0.9959 - val_loss: 0.1936 - val_accuracy: 0.9502\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9973 - val_loss: 0.1964 - val_accuracy: 0.9482\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1422 - accuracy: 0.9767 - val_loss: 0.1980 - val_accuracy: 0.9453\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9924 - val_loss: 0.1884 - val_accuracy: 0.9502\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0190 - accuracy: 0.9977 - val_loss: 0.1907 - val_accuracy: 0.9541\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0131 - accuracy: 0.9989 - val_loss: 0.1929 - val_accuracy: 0.9482\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9991 - val_loss: 0.1874 - val_accuracy: 0.9551\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9995 - val_loss: 0.1975 - val_accuracy: 0.9531\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9998 - val_loss: 0.1958 - val_accuracy: 0.9551\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9998 - val_loss: 0.2104 - val_accuracy: 0.9541\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.2013 - val_accuracy: 0.9551\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 0.2048 - val_accuracy: 0.9561\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.2087 - val_accuracy: 0.9570\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 0.2104 - val_accuracy: 0.9541\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.2142 - val_accuracy: 0.9531\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.2178 - val_accuracy: 0.9570\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.2165 - val_accuracy: 0.9541\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.2229 - val_accuracy: 0.9521\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.2199 - val_accuracy: 0.9551\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.2421 - val_accuracy: 0.9443\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.2233 - val_accuracy: 0.9541\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.2321 - val_accuracy: 0.9521\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.2275 - val_accuracy: 0.9541\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9521\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9541\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9541\n",
      "Model: \"functional_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 2048)              1607680   \n",
      "_________________________________________________________________\n",
      "re_lu_136 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_137 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_138 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_139 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_140 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_141 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_142 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_143 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 35,198,986\n",
      "Trainable params: 35,198,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 15ms/step - loss: 2.2653 - accuracy: 0.2859 - val_loss: 2.2027 - val_accuracy: 0.5049\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.8275 - accuracy: 0.5903 - val_loss: 1.1572 - val_accuracy: 0.6289\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.7908 - accuracy: 0.7653 - val_loss: 0.9071 - val_accuracy: 0.6836\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4946 - accuracy: 0.8516 - val_loss: 0.4348 - val_accuracy: 0.8672\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3763 - accuracy: 0.8866 - val_loss: 0.3917 - val_accuracy: 0.8838\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3018 - accuracy: 0.9097 - val_loss: 0.3094 - val_accuracy: 0.9131\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2489 - accuracy: 0.9258 - val_loss: 0.4694 - val_accuracy: 0.8691\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2192 - accuracy: 0.9344 - val_loss: 0.5085 - val_accuracy: 0.8447\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1880 - accuracy: 0.9451 - val_loss: 0.3480 - val_accuracy: 0.8955\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1640 - accuracy: 0.9527 - val_loss: 0.3463 - val_accuracy: 0.8906\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1425 - accuracy: 0.9564 - val_loss: 0.3739 - val_accuracy: 0.8838\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1205 - accuracy: 0.9670 - val_loss: 0.2110 - val_accuracy: 0.9375\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1505 - accuracy: 0.9606 - val_loss: 0.2134 - val_accuracy: 0.9365\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0989 - accuracy: 0.9741 - val_loss: 0.2885 - val_accuracy: 0.9150\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0825 - accuracy: 0.9779 - val_loss: 0.1876 - val_accuracy: 0.9492\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0698 - accuracy: 0.9824 - val_loss: 0.5365 - val_accuracy: 0.8672\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0657 - accuracy: 0.9842 - val_loss: 0.1647 - val_accuracy: 0.9590\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0537 - accuracy: 0.9858 - val_loss: 0.1708 - val_accuracy: 0.9561\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0453 - accuracy: 0.9895 - val_loss: 0.1747 - val_accuracy: 0.9541\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0377 - accuracy: 0.9918 - val_loss: 0.1770 - val_accuracy: 0.9492\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9928 - val_loss: 0.1668 - val_accuracy: 0.9561\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0240 - accuracy: 0.9956 - val_loss: 0.1913 - val_accuracy: 0.9463\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0215 - accuracy: 0.9959 - val_loss: 0.1715 - val_accuracy: 0.9619\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0171 - accuracy: 0.9973 - val_loss: 0.1976 - val_accuracy: 0.9609\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0143 - accuracy: 0.9985 - val_loss: 0.1886 - val_accuracy: 0.9600\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0107 - accuracy: 0.9989 - val_loss: 0.1852 - val_accuracy: 0.9561\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0091 - accuracy: 0.9994 - val_loss: 0.1728 - val_accuracy: 0.9639\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0081 - accuracy: 0.9996 - val_loss: 0.1804 - val_accuracy: 0.9580\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0068 - accuracy: 0.9997 - val_loss: 0.1854 - val_accuracy: 0.9590\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 0.1863 - val_accuracy: 0.9600\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.1964 - val_accuracy: 0.9580\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 0.9998 - val_loss: 0.2188 - val_accuracy: 0.9531\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.1860 - val_accuracy: 0.9639\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.1891 - val_accuracy: 0.9590\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.1899 - val_accuracy: 0.9619\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.2029 - val_accuracy: 0.9541\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.2041 - val_accuracy: 0.9561\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.2001 - val_accuracy: 0.9580\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9561\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9570\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9570\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9561\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9590\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9580\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9561\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9561\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9590\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9551\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9570\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9570\n"
     ]
    }
   ],
   "source": [
    "# for multi in width_tick:\n",
    "#     img_input = layers.Input(shape=(28*28,))\n",
    "#     x = layers.Dense(width * multi)(img_input)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.Flatten()(x)\n",
    "#     out = layers.Dense(10)(x)\n",
    "    \n",
    "#     model = tf.keras.Model(img_input, out)\n",
    "#     model.summary()\n",
    "#     model.compile(optimizer='sgd',\n",
    "#               loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "#     model.fit(x=train_ds, validation_data=valid_ds, epochs=50)\n",
    "#     model.save_weights('./dense_10_weights/dense_10_with_multi_%s'%(str(multi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "100%|| 10000/10000 [56:53<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "100%|| 10000/10000 [58:11<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "100%|| 10000/10000 [57:48<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "100%|| 10000/10000 [1:13:34<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "100%|| 10000/10000 [1:14:33<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "100%|| 10000/10000 [1:14:34<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "100%|| 10000/10000 [1:49:31<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for multi in width_tick:\n",
    "    img_input = layers.Input(shape=(28*28,))\n",
    "    x = layers.Dense(width * multi)(img_input)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    out = layers.Dense(10)(x)\n",
    "    \n",
    "    model = tf.keras.Model(img_input, out)\n",
    "    model.load_weights('./dense_10_weights/dense_10_with_multi_%s'%(str(multi)))\n",
    "    \n",
    "    @tf.function\n",
    "    def get_cross_entropy_hessian(y, x):\n",
    "        y_pred = model(x)\n",
    "        cross_en = loss(y, y_pred)\n",
    "        return tf.hessians(cross_en, x)\n",
    "\n",
    "    hessians = 0\n",
    "    for x, y in zip(tqdm(x_test), y_test):\n",
    "        x_tensor = tf.convert_to_tensor(x.reshape(-1, 28*28))\n",
    "        y_tensor = tf.convert_to_tensor(y.reshape(-1, class_num))\n",
    "        hs = get_cross_entropy_hessian(y_tensor, x_tensor)\n",
    "        hs = tf.reshape(hs, (784, 784))\n",
    "        hessians += hs\n",
    "        \n",
    "    onp.save('./dense_10_hessians/dense_10_hessians_with_multi_%s'%(str(multi)), hessians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian = {\n",
    "    i : onp.load('./conv_10_hessians/conv_10_hessians_with_multi_%s.npy'%(str(i))) for i in [1,2,4,8,16]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return onp.allclose(a, a.T, rtol=rtol, atol=atol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paper_plot as pt\n",
    "width = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = []\n",
    "line_lables = []\n",
    "for k, v in hessian.items():\n",
    "    val, vec = onp.linalg.eigh(v)\n",
    "    vals.append(val[:-101:-1])\n",
    "    line_lables.append(\"width = %s\"%(str(k*width)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<paper_plot.FigureBuilder at 0x7feef5df2828>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoEAAAEECAYAAABXxu5OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd1RU59bA4d/MUIcuRVBQURFUVFDAhhhr7F1jiUYTjb0kliQmxhaTmEQTW0xsyY0aY+8lXjvWgGIHC4oiIlKlydDm+4PvcsPVYGecYT9rsZac8p79cs5s95zyHoVWq9UihBBCCCFKFaWuAxBCCCGEECVPikAhhBBCiFJIikAhhBBCiFJIikAhhBBCiFJIikAhhBBCiFJIikAhhBBCiFJIikAhhBBCiFJIikAhhBBCiFJIikAhhBBCiFJIikAhhBBCiFJIikAhhBBCiFKoVBSBvr6+REdHP3bepk2b6NOnzz+ue+rUKYKCgl5VaOIlk31dusj+Fn8nx4P4DzkWnk6pKALDwsJwc3N7qmU9PT25devWK47oURMmTCAwMJC6devy5ptvsn79+sJ5Z8+eZdCgQQQEBNCgQQPGjBnD/fv3SzxGfaAP+xpg586dtG3bFh8fH1q2bEloaOgjyyxcuBBPT0+OHz+ugwj1gz7s71WrVtGtWze8vb35+OOPi8x70mc7Ozubzz//nEaNGhEQEMCwYcOIi4sr6S7ojdf9eMjOzmby5Mk0a9YMX19fOnfuzOHDhwvn37lzB09PT3x9fQt/Fi1aVKSN48eP07VrV3x8fAgKCmLXrl0l2gd98bofCwD9+/enVq1ahfv6zTffLJx3//59hg0bRmBgIJ6enty5c6fIurNnz6Z169b4+vrSpk0btmzZ8lwxGL1QD8RLM3ToUL788ktMTEyIjIxkwIABVK9eHW9vbx48eECvXr1o0qQJKpWKGTNm8Mknn7B8+XJdhy2ew7Fjx/juu+/4/vvvqV27NvHx8Y8sc/v2bf78808cHR11EKF4mZycnBgxYgTBwcFoNJoi85702f7Xv/7F2bNn2bZtG1ZWVkyZMoWZM2eycOFCXXRFvKDc3FxcXFxYuXIl5cqV4/Dhw4wbN47t27fj6upauFxISAhGRo/+93z9+nXGjx/P119/TePGjUlLSyMtLa0kuyBess8//5yePXs+Ml2pVNKkSROGDh1K7969H5lvbm7O4sWLcXd358KFCwwePJgKFSpQt27dZ9q+3p4J3LhxI8OGDSv8vXXr1owZM6bw96ZNmxIeHg4UrfKTk5MZNmwYdevWpUePHty+fbtwnX79+gHQuXNnfH19i3zDWrFiBQ0bNiQwMJCNGze+9P54eHhgYmICgEKhQKFQFMbWtGlT2rZti6WlJebm5rz99tucOXPmpcfwujK0fb1gwQJGjBiBj48PSqWSsmXLUrZs2SLLTJ8+nQkTJhQeE6WJoe3v1q1b07JlS2xtbR+Z96TP9p07dwgMDMTBwQFTU1PatWvHtWvXXnqMrzNDOh7UajWjR4/G1dUVpVJJs2bNcHV15dKlS0+1/uLFi3nrrbdo2rQpRkZG2NnZUaFChZca4+vMkI6FJ3FwcKBfv37UqlXrsfPHjBlDlSpVUCqV1KlTh3r16nH27Nln3s4znQncePoO60Iff439Zenl50b3eq5PXC4gIICvvvqK/Px84uPjycnJKfwDREdHk5mZiaen5yPrzZgxA1NTU44ePcqdO3d47733Cr+BrV69Gk9PT7Zu3UrFihWBgnsDEhISSEtL48iRIxw/fpwxY8bQsmVLbGxsHml/2rRp7Nix47Exu7i4sH379n/s07Rp09i8eTNZWVnUqFGDpk2bPna5kJAQPDw8iv8DvQxn10DYqle7Dd+3weef780Aw9rXeXl5XLx4kebNm9OqVSs0Gg0tW7Zk0qRJmJmZAbB7925MTEz+cf+/Ktsit7H52uZXuo2uHl3pVKVTscsY0v5+Vv/72e7RowezZs0iLi4Oa2trtm/fXiL3KqVs2cKDjZte6TZsunfDtkuXJy5nyMdDQkICUVFRVK1atcj0Zs2aoVAoaNy4MRMnTqRMmTJAwe0Dbm5udOzYkeTkZBo0aMBnn3322C8YL1PEyVjCj8W+0m1Ub+yCVwOXYpcxxGNhzpw5fPfdd7i7u/PBBx9Qv379Yv8Gj5OVlcXFixfp27fvM6+rt5eD3dzcsLCwIDw8nKioKAIDAwkPDycyMpKzZ89Sr149lMqiJzrz8vLYu3cv27ZtQ61WU61aNbp27UpISEix2zIyMmLkyJEYGRnRtGlT1Go1N2/exMfH55Flp02bxrRp056rT9OmTWPKlCmEhYXx119/PfYsUEREBD/++CM//vjjc21DHxnSvk5ISCAnJ4c9e/awevVqjIyMGDFiBIsXL+aDDz4gPT2d77//nhUrVjxTu4bEkPb3s3jcZ7tSpUq4uLgQFBSESqWiWrVqTJky5ZXF8Doy1OMhJyeHCRMm0LVrV6pUqQKAnZ0dGzZsoHr16qSkpDBjxgwmTpxYeHtAXFwc27ZtY/ny5Tg5OfHxxx8zc+ZM5syZ89xx6BNDOxYmTJhAlSpVMDExYefOnQwbNoytW7c+89ndqVOn4unpSZMmTZ45hmcqArvXc32qs3Qlxd/fn7/++otbt27h7++PlZUVISEhnD17loCAgEeWT0pKKrwn4z/KlSv3xO3Y2toWuT/D3NyczMzMl9OJ/6FSqfDz82Pbtm2sWbOGAQMGFM67desWQ4YMYfLkyfj5+b2S7Rfh0+eJZ+lKiqHs6/+c7evfvz9OTk4ADBo0qLAIXLhwIZ06dSpyf1BJ6VSl0xPP0pUUQ9nfT+ufPtvTp08nOzubU6dOoVarWbp0KUOGDCny4NirYNuly1OdpSsphnY85OfnM2nSJIyNjYsU9RYWFoWX/xwcHJgyZQqBgYGkp6djaWmJqakp3bp1w93dHSi4l3zQoEEvPb7/5dXgyWfpSoohHQt16tQp/HfXrl3ZsWMHhw8fpn///k/dxuzZs7l27Rq//fYbCoXimWPQ2zOBUHBq+MCBA8TExDBs2LDCyyVhYWGF1/n/rkyZMhgZGREbG1v4zSs29uWe4v7888//8dRvuXLl2Llz51O1k5eXV+S+hZiYGAYNGsSIESPo8hol55JiKPvaxsYGZ2fnIh/Wv//7xIkT3Lt3jzVr1gAFCWzcuHEMHjyY999//6XG/zozlP39NIr7bEdERDBu3LjCy339+/dn/vz5JCUlFV4iLA0M6XjQarV8+umnJCQksHTpUoyNjf9xG//JDVqtFuCRS53P85++vjOkY+F/KRSKwn39NObPn09wcDArV67E0tLyqdf7O719MAQKvhGcOnWKrKwsnJ2d8fPzIzg4mJSUFGrUqPHI8iqVilatWrFw4UIePnzI9evX2by56D1QDg4O/zi20NOYMWMGYWFhj/35pwMhMTGRnTt3kpGRQV5eHsHBwezcuZOGDRsCBZcA3nnnHfr161fs2EaGzFD2NUC3bt1YuXIliYmJPHjwgF9//ZU33ngDgF9//ZUdO3awZcsWtmzZgpOTE9OnT39scjNkhrS/c3Nz0Wg05Ofnk5eXh0ajITc3F3jyZ7tWrVps3bqVtLQ0cnJy+P3333FycipVBSAY1vEwdepUIiMj+emnnwqvDPzHuXPnuHHjBvn5+SQnJ/PFF18QEBCAlZUVUJA7Nm3aRHR0NA8fPmTJkiWFuaO0MJRjITU1tXDEgNzcXLZt20ZoaGiRS7oajYbs7GygYHihv48u8PPPP7Njxw5++eUX7Ozsnjt2vT4T6O7ujoWFReHlE0tLS1xdXSlTpgwqleqx63z++ed88sknNG7cmMqVK9OtWzdOnTpVOH/UqFF8/PHHZGVlMWPGDOzt7V95PxQKBWvWrGHq1Knk5+dTvnx5Jk+eTIsWLQBYv3490dHRLFy4sMjQEGFhYa88tteFoexrgBEjRpCcnMybb76Jqakpbdu2Zfjw4QCPfJhVKhU2NjZYWFiUSGyvC0Pa34sXLy7yud22bRujRo1i9OjRT/xsT5o0iS+++ILWrVuTk5ODh4fHI+PGlQaGcjzExMSwdu1aTExMCAwMLJw+ffp0OnXqRHR0NHPnziUpKQlLS0saNWrE3LlzC5fr0aMHd+/eLRxSpEmTJnz22WevPO7XiaEcC7m5ufzwww/cuHEDlUpF5cqVWbRoUeGlfoDatWsX/rtt27YAXLlyBYC5c+dibGxM69atC5cZOnRokaenn4ZC+yznHoUQQgghhEHQ68vBQgghhBDi+UgRKIQQQghRCkkRKIQQQghRCkkRKIQQQghRCkkRKIQQQghRCkkRKIQQQghRCkkRKIQQQghRCkkRKIQQQghRCkkRKIQQQghRCkkRKIQQQghRCkkRKIQQQghRCkkRKIQQQghRCkkRKIQQQghRCkkRKIQQQghRChnpOgAhnkZ13+p4VvJEqZDvLUII8bRiYmI4deqUrsMQrykpAoVe0Fpr6TKzCwO9B+o6FCGE0BvdunXTdQjiNSanVYReqJCgYP2FVeTm5+o6FCGEEMIgSBEo9IJRbj5lwmPZd3ufrkMRQgghDIIUgUI/KJUE3bZg5eWVuo5ECCGEMAhSBAq9oLKwwP+GkvP3z3Eu/pyuwxFCCCH0nhSBQi8orawwvf8Aj1QLVl1epetwhBBCCL0nRaDQC0pLSwDeTvHi37f+zd30uzqOSAghhNBvUgQKvaAwNsbUw4Na13JQKVSMOTCGhIcJug5LCCGE0FtSBAq9Ydk0iNyzF1lQ/xtupd5i0J5BxKbH6josIYQQQi9JESj0hmXTppCTg3dUHktaLyHhYQID9gwg6kGUrkMTQggh9I4UgUJvmPv4oLSyIv3IEXydfFnx5gqy87J5e/fbHL97XNfhCSGEEHpFikChNxTGxlg0bkzG4SNotVqq21dnZduVOJo7MnzfcFZcXIFWq9V1mEIIIYRekCJQ6BXLoCBy4+PRhIcDUMG6AqvbraZlhZZ8f/p7Jh6ZSE5+jo6jFEIIIV5/UgQKvXDvQRbLgm8QWtYTVCoebN9eOE9trOa7pt8xxncMf0b9ydqItTqMVAghhNAPUgQKvZCUmc0XO8MZvP0mB11qE/v7WpLjkwvnKxQKBtcaTAOXBiw+t5gHmgc6jFYIIYR4/UkRKPRCDRdrwqa0YuvIxli+PQBTzUMWjJ/D5buphcsoFAom+E0gLTuNn8//rMNohRBCiNefFIGixCUkJNC7d2/efvttBgwYwP37959qPTsLE+q42TJgYBvyavnS7NIBui88wrqQ6MIHQjzLeNLNoxtrItZwK/XWq+yGEEIIodekCBQlzs7Ojt9//51Vq1bRpUsXNmzY8MxtVBw+BIeMZPplRTJp43lG/n6GlMxsAEb5jsJEacL3p79/2aELIYQQBkOKQFHiVCoVSmXBoZeRkYGHh8cT10mITmfL3DOE7ori3s0HWDQNwsTdnb63gpn0ZjX2XoqjzQ/BHLuegIO5A4NrDWb/7f1suLqBzJzMV90lIYQQQu9IESie26pVq+jWrRve3t58/PHHRealpKQwcuRIfHx8aNasGdv/9jQvQHh4OD179mTVqlXUqFHjidsyszQmKzOXU9tusHH2aQ78dgXb/u+guXSJdyyS2TyiMWpTFf2WneLTzRfoWrk3VWyqMP3EdJr80YQR+0awLXKbDB8jhBBC/D/VtGnTpuk6CKGf7t27R0BAABYWFuTl5dGyZcvCeZMnT0apVLJ69Wp8fX2ZMGECzZs3x97eHgBHR0d69eqFvb09W7dupVmzZsVua/O2jcxc9CG1mpZHaaTgwqEYMmzcKHPtMFmnT1Oxvg99O/jxMDuflSdvsf1cHJMaD6R3reaojdWE3Q9jy/Ut7LixA7Wxmqp2VVEpVK/07yOEELq2du1a3nrrLV2HIV5TciZQPLfWrVvTsmVLbG1ti0zPzMxk7969jB07FgsLC/z8/GjevDlbt24FIDs7u3BZKysrzM3Nn7yx9DjQpGFuZUKDzlUI7OnBzfNJhLeaiiYhhajefUgcM5qJ7lo2DW2AlZkR7/8WxqLdWpo7DWF3t90sarEIW1Nbph6fSsfNHdl3a5+8YUQIIUSpZaTrAIThiYqKQqVS4e7uXjjNy8uLkJAQACIiIpg9ezZKpRJTU1O+/PLLJzeaFgtLmkGv36BsDeq0cMPYVMXB1REkNZyBRX4aRneuoh6/ArfEkyyu4Mxtq7IsyahNzyvxBFQqw7hWNVjTfg3BMcHMOzOPDw59QJBrEJ8EfIKrleur+nMIIYQQryUpAsVLl5mZiaWlZZFpVlZWZGRkAFC7dm1Wr179bI3aV4Wsm7C0OXSYCz59qRFYDrWNCZFn7pOWZEWauS33E2tzr2or6miOUv7yQT5/cISoHu8yI6k2by87xcK+dWlXK4hG5RqxOnw1i84uouvWrkz0n0gvz14v608ghBBCvPakCBQvnVqtJj09vci09PR0LCwsnr9RE0sYdhQ2vgdbhsPxBVC9E5VqdKLSgBqgUABw/1Yq+365zMl7zfEe3puKp5ZRae1S/mjblo/dOzL2jzDMTVQ083TinZrv8GalN5l2fBozT85EoVDQs1rPF+m6EEIIoTfknkDx0lWqVIm8vDyioqIKp0VERFC1atUXa9iqLPTfAu3ngJktHJ4NixvB3Bqwpg8c/AqnnBB6feJHneZuXDx2nxOOfTAdPonMPXuYsWcOrfPvMWzlaU7eSATA2cKZBc0X0KR8E2aemMn2yO1PCEIIIYQwDFIEiueWm5uLRqMhPz+fvLw8NBoNubm5qNVqWrVqxfz588nMzOT06dPs37+fzp07v/hGVUbgPxje3Q3jr0D7uVCpMSRGFhSFq7phdHg6gT2r0nFMHTLTstl3ozJ5n/0EWZmM2vwtH59fzwc/HeTr3RGcvpWMSmHE3Dfm4u/sz5RjU9h3a9+LxymEEEK85hRaeTxSPKcFCxawcOHCItNGjRrF6NGjSUlJYfLkyRw/fhxbW1vGjx9Px44dn3tb3bp1Y9OmTcUvpEmHf38Oocuh0RhoNYP0FA1/Lr3EvRsP8A4sS7XYvaT8uoKHxqYsqdGePW7+OFiZMraFB939nHj/3+9zIeECbSq1YWidoVS2qfzcMQshhK49Ve4UpZYUgUIvPHUi02ph5/gihWBevpYTmyM5ty8axwpWNGttReYPs8gMDSWjVl2WBbzFn0kqVr9Xn9oVzFhyfgl/XPmDrNws2ri3YbTvaNys3F59J4UQ4iWTIlAURy4HC8OiUBTcM+j3HhyfD+v6o0qOJLCHB22H1SI14SFbVsWRPe5bnKdNxerGFcatnsaguBDG/hHGQ40xH/p9yJ7uexjkPYhD0YfourUryy4sIydP3jYihBDCcEgRKAzPfwrB5p/B9QOwKAC2jqRypSx6feqPnYsFe5dd5lRqTRxXbUId4EfP42sZ++8f+WzFIfLztZQxK8MH9T5ge5ftBLkGMe/MPHrt6MXZ+2d13TshhBDipZAiUBgmhQKCJsLYc1B/OJxfD4vqYx27i64T6lK/kzu3LiSy7scb3Ov4MfafTsE36QaDln/Kuvn/HcOwrEVZ5r4xlwXNF5CRk8GgPYPYcn2LDjsmhBBCvBxSBArDZukIbb6E0afBuRZseBfV3sn4tS5P3+kNcK/jQMjOKLaFuRI7fAnJ5X2o/dOXhLw/hryUlMJm3nB7g42dNhY+QTz/zHzytfk67JgQQgjxYqQIFKWDrRsM3AENRsCpxfCvDlipEnlzsDfdJtSlUi0HIq9kcaNiXw4GzSbzYgwRbdqT+u9/FzZhZWLFopaL6O7RnaUXljLpyCRSs1N12CkhhBDi+ckbQ0TpoTKGNl+Bqz9sHQU/N4FuS3Gp2gKXqrYEZeVy81wCf+28yUXlSCwTz5I/bhI2DerhMGokal9fjJXGTG04lYrWFfn+9PecjD3J0NpD6e3ZG2OVsa57KIQQQjw1GSJG6IWXPsxB/FVY/w7cDy+4d/CNj0GpAiA3J4/Dm64TfvAOefka6l77DYfYc6gDA3EaNw5z75oAXEm6wtzTczl+9ziulq68WelN7M3tsTezx8POAw87j5cXrxBCPAcZIkYUR4pAoRdeSSLLzoRdE+DsaqjQCLr8CGXcC2dfvBDPziUXMM/RkpB6lvaX1qDOy8b++3mUa9WscLljMcdYELaAK8lXyM3PBUCBgjF1x/Ce93so/v+9xkIIUdKkCBTFkSJQ6IVXmsjO/g67P4L8PGg9o2CMwf8v3LIyctiy8CyJN9NIraCi1tYZuKXdJ+mTWTTr36lIM1qtltTsVBIeJvDTuZ/YE7WHtu5tmd5oOuZG5q8mdiGEKIYUgaI48mCIED59YfhxcAsoeNvIyq6QGguAmYUxPT+sh4efE9a388jpP5s4ezfKfPUps6f/QnJGdmEzCoUCG1MbqthW4Zugbxhbdyx7bu7hnd3vsOHqBkLvhZL4MBH53iWEEOJ1IGcChV4okW+zWi2EroC9n4GRWcHlYc+2BbPytZzadoPTe25h42hK+bDl2N/4i+112tJy2ofU93R5bJOHow/z6bFPeaB5UDjN086Tif4Tqe9S/9X2RwhR6smZQFEcKQKFXijRRBZ/FTa+C/cugP8QaD0TjAsu50ZHJHHgX+FkPtBQIecilY7+TKy6DLH9h9NndG+MVI+eXM/X5hObEUvUgyiup1xnTcQaYtJjaO7WnAl+E3CzlvcSCyFeDSkCRXGkCBR6ocQTWa4G9s+AEwuhrDf0WAGOnkDBfYJH/rjKtZA4HB2h7NH5OMVe4Yp9Ja75BqFt2oIGddwJqub42KY1eRp+u/QbSy8sRZOnoZZDLQLLB9LEtQk1ytSQB0mEEC+NFIGiOFIECr2gs0R2bR9sHgo5mdDuW/DpV/jQyJWTsRxecxWlSkF56yhsD6zE9v4dcpQqzjtUoXyVCtTwcsPIwQGbrl0wKlOmSNP3M++z/up6gu8EcynxEgAtKrRgdtBsTFWmJd5VIYThkSJQFEeKQKEXdJrIUmNh8/tw80jBUDLOtcC+Cjh6kqKux94VEcTfTqOqnxPeHrlwZAeR+4/CgxTK5D5ElZONkbMzrvPnYV679mM3kfgwkU3XNjE/bD71ytZjfvP5WJtYl3BHhRCGRopAURwpAoVe0Hkiy8+D4/Ph4iZIugHZ6QXTHTzJa/IxoVF1OHfgDjmaPCrVdsCnVQXmnoliY1gMn1SBFn98T+79+5Sd8hl2vXr942Z239zN5KOTcbdx56eWP+GkdiqhDgohDJHOc6d4rUkRKPTCa5XItFrIiIeoYDj8LcSHg1MNsmoO5MLdWpwLzUWTkYtjBSuuWsMv0fcJcFAxIXQ16nOhWHfqSNmPPsLI3v6xzZ+4e4JxB8dhbmTO8DrD6VatG8ZKeSWdEOLZvVa5U7x2ZJxAIZ6VQgGWTuDdHYYfg+7LQZuP2cFJ+F9pywDbAQRVO0ludi52F9MYr7HANsmE/hV6scOnHQ927iKybTuS16xBm5f3SPMNyzXkt7a/UdG6Il+c+oLOWzqz68YuGV9QCCHESyVnAoVe0Itvsw/uQPQpiDoGocvR1nqLOzW+4vyBO0RdSERhrCTSGi4k3+Lz6J3YX7uAmbc3bot/xMjx0SeJtVotwTHBzDszj6vJV+lZrSefNfgMpUK+uwkhno5e5E6hM0a6DkAIg2HjWvDj3R2snFEcnIVbuTq4jRxJwp10zvx5C0LjcNe6sbPCEMpXS6BJ8M/cHjyEir/9C5WNTZHmFAoFQa5BBJYPZP6Z+Sy/uJys3CxmNJ6BkVI+ukIIIV6MnFIQ4lVoMgGqdyx4+0jkQRxcLWn9Xk36zWhAQIdKlLcwQ5FRluC6U7iYV5Pwd4eTnZb+2KaUCiXj6o1jtO9ott/YzqQjk8jJyynhDgkhhDA0cjlYlLjz588za9YsjIyMKFu2LLNnz8bYuPgHH/TykoYmDZa1grTYgvsGq7YoHGMQYN2BGxzdcQPPTCVmDxMwig/m6sCBjGlTk7LWZo9tcuXllXwT8g1l1WVp4NKA+i71aeDSAEf14wemFkKUbnqZO0WJkSJQlLj79+9jbW2NmZkZc+bMoWbNmrRp06bYdfQ2kSXdgF87QuodcKwODUeAdw8wUQMF9/2dCb3HmZXnyc42xvjBFX51c6FLcy+GNq2CjfmjxfH+2/vZeWMnIfdCSNGkYKw0ZrzfePp69ZW3jQghitDb3ClKhNxYJEqck9N/x74zNjZGqTTguxLKVIYxYXBpU8Er6LaNhu3jwL4qOHujKFuTes518JlRh+NLTnPxemX6J+dzfEc4rULv8NOAetStYFekyRYVWtCiQgvytflcTb7KorBFfP3X15yKPcXMxjOxMbX5h2CEEEKI/zLg/33Fq7Zq1Sq6deuGt7c3H3/8cZF5KSkpjBw5Eh8fH5o1a8b27dsfWT8mJoZjx47RrFmzkgpZN4xMoE5vGBoM7+yAJuML3jgSHVLwfuLV3VH94EkT1Xg6172AbfotGuTa0ONuNhN+OMT6kNuPbVapUOJVxov5zeczyX8SwTHB9Njeg4O3D8pwMkIIIZ5IzgSK5+bk5MSIESMIDg5Go9EUmTdjxgyMjY05duwY4eHhDB06FC8vLzw8PABIT09n0qRJfPXVV0+8H9BgKBTg3qTg5z8epsC9C3DvPFzaTLmYL+ky8HtCFm4kwrE1PXItMJ/yA6cehOHSsgn27duj9vdDoVL9rVkF/Wv0p65TXT4O/pgxB8dQx7EOY+uOxd/ZXwcdFUIIoQ/kTKB4bq1bt6Zly5bY2toWmZ6ZmcnevXsZO3YsFhYW+Pn50bx5c7Zu3QpAbm4uH3zwAaNGjaJy5cq6CP31YW5bUBQ2HAn9N4NTDcxPT6bRt33p3N4IVwcNtyp14LTnMO7sOsbtgQO51LgJ9+bMJS8lpUhTNR1qsqnzJqY2nEpsRizv/vkuk45MIjc/V0edE0II8TqTIlC8dFFRUahUKtzd3QuneXl5cf36dQB27NjB+fPn+fHHH+nfvz+7du3SVaivF1Mr6LcOTK0x2jmYsi196PRlR9oOrYXKzpnTDT9lWZMxnDIvT+LSZSWm7/IAACAASURBVFxr2Yr4H38kL/2/Q8sYK43pUa0HO7vuZFidYey+uZsvT30pl4eFEEI8Qi4Hi5cuMzMTS0vLItOsrKzIyMgAoEuXLnTp0kUXob3+rMtBv/Wwog0saQoVGlK5nC99+tdl53Y1qjhPlAMDGXnyFBPuHkY7fwHJq3+n/Ny5WNQPKGzGzMiMkT4jycnLYfnF5bhYuDCk9hAddkwIIcTrRs4EipdOrVaTnl504OP09HQsLCx0FJGecfaGtzdCpSYF9wvun471ts50txlPRTcNmSfi6VXBm489e3No7GxUNjbcfvddkn777ZEzfmPqjqF95fbMD5vPtshtOuqQEEKI15EUgeKlq1SpEnl5eURFRRVOi4iIoGrVqroLSt9UqA89f4GxZ+GjKOixAhMTLW2z+uLv8CeKO5kMSzcnOMKUo2NmY9nsDeK+/Iq7kz4i/+HDwmaUCiUzG82kvkt9phybwsA9A1l+YTnXkq/JJWIhhCjlpAgUzy03NxeNRkN+fj55eXloNBpyc3NRq9W0atWK+fPnk5mZyenTp9m/fz+dO3fWdcj6ydyu4H3Ew46i7P0bAWX306/seKrWtKCxxpiYrfeY7tWHnIHvk7pjBzd79iTr6tXC1Y1Vxvzwxg+85/0e6dnp/HDmB7pt68bwfcNJykrSYceEEELokrwxRDy3BQsWsHDhwiLTRo0axejRo0lJSWHy5MkcP34cW1tbxo8fT8eOHZ97WzLq/d8kR8HiQHCuxa2Gv7Hjp0uk5+axykJDL3UcPfcuh4x0yk6ejG2vno+8RSQuI47dN3ezIGwBtqa2zA6ajZ+zn276IoR4pSR3iuJIESj0giSy/3F2DWwZBs2nEF9pKJu/P0OOSsFvZg8xzk1jQdQ2zM6GoA4IwKrNm1g1bYpx+fJFmriSdIUJhydwO+02/ar3w8fRh0o2lahoXRFTlamOOiaEeJkkd4riSBEo9IIksv+h1cKGdyF8G7z3b+5pqrB13lnMbUzYapfLmXspfKsIx+fMfnJuF7xxxKxGDcrPn4eJq2thMxk5GXxx8gt23NhROM1IacS4uuMYUGOAvItYCD0nuVMUR4rAUiY6OhqFQoHr3woBfSCJ7DEeJhdcFlYqoeU0YlRBbP/xEmobE655mrPy0l0q2qsJNM0gIPYyVf+9ATPnslT6Yw2q/xnCJzMnk6jUKKIeRLH75m4O3TlEb8/efBTwEUZKGUlKCH0luVMURx4MMXAffvghZ86cAWDjxo20b9+eDh06sH79eh1HJl6YuR30/BUUKtjwLuV3BdGleTi5WTlUOJPG7EAPPJysOJKlZqy2JpPr9CXrxk1iPvgQbW7Rt4iojdXUsK9Bu8rtmNd8HgNrDuSPK38w7uA4MnMyddM/IYQQr5QUgQbuxIkTeHt7A/Drr7/yyy+/sH79epYuXarjyMRL4eYPo89An7Xg4IHzuY/pYT4ES+6RuDOad83NWf5GDQ4Oaki9di1YWLsrGcHBxM3+5h+bVCqUjPcbz6f1PyU4Jph39rxDbHpsCXZKCCFESZDrPAYuJycHExMT4uLiSElJoV69egAkJCToODLx0iiV4Nmm4Cf+KtYX1tP97Bz23epC2IH6QBwADkoF5g06sjktjq4rV/Lw3DmUZmYojIww9fLCafyHKFSqwmZ7e/WmnGU5PjryEb139uaHZj/g6+Sro04KIYR42aQINHDVq1fn559/JiYmhjfeeAOAuLi4R17rJgyEYzVo/ikmzSbTLvoUuZvGkJqYRWrtCUQk+xJ5Jp7segPYpDTFP/Uu7socjDIySFqxAqVajeOokUWaC3INYnW71Yw+MJp3/3yXiX4TCXINwsXCBZVS9Q9BCCGE0AdyOdjAzZo1i6tXr6LRaBg3bhwAYWFhLzRmn9ADCgVUaIDRsH9TpoY3lS6N5k3rb2jSOBWzhGzsPLox1WcwXT3f4cC4b7Dq1ImERYtIP3bskaYq21bm9/a/41/Wn6/++oq2m9rit9qPTls6sefmHh10TgghxMsgTwcLvSBPuL2A/Hw49j0c/Aryc7iXXY3dKR+hMlFxtKYDeyNTqVXGhC/+PRfzjFTcN2/CuGzZR5rJy8/jbPxZoh5EcTvtNifuniAiKYKZjWfSuaq8DUaI15HkTlEcORNo4LRaLevWreOdd94pPPsXEhLCrl27dByZKDFKJTQZD5NjYNRpnAd9xZtNoknLsqLPnTMs7e1FhtKYUdV6kpmawcWho8jPzn6kGZVSRb2y9eherTsf1PuAf7X9V+E7iTdf26yDjgkhhHgRUgQauHnz5rFhwwZ69epFbGzBE57Ozs4sW7ZMx5GJEmdkCg5VwaMl5fp8gG+dDC7H1aLq/rnsHV6HD95rzarAvphFXGRv626cPHa+2ObMjcxZ0HwBjco14vPjn7P+qgw7JIQQ+kSKQAO3efNmfvrpJ9q3b1/49gdXV1eio6N1HJnQtfqDO2LvkMfByBZkL+9NN9d0vl40gdsjP8ExMQbjoQP4esI8rsal/WMbZkZmzGs+jyblmzDjxAy2Xt9agj0QQgjxIqQINHB5eXlYWFgAFBaBGRkZqNVqXYYlXgMqYyWthjckW2HDrsgehH43l8g1q6jdpgPlV28ku2JVOu/4icvdehI64TNSNm1Gc+PGI+2Yqkz5vtn3NHRpyOfHP5eHRYQQQk/IEDEGrmnTpnz11VdMnjwZKLhHcN68eTRr1kzHkYnXgX15S5r2q8HJzcacSq0CR4GjZwFQVByBWeUclAnXsTu6l7s7NqIAbLp1w2niBIzs7ArbMVWZMq/5PIbvG84nwZ9gojKheYXmuumUEEKIpyJPBxu49PR0PvroI44cOUJubi6mpqY0btyY2bNn69VYgfKE26uXo8kl/fgmUg/+i7QsNemWvqRaBxAVZUxOVh6JaPBUXqPWkaUYWVriNGkSNl27FJ5hBsjIyeD9ve9zOekyjcs1JrB8II3LN8bNyk2HPROi9JLcKYojRWApkZCQwN27d3FxccHR0VHX4TwzSWQlSJMGp/8FJxdD6h2y7X2IsB/P/lBrTDLzybTX0C3yN7LPnsX+/fdx+vCDIqs/0Dxg8bnFHI4+zJ30OwD4Ovky2nc0/s7+uuiREKWW5E5RHCkCDVx+fv4/zlMq9eeWUElkOpCXAxc3wdG5EB9Bfplq/J48kQexDkQ5KRmesQvN7p1U+mMN5rVrP7K6VqvldtptDkUf4rfLv3E/8z71Xeoz0mckPo4+Rc4gCiFeDcmdojhSBBo4Ly+vf/zPNjw8vISjeX6SyHQoPx8itsORb9HGXmRf5niupjXmumUWA49/hbmNNVW3bkZpYvKPTWjyNKy7so5lF5aRlJVENbtqdPfoTvvK7bExtSnBzghRukjuFMWRItDAxcTEFPk9Pj6eJUuW0KxZM3r27KmjqJ6dJLLXgFYLV/9Ee2QOhy77cflhK2zyT+NzdCW3vN2503sY7d5oiluZf37yPDMnkx03drDx2kYuJ17GVGVKh8odGFBjAJVtK5dgZ4QoHSR3iuJIEVgKpaWl0aNHD/78809dh/LUJJG9RrRatDeDObEmlLBoH6yy7+J1/hc8Gl6mt9U0Ktfw471Ad/wqlSm2mfDEcNZdXcf2yO1o8jQElg+kV7Ve1Hepj9pYhjAS4mWQ3CmKI0VgKRQbG0unTp0ICQnRdShPTRLZ6yk6PIl9Ky7y8EEWVWJ2UtX6KKMqjCVcYU+H2i5M71QTe0vTYttIzkpm7ZW1rIlYQ1JWEkZKI+o51SPINYi3vN7CVFX8+kKIfya5UxRHikADN3HixCL3BGZlZRESEkK7du2YMmWKDiN7NpLIXl8P07LZ9+Nf3L6ZjSpPg/O9k5hbP2CxRRVuu3oyrbM3HWu7PPFBkJy8HM7cP8OxmGMcvXuUa8nXqGpblS8Dv6S6ffUS6o0QhkVypyiOFIEGbuHChUV+Nzc3p3r16jRq1EhHET0fSWSvv/u3Ujn7r11ExtiRj4oa4b+Sn3+fP9waYhPYmE96+lPG0fapnwo+FnOMKcemkKxJZkSdEQzyHoSRUsa3F+JZSO4UxZEiUJS4tLQ0Bg0aRGRkJGvXrqVatWpPXEcSmZ7QaslcPZQ/T3lzL8eLerd/werG2f/OVioxrexO+TlzMfN88n5/oHnAFye/YE/UHlpUaMF3Tb+TQlCIZyC5UxRHsqkB2rBhw1Mt16NHj1ccyeOZmZmxZMkSvvnmG51sX7xCCgXqnnNoW2Y+m/Ymc65iX9pVvIJ5VjIh2dU5nebKm/cuoundG6dvv8OhZfGvlrMxteHbpt9Sy6EW34Z+y9TjU5nZeCZKhf6McSmEEK8rKQIN0NatW5+4jEKh0FkRaGxsTJkyxT85KvSYqRVm7T6lY4MsNnwdwj6+o2vAWt689QdNlWpWPQii/NH75I8axbLAt3AZNIBe/hUwN1H9Y5MDag4gIyeDH8/9iLWJNZP8J8lg00II8YKkCDRAK1euLJHtrFq1ik2bNnH16lU6dOjA119/XTgvJSWFTz/9lGPHjmFnZ8eHH35Ix44dSyQu8XqwKmNGh9E+bP7uDCv/egsXt7dxNzlBz+ylqN98wJVQDzof/YPE0F2sdXTHxq8eTd7uhENNz8e2N6zOMFKzU1kVvgotWvrX6E95y/Il3CshhDAcUgSWIlqtlr/fAvqir41zcnJixIgRBAcHo9FoisybMWMGxsbGHDt2jPDwcIYOHYqXlxceHh4vtE2hXxzdrOj1qT/XQuK4cTae49f9OKn0o07FK/j5f0GGoxazVCvUMZGYbz5H/OYVpDZrjsuIYZjXqlWkLYVCwUT/iWTlZbE6fDWrw1fjVcaLlhVaMqDmAMyNzHXUSyGE0E9SBBq4uLg4ZsyYQWhoKKmpqUXmvehr41q3bg3AhQsXiIuLK5yemZnJ3r172b59OxYWFvj5+dG8eXO2bt3KhAkTXmibQv/YOqnxb++Of3t3UhMeEro7irBjcM12DUHNz+Ke+DPuqXfIylZzPMID2+Mn0Bw8gEWjRjiMHoXa17ewLaVCydSGUxlUcxAHbh9g/+39LDy7kOi0aL4I/EKHvRRCCP0jd1cbuKlTp2JsbMyvv/6KWq1m8+bNNG/enOnTp7+ybUZFRaFSqXB3dy+c5uXlxfXr1wt/HzJkCEePHmXKlCny5FopYu1gTvP+1ek6oS4malN2nfBml/ka0rrvwqx+d5rVvkC59oncbNKArIgIbvXpS/Sw4WRFRBRpp4J1BQZ6D2Rlu5UMrT2UrZFb2R65XUe9EkII/SRnAg1cWFgYBw8eRK1Wo1Ao8PLyYtasWfTu3ZtevXq9km1mZmZiaWlZZJqVlRUZGRmFvy9duvSVbFvoh3JVbek12Z+z+24TujOK3yMU1O84idqD38VozVDamWwiwusNHE17kvjbGm526Yr98GE4jhnzyAMhw+oMI+ReCDNPzqSWQy0q2VTSTaeEEELPyJlAA6dUKjEyKqj1ra2tSUpKQq1WF7l8+7Kp1WrS09OLTEtPT8fCwuKVbVPoH5WRknptKtFnan3Ke9hybMN1fl+iIbr2OnbYj6RyajB5KT9jvPBrbLp2JXHxT8TPn8//Dm1qpDRidtBsTFWmTDwyEU2e5h+2KIQQ4u+kCDRwderU4fDhwwAEBgYybtw4Ro0ahbe39yvbZqVKlcjLyyMqKqpwWkREBFWrVn1l2xT6y9rBnPYja9N2WC3MLU04vvkmd6625neT38nOVuC88y0OV7XHuFNBIZiwcNEjbThbOPNF4y+ISIpg/KHxxKTH6KAnQgihX6QINHDffPMN/v7+AEyePJkGDRrg4eHBnDlzXrjt3NxcNBoN+fn55OXlodFoyM3NRa1W06pVK+bPn09mZianT59m//79dO7c+YW3KQyTQqGgso8j3SfV463P/PFq4MzDu6YczPuZm6aB9ImeQZTJcWJrVCNh0SLivvmG3OTkIm00dWvKJP9JnIo9RcfNHZkTOocHmgc66pEQQrz+5LVxBi4pKemVDcy8YMGCR95NPGrUKEaPHk1KSgqTJ0/m+PHj2NraMn78+BcaJ1BefVT63L2ewp6fL5CXm09gnXO4xfyAhSaRmyGOaG4ao1WpsG7eHJvu3bBs2rTwXsG4jDgWnl3I1utbsTKx4p2a79DXqy+WJpZP2KIQhkdypyiOFIEGrk6dOgQEBNChQwdatWqFWq3WdUjPRRJZ6ZSa+JBdiy+QFJOOf/uK1Kp4lYRjy7CJCCbzpinJtyzRZoFFPW9cvvke4/KuheteSbrCwrCFHLpzCGsTawbUGEDf6n2xMrHSYY+EKFmSO0VxpAg0cElJSezevZsdO3YQERFBs2bN6NChA0FBQYUPjOgDSWSlV3ZWLodWX+FaSByOFaxo8U51zK00HNi8AuurW6kRdYOEc1agUKBsVhH1+5/h6t2kcP1LiZf46exPHLpzCCtjK/pU78Pb1d/GzsxOh70SomRI7hTFkSKwFImJiWHnzp1s376d+Ph4Tp48qeuQnpokMnH99H0Or7lCdlYudVtXpGaT8tx+qOHX/adxvbKHxof2ok7IwqxcNof7fE7Xt/tiY25cuP7lxMssPb+Ufbf3YW5kTjv3dvg6+VLHsQ4VrSvKu4iFQZLcKYqjP6eCxAtLTEwkISGB5ORkrK2tdR2OEM+kaj0nynnYcuSPq4TuiuL07ijcqpdhSMMaVO7bFIV2FrcWzCNr2VIaLPiKOSfCqT50OL0DKqBQKKhhX4Pvm31PZEokyy8s58+oP9l4bSMAZczK0KNaD/pV70cZs1dzD60QQrxu5Eyggbt+/To7duxg586dZGVl0bZtWzp06EDt2rV1HdozkW+z4u9S7mdy5eQ9Ik7Ekp6swdrBjHptK+HZwJncs4e4O24YWfEqzjtVJrG6H506NcKpTk1MXP97z2C+Np8bKTc4n3CeQ9GHOBR9CFOVKV2qdmGQ9yDKWZbTYQ+FeDkkd4riSBFo4Pz9/WndujUdOnSgfv36KJX6OSqQJDLxONp8LbcuJvLXjpvE307D2tGcoLeqUcHyGomfvEXiVQvyM/6b4qw7dsTli5koTU0faevGgxv8evFXtt8oeP1c5yqdGVJ7COUty5dYf4R42SR3iuJIEWjgsrOzMTEx0XUYL0wSmSiOVqsl6kIiJ7dEknI/k85jfShHKGwaQt6DFEIzfTl1w5VWV0NJqlgN41nf4utbFWPVo1+K7mXcY/mF5Wy8thGtVksXjy6M9BmJg7mDDnomxIuR3CmKI0VgKXD06FHCw8PJzMwsMn3s2LE6iujZSSITTyMrI4dN354mMzWbbhPqUaZMHpxcjPbEAtCkczvGhfTjCrJNjDjYrBkeXd+mXWM/VMpHHwq5l3GPFRdXsP7qekyUJgyuNZj+NfpjZmSmg54J8Xwkd4riSBFo4GbMmMHu3bupX78+5ubmReZ99dVXOorq2UkiE08rNeEhG785jdJIQY9JfljYmkJmEpz+BWLPkXHxMne3p5KXo6BcgxTSK9hBpUBc/DujqNICTIqOpXk79TZzQudwIPoALhYuBLkG4VXGC68yXlSzq4aJSv/PtAvDJblTFEeKQAMXEBDA1q1bcXFx0XUoL0QSmXgW8bfT2DTnDDYO5rQbXgtrh6JfgHLuxXJn2BCyIiLJrG1NVa/b2CgzyVOZoaraAvzfhaoti6zzV+xfLLmwhEsJl0jPSQfAwdyBgTUH0rNaT9TG+jkQuzBskjtFcfTzKQHx1Ozs7LCykjckiNLFsYIVbYd6k5b4kD9m/sXlY3f5+/ddY2cXKq7diHWnjqjPp3LxZgfG5k/mN01Tkq6fglXdYU0fSLpZuE6ASwDLWi/jeJ/j7O62mzlN51DFtgrfhX5Hm41tWHFxBbn5ubrorhBCPBfVtGnTpuk6CPHqGBsbs2TJEsqXL09ubi6pqamFPzY2NroO76mtXbuWt956S9dhCD1i46jGw78s92+lcv7AHeKj03FwtcTcquDyrcLICKuWLVGam5G/cR0N0pK423QYI5PbkJxrit+DPahClqLIuA+ZyZCfA6bWKIxMsDa1poptFTpV6USjco24lXaLdVfWERoXSuNyjbEwttBx74UoILlTFEcuBxs4Ly+vx05XKBSEh4eXcDTPTy5piOelzddy7kA0J7fcIC83H3tXS6r5l6VagDOWdgVDxWSGhBAz6SNy4+OxGj6S1e5N2HniLB/yOx1VJ1CRV9CYQgk+/aDF52DpVGQ72yO3M+PEDCyMLfiu6Xf4OfuVdFeFeITkTlEcKQKFXpBEJl5UxgMN10/f51pIHHE3UzEyVhLQqTJ1mruiVCnJe/CA2GnTSNu9B4WpKYpy5bhtasfJfGsS3V3p09KZAGU4itO/gJE5NJ0I9YeB0X/HHLyWfI0PD31IdFo0fbz6MLDmQMpalNVhr0VpJ7lTFEeKwFIiNjaWuLg4fHx8dB3Kc5FEJl6mlPuZHNtwnajzCThWsKJZfy8c3azQarWk799P5pkwcqJvk307mqzISBS5ucSb2xDp5Y9jz1Y0SlxBmZiDaG0ronjjE6jdC5QqANKz0/km5Bu2RW5DqVDSuWpn3vV+FzcrNx33WpRGkjtFcaQINHB3797lww8/JCIiAoVCQVhYGHv27CE4OJhZs2bpOrynJolMvGxarZbIM/Ec+eMKD9NzcHa3plJtB9xrO2LnokahKBg7MC81ldQDB4lYtxWLs3+RZGrN1IbvUtH2PtPUG6icGwkOnhA0AcrXA9uKoDLiTtodfrn4C5uvbyY3P5c33N7g7epv4+/sX9i2EK+a5E5RHCkCDdzgwYPx8/Pj/fffp379+oSEhJCWlkanTp04ePCgrsN7apLIxKuSlZHDxcN3uHkugfu30gBwqWJDo+5Vca5c9OGphxcvcmvYcPIyH3LhvUl8GW9FS+1fTLfaglX6jYKFlMZQxr3gvsHqHbmfeZ8/Iv5gw9UNJGuSqWZXjW+DvqWybeWS7qoohSR3iuJIEWjg6tevz4kTJ1AqlQQEBPDXX38B4OfnR2hoqI6je3qSyERJSE/OIvJMPGf+vEVmajZVfB2p37kyds7/fdo3JzaW6OEj0Fy7hvE77/IF1TiSpGV89Qf0r5aLdUYUXN0LSZHw7h4o5wtAVm4Wu2/uZt6ZeagUKn5t+6tcIhavnOROURwZJ9DA2dvbc+vWrSLTrl+/rveDRwvxKljamVGnhRtvz2xIQEd3bl1O4vdpp1g99SRH1l4l6kICCnsnKq5ahVWLFuSsWMpHv0zil/DfObXvFvV3OjJL04uE7uvAwhH+6Afp9wEwMzKjq0dXlrRegiZfw5C9Q7iXcU/HPRZClGYyTqCBMzU1ZcaMGajVag4fPkz58uWZNWsWQ4YMwdPTU9fhPTUZ60qUJJWRkvLV7KjRuByWtqZkZeRyMyyeKyfvce7AHRLjNFi1aYProF4Y21pjfP40ja8cp8nDO/yUbM2P59PJdWuEf/xGFLdPovjbgyP25vYEOAew7uo69t/eT72y9TBWGmOiMpF7BcVLJ7lTFEcuB5cC+/btY+3atdy9exdnZ2f69OlDy5Ytn7zia0QuaQhdy83J4+61FG6ExXPjbDwP03KwtDOl1Xs1calsTcr6Ddz/5hvy8/M52aIPc81q8kb+MRaYLOSWbQBlqwdiZlMWLB3B2pXTuSkMO/4ZWXlZACgVSsqqy9KoXCOaujalvkt9eRWdeGGSO0VxpAgUekESmXid5OdriYlI5tDvEaQlZuHfwZ16bSuRdy+W2Cmfk3HsGApzczIqeZBhkkZly8uUdX6AsXF+kXaiTMy46OhOir07ydZluanI43hcCBk5GZgoTehUtRNDag2hnGU5HfVU6DvJnaI4RroOQLxaGzZseOx0ExMTnJ2d8fHxwcTEpISjEkK/KZUK3GqU4a1PAzj0+xX+2n6TOxHJNB/ghduypaTt20fmyVOYXriAxeU7pOWYk2xkzXn7SkRVqIR3yxq0qqqgUmYMle6chkv7IC8bVKbk1OrO6apN+DPtGluvb2XL9S10qdqF92u9j4ul3MsrhHh55Eyggevfvz9hYWE4ODjg7OzMvXv3SEhIwNvbm5iYGAB+/PFHatWqVaJxffvtt4SFhVG+fHm+/PJLjI2Ni11evs2K15VWqyXixD2C110lP09LQAd36rR0Q6UqeO5Om51N5pkzpB04QNLefSjuxZKlMuZYhXoYd+1Or36tsTPJgzuhcGkTnPsDcjKhYmPuebZieU4cG2/vRYGCd2q+w+Bag+UysXhqkjtFcaQINHDTp0/H3d2dAQMGFE5btWoVN27cYMqUKSxevJjDhw+zdu3aEospIiKCZcuW8d1337F48WLc3Nzo0KFDsetIIhOvu/RkDcHrrnIjLB778pY0e9uLsu7WRZbRarVkXbxI1K+rydm7B+McDccr1sPhyy/pVNet4MGQh8kQthpCl0NSwdiD9xz/r707D4+qPhc4/p19MkuWmewL2RdI2BeJgBAEK1UQsFZra6128RahVEWrVtsr1erVXnsVr7XtVVsFtZtScaeILIFA2BKWhCwkQBKyZ7LMTGa/f4yGRiAqCiHk/TxPHpjfOXPOb84zz5s3vzWTp6JieMt5jKiQKH4y4SdcnXY1aqV05oiBSewUA5Ek8CI3efJkduzYgVJ5cjUgn8/H1KlTKS4uxu12k5+fz+7du89bnV555RUMBgMLFy7kwIEDvP766/ziF78Y8D0SyMRQcWRfC5tfq8DR6WLM7CQuWZCGRqc65TxfdzcVTz8HL7/AByMmsfeG23l40RgSIz5u5QsEoK0KKj8I/tRspkSr5r/iktiv8BBjiOaGnG9xbea1ROgjzvOnFEOFxE4xEFkn8CJntVr58MMP+5V99NFHWCwWAFwuF2r12bUmrF69msWLF5OXl8e9997b75jNZuP2229n3LhxFBQUsG7dur5jXV1dmEwmAMxmW1vl9wAAIABJREFUM52dnWd1fyEuRGnjovjWLy9h1IwESjYc57Vf7eDI3ha8bl+/81RmMyN/fjfWpUu54tguxrz+PAVPbOSm53fwctFRGrtcEJkJ+bfDd/8Jd5YxdsbPWd2tYFVjC2nt9Ty15ynm/O1y7tl0D5uOb8Lj8wzSpxZCDEXSl3CRe+CBB1i+fDmZmZnExcVx4sQJKisreeqppwAoKSnhpptuOqtrR0dHs2TJErZs2YLL5ep3bOXKlWg0GgoLCykrK+O2224jJyeHzMxMzGYzPT09AHR3dxMWFna6ywsxZOlC1My6MZvMSdFsXF3Ou7/fj1qjJCE7guQ8Kzn5cX2tg1G3LyHgdDDv+RfITIjgf8K/xoNrD/Dg2gOkRxmZmBzBpGQL0zIjSZj+U5TTljPr2HZm7XqR6op1vGrS857vPd6tfZcwtZE5KVcyO3k2l8Rdgk6lG+QnIYS4kEl38DDQ3t7O5s2baW5uJjo6mpkzZxIR8dV1H/32t7+lqamJxx57DACHw8GUKVNYt24dqampANx9993ExMSwYsUKysrKePHFF3n88cd57rnnSExMlDGB4qLl8/ipO9zB0YNtHDvQRmeLE1OEjmnfyCR9QhQKhYJAIEDTr35FxyuvosvOxrv0Tj7UJlBc087uYx3YHB4UCpidHc138pOZmRmFUqkAexuUvIqn/C22t5bwljGETQYDDqWCEJWe6YkzmJ82nxmJM2T84DAlsVMMRKLCMGCxWFi4cOF5u19tbS0qlaovAQTIycmhuLgYgJEjR2K1WrnxxhuJi4vj1ltvPW91E+J8U2mUJOdZSc6zwvXQUGlj818qeP+PB0jMiWDy1anEpoUR8+CDGC6ZStNjj+Fbdhvz58/npmsXo7v2UmocAd4saeDVncfZ8GIxiREhzB8bz1Wj48jNvx3NpUu5zNHOZVUbcJe8ys6GbXxkCGGDbyPrj64nWhfBoqzr+Eb2dcQaYwf7kQghLhCSBF6Evv/97/P8888DcOONN55xK6o1a9ack/s7HI6+MX+fMJvN2O32vtc/+9nPzsm9hbjQxWeG8837JnFwSwM73jzCG7/Zg96oITnPSsakCaS/8zatf/gD7c+/QNe6daBUosvI4MaJE7hl8hSKQtN49XAXf9h8hN99VE2K1cCSWRlcNykRxZjr0I65juntNUzf/SL37nuFzYEe/m528ofS3/N/+//AHHMGN+V9n7GZV4FsUyfEsCZJ4EXo31v9rrvuutOecy73KDUYDH1j/j7R09OD0Wg8Z/cUYihRqpSMnpVI1iWxHDvYRu3+VmoPtHJ4RyNjZicybdlPsN5yC86SUpwlJTj37aPrzXX4X32NVGBlbi7ab3yTrckTeXVvI/f8o5RNlS38etFowkI0YEmFuStRz3mI2W3VzD5eREPtR7zavIN/+Cp4f/t9jN38M25TxTDdMgqFNR1G5EPi5L49joUQFz9JAi9C8+fP5+GHH+aBBx5g0aJFAPztb3/rlxAuW7bsnHURp6Sk4PP5qK2tJSUlBQiuDZiRkXFO7ifEUKULUZM5KYbMSTH4fX62vV5NyYbjdLY4ueL7uZhmTMc0YzoAAY8H54EDOIqK6Hrvfboe+iUTYmKY/d3v8vdZU/jN5mPsO2bjievGkJ9mDf6hp1BAZAZEZhA//jvcBfxH80HW7v09LzVtY0mghbyWjfy4/G/M+FcvipAISL8csr4GGXPAYBncBySEOKdkYshFasKECezZs6fv9ZQpU9i5c+cZj58Nr9eLz+fjmWeeobGxkYcffhiVSoVareaOO+5AoVDw8MMPU1ZWxo9+9CNee+01MjMzz+peMrhZDBcHNtez+bUKLHEG8mYmEhqpJ9QagjlSf3IXkkAA+9attP3f8zh27EA/dgy2h/6bn7xZwfF2JwnhIXwtN5YrcmMYGRcabB38FI/Pw5vVb/LH/X+kvqeeDH0038bMVUf3E+JoBYUSEiZB5lyIHQ2RWRCRIi2FQ4zETjEQSQIvUuPHj2fv3r19rydPntw3MeN0x8/GqlWreOaZZ/qVLV26lGXLlmGz2bj//vvZtm0b4eHh3HXXXcyfP/+s7yWBTAwnxw+188HzB+m1n1z3T2dUkzUllpH5cUQmmfqGdHS9/wH1d95JyPhxWFY9y3vVnXxwsJHNla24vX4Awg0aki0GxiSGc2VeLJekWlB/nFB6/B7eOfIOq8tWU95eTpg2jEWx+Sz0KEmvKYIT+05WTKWD5Eth7A2QczXo+o/9FRceiZ1iIJIEXqTOR0vg+SSBTAw3fn8Au81Fd1svXa1Ojh5so2ZfKz6vH2uCiZz8WLKmxGII1dL1zjvUr7gbw5QpJD33O5R6PT0uL0XVbRxp7eFom4OjbQ52H+3A6fERbtBwZW4sP5iRRkZ0MJELBALsad7DmrI1bDy2EW/Ay+jI0VwzYi5XGlMIs9VBcxmUvwW2o6AxwqhrYOp/QNzYQX5a4kwkdoqByJjAi5TP56OoqIhPcnyv19vvtd/vH8zqCSE+g1KpwGzRY7boic8MJyc/jl67h8riJsq3n6Dw71Vse72aEbkWLpk/g/hHf03DvfdRe/0N6EeORB1pZUJUFNMmTEQ/PReFUonT7WNTRQvvH2zkn/sa+Muu41w1Oo5lszPJjjUzMWYiE2Mm0ups5e0jb7O2ai0P73mSx5VaCkYUcE3eNeTPfQh13S4ofQ32/x1KXoGUGZC/FNILQC0LVAsxVEhL4EVq9uzZn3nOp7eTu5DJX7NC9NfeYOfwjhOUbTuBz+NnwfLx6A9sov2ll/G2tuJrbSXgCXYnq6xWTNOnYZozB/PMmSi0Wtp6XPzf1hpe2laL3e0jNz6U/DQr+elWLkmzYtKpCQQCHGo/xJtVb/JOzTvYXDaiQ6JZkLGAhRkLSdaEwZ4/w47fQ1c9KDUQmwfxEyBuDFgzg2MJjZGyHM0gkdgpBiJJoBgSJJAJcXrd7b2sfXIPvT0eFiwfT0xqKBDs3vW2tODYvp2eLVuxb92Kz2ZDFRFB2IL5hC2+Fn12FjaHmzU7jrG5ooW9x2y4fX5MOjU3X5rM96enYTFqgeBEks11m3mj6g221G/BH/AzKWYS38v9HjPipqKs2gDHd0DDHqjfC+7uk5UMiYCYvOAEk9jRweVoLKmn+zjiKyaxUwxEkkAxJEggE+LM+hJBu5cFPxnXlwj+u4DXi72wENs/Xqd740bweNCNGkn4wkWEXn0VaouFXo+PPUc7WLPjGO8cOEGIRsW3LxnB/LHx5MWHBbeqA5odzbxZ/SZ/PfxXTthPkB6Wzs25N/P1tK8H9yv2+6HzOLRVQmsltJRD4wFoOgheZ7BClnTIuBxSZ0L8OAhNkNbCc0BipxiIJIFiSJBAJsTAPkkEe9pdpE2IYsysRGLTw067MLy3o4OudW/RuXYtvYcOgVpN2Pz5RP7HbWiTkwGobOrmmY1VrCtpwB+AKLOOWVlRfC03lsuyotCqlXj8Ht6vfZ8XD7xIRUcFZq2Zq1KvYnHmYkZaR55aSb8vmBTWbIKqf0HNlpNJoSEyOMEkflywOzl+PITGS2L4JUnsFAORJFAMCRLIhPhs9k4X+9Yf41DhCdxOL5FJJjInxZAyJpKIWMNpE8LewxXY/v53bH/9KwGvl7D587He9iN0H+/93dbjYlNFCx+WN7O5ooWuXi+hejXz8uIoyIkiVK9Br1FSay+hqOVdNhzbgNvvJiU0hUmxk5gcM5nJsZOJMkSdWmFPLzSWwomS4FI0DSXQfAgCvuDx6FEw+Qcw5npZjuYsSewUA5EkUAwJEsiE+PzcvV4qdjZxaGsDLceCY/PCokKITQvDFKHDFKEjPNZIQlZ4X2LobWmh7fkX6HjtNQK9vRjypxLxzW9ivvxyFNpPxgX62VrZyrqSBt4/2Ijd7et33+wYM7fMiMZv2Evhia3sadpDjye4hWRKaAoTYyYyOXYyOZYcksxJaFXaUyvvcQa7jut3QcmrwQRRFwrjvg35SyB8xDl8chcfiZ1iIJIEiiFBApkQZ6e7vZej+1up3d9GW0MPDpsbvz8Y9hOyw5nxzSysCSdb2bytrR+3DP4NT0MDqvBwjNOnY8zPx3hpPpq4OAB6PT4qmrpxuH043T4aOp38qbCWyuYekq0Gbp2WytVjY2jsPULxiWJ2Ne1id9PuvqRQgYI4YxypYalkhGeQGZFJtiWbrIgslIrgQtYEAlC3C3b+Hg6+ESwbfR1M+ylE55y/hziESewUA5EkUAwJEsiE+Gr4/QGc3W5q9rVQ9OYR3E4fo2cmMGVBGrqQk0vHBvx+7IXb6HzzTezbt+NrbQU4ZTLJp6+9vqyJZzdWUVLXiVal5PKR0VwzLoEJI8KxGNVUdVZRbavmaNdRjnYdpaazhmpbNW6/G4B4YzxXpV3FVWlXkR6efvLinXWw7RnY/afgOMK4ccF1CdMKIHEyaA3n/NkNRRI7xUAkCRRDggQyIb56vT0eit48wsEt9ZgteubeMoq4jPBTzgsEArgqK7FvLaTrrbf6JpOYC2YR8a1vYcjPP2W84cGGTv6xu55/7qunzR5M8CJNWkbGhRITqidUr8GsV5MRbWLOqEgaHfWUtpTybu27bG/Yjj/g7zeucELMBGIMMSgc7bD7xeDEkrpi8HuDNzRGQVgShCWALgy0xuBPbB6kXw4hp36u4UBipxiIJIFiSJBAJsS503ikk/UvHKS7rZdJX09h0tdTUH68t/Dp9B6uoHPtWjrXrsXX0YE2LY2IG25Al5GO0mhEaTSiiY9HaTDg8fnZe8zGoYZODp3ooryxm9ZuF129XnpcwQQuyRLCklkZXDshEa1aSauzlfdr32d7w/Z+Xcih2tC+ruNr0q9hdGgK1BZC0wGwHQsuS9PVAK4ecH/84/eCQhXc8zh9dnAGcuxoMEWfj0c76CR2ioFIEiiGBAlkQpxbbqeXLX+poLyokbCoEJJGWUjIiiA+MxxD6GkmcAB+l4uud9+l45VX6S0t7XdMYTAQ+rWvEb54ESGTJp1+qRqfn48Ot7Dqw0pK6jqJD9Nz86UpXD85iXBD8J4+v4/yjnJKmkuotlVTZavicMdh7B47c0bMYdn4ZaSFp53+Q/l9wTGFFe8Ff5oPnTxmjIbwJDDHgSkm+K85BkyxwfLIbFCeOREeKiR2ioFIEiiGBAlkQpwf1XuaOVTYQENVJ16XDxSQPj6KCV9LJjr51EWoP+E6UoOvrRWf3Y6/x45jRxFd77yL325Hm5JC9Iq7MF1++WmTwUAgwObKVp7dWMWOmnb0GiULxyUwMyuKcIOWCKMGi0GL1aRDpVRg99h56dBL/Pngn3F6ncxMnMn46PGMjhzNKOsoDJozjA90tAdbDRv3Q9Oh4FZ3PU3QfQKcHf3P1YdD8jRImQ6ZcyEy88s81kEjsVMMRJJAMSRIIBPi/PL5/LQc66ZmXwsHNtXj7vWRkB3BmIJEkvOsqNSf3Urmdzjo+uAD2p9/HldlFcYZM4i5/76+NQhPp+xEFy9tr+WNvfX0evz9jqmUCqJMOmLC9EQatZiMvTQE3qHRW4zN09R3XrgunMiQSKIN0UxPmM43sr5BiDpk4Mp6XR8nhI3QVg1HC6F2K3TUBI9bMyHnquBkFGsGmOOHREuhxE4xEEkCxZAggUyIweN2ejmwpZ6SDcdxdLrRGzVkTIombXwUoVY9xjAdaq3qjO8PeDy0r1lD66pnCLjdGC7NJyQ3F31uLiFjxqCOOnUh6e5eD8fbndgcbjocHtrsLpq7XDR19dLY1Utbj5t2u5s2uwuPL4BC1UNo+AniotrR6roJqLpw+ltoctVg1Vu5Je8Wrsu67sythGdiOx7sSi5/K5gUfjIRRR0CljSIyg4uah2dE3wdmgD6sAtmpxOJnWIgkgSKIUECmRCDz+fzc/xQO4d3NFJT0orv31rq9EYNSaMsZE2JIWmUBdVpJpZ4W1po/d1zOIqLcVVXB/cYBvSjRmGaNRPTZZehz81FodF87joFAgFq2xwU17Szs7ad0jobjZ29dPUGkzVVSA3hCR/h1hxGrwohLzKX0VGjGRs5lkviLsGk/QI7kThtwcWr26uDrYVtVdBcBraj/c/TmoIJYXoBZMyBpKmgPv24ynNNYqcYiCSBYkiQQCbEhcXl9NJc00WPzYW900Vns4Oa0lZcdi96o4aE7HDMFj1mq55QawjRKaH9Jpj4nU56y8tx7CymZ9MmnPv2gd+PIiSEkNGjCRk/HuO0SzFMmoTiLLpdez0+GmxONle08M7+RnY370FtLsEY2oBPXY8fLxqlhvz4fOaMmMPUuKnEGmNPO2bxsx9GD7Qeho6jwXGGnXXQdBCOFYHfAxpDcExhRErwx5IW7FK2ZgQnpZzDVkOJnWIgkgSKIUECmRAXPp832FJYUdxEy7Fuutt7+7UWhkWHEJcWRu5lCcSmhfV7r7ejA0dREY49e3Hu3UtvWRn4fKhjYgidN4/Qq76OPi/v7JI0oLmrl/cONvJW6QmKjzah1B0nPKoClekgzkALACaNiYzwDHIsORQkFTA5bjIa5edvlTyFqxtqtkDNpmCrYUdtcCkbn/vkOfowSJkBGZcH1zOMSD77+52GxE4xEEkCxZAggUyIoScQCODs9mBrdtBY3cmJ6k5OVNlwOb2MviyBqQvT0f7bLiX/zm+30/3RR3S9/Q49W7aAx4M6Nhbz7AJMBbPRjxqJymI5q6SwuauX9w81saWihe3Vrdg5hirkOEZzCyHGFnoVR/HiQqswkRIymQnRl3BV1iWMjU0/6yT05AfzBVsL26qgtQoaS6F6I3TVBY9HZkHmFcEZySPyQa37UreT2CkGIkmgGBIkkAlxcXD3etnxzyOUflSHMUzHxCuTMVn06AxqQkwawmMMpyRaPpuN7g830v3hBuyF2wg4nQAoQkLQJMSjHzmK0HnzME6fhlL7xcbeeX1+SupsHy9o3cWhE13UtNkI6CtQmkpRm8tQqHqD9/OZsWjSSDanMiY6i2nJuYyOzsaoMX65hxIIQGtFcBeUqn8FJ6D43IACDFYwxwa7jY1RYIwMlkWkBBe+jkgdcJayxE4xEEkCxZAggUyIi0tTTRcbV5fTVt/Tr9wUoSN9fDRpE6KISwtDoeyfEPp7e3EU78JdW4unrg53fR3OXbvx2WwozWZMBbPQpaWjiYtFHReHflQuKtPZJ2kOt5v1VSVsqNnJgdb9tHqO4Fe1oFB6+85R+qyEBBKxatJIMWeTaxlFblwi45LCCQs5i+5ktx1qNkPDPuhphO6m4PI1jlawt4LHcfJcrRlicj8eY5ge/DcmNzjuUKGQ2CkGJEmgGBIkkAlx8fH7A3S3OXE5vLjsXrrbe6kpbeX4oXZ8Xj+mCB1ZU2LJviQWS/yZE7mAx4O9qKiv69jX1tZ3TKHVYpw+HfMVczHPno0q9MwLXn9ejV0ONh85zM76Q9TZj9DiqsXmO4qbZlAEf6X63RH4HOlEq8cwJXYKYxMSSY80kh5tItqs+3Ldym47tFYGu5JPlAYnobRXBxPFT+jCIG4Mi9/USuwUZyRJoDjvuru7ueWWW6iuruYvf/kLWVlZn/keSQKFGD7cTi+1+1up2NnEsUPtBPwBIuKMhEWFYAzXYQrXER5jwJoQLPv0Psd+pxPPiUY8dcfp2bqV7g/W421sRKHRYJo1i9AF8zHNnPmFu44/S4+7h7K2MopPlLK9YTeH2nfjDgRb7fyuSHy9Cfh649F6UxlhHElqpJkRFiORJi1WkxarUUeSxUBSRAjqAfZuPqPeLmirhMYDcGIfnChh8bvhEjvFGUkSKM47j8dDd3c3jz/+OLfeeqskgUKIM3J0uaksbuJ4WTs9HS7sNhe9dk/fcaVagTXeRExKKDGpwZ/waEO/buSA309vaSld775L59vv4GttRRkWRviiRUR8+0a0SUnnpO5ev5eDbQcpaihib9MBytrLaHcFW+tUgRBU7mzstmS8Pi0ElICSgCcMpTeWlIhIkiwGjDo1Jp2KUL2GKakWpmVEoteceWHuT5PYKQZy+mlZQpxDGo0Gi8Uy2NUQQgwBhlAtYy9PYuzlJxM1j9uHrdFBe0MPbfV2Wo53c3hnIwc21wOg0amITDIRPSKU1LGRxGeFEzJuHCHjxhF9993YtxfR+cbrtK9eTfuf/4ypoCC4BM2oUWiTk89qXcLTUSvVjI0ay9iosX1lHb0d7Graxdb6rWyt34pbt4/TjRpsx0qnJwGFPRmPcwQ9tjh+v1mNXqNkRmYUYxLCCDdoCDdoiTLryEsIw6STX+nii5FvjBjQ6tWref3116moqODqq6/mscce6ztms9n4+c9/TmFhIREREdx5553Mnz9/EGsrhBgONFoVUSPMRI0w95X5/QE6Gu0013bRcrSbluPdHNxST8mHx4lMMjH28iQyJ8WgUqsxzZiOacZ0opua6HjtNWx/+Ss9H34IgMJgQJeRgToyErXVgspqxXz55YSMHv2V1D1CH8Hc5LnMTZ5LIBCgydGEx+/BH/Dj9Xup666j0lZJRUcFZW1l1HatAxMYolWMNOWgdedQWp/I+vII8GuBYMKqVEBWjJnxIyJIsRqIDdMTE6r/SuosLl6SBIoBRUdHs2TJErZs2YLL5ep3bOXKlWg0GgoLCykrK+O2224jJyeHzMxMWlpauPPOO0+53pNPPknUafYJFUKIL0OpDHYLW+NNjLw0WOZ1+6jY2cS+DcfZ8KcyitYeYcr8VHLy41AqFWhiYohevpyoH/8YV1UVvWXl9JaX466uwlNfj3N/Kb72Dtqe+z3Gy2YQ+eMfYxg//iurs0KhINYY268sPTydmUkz+17bem2Utpayt3kvRQ1FHOx+nUBkAHNk8LhWqcOoDiNcmYnHkcJbZbF0d1uAYJfxhK+stuJiJGMCxefy29/+lqampr6WQIfDwZQpU1i3bh2pqakA3H333cTExLBixYrPdc17771XxgQKIc65QCDAsUPt7FxXQ3NtF5Z4I/mL0knOs37mLF1fj52OV16h/YUX8Nls6DIzUUdHo4qIQG21osvKRD9yJNqMjK98osnpdLo62dm4k4aeBhweBw6vg0Z7I3ua99DsaAZApVARqY/Boo3H+1KnxE5xRtISKM5KbW0tKpWqLwEEyMnJobi4+HO9/4c//CFlZWXU1NRw/fXXs3jx4nNVVSHEMKdQKEjOtTJilIXqPS0Ura3m7f8txWzVkzExmsxJMUQmmU6bEKpMRiJ/9EMs376Rjr/8FceOHXg7OnAfO4a3pYVAb3AhaTQaDOPGYZ53JaFXXIE6MvKcfJYwXRhzk+eeUh4IBKjrqWNv815qO2up667jePdxvKe5hhCfkCRQnBWHw4HJZOpXZjabsdvtn+v9f/zjH89FtYQQ4owUCgUZE6NJHRdJZXETlcVNlPzrOHs/OEZIqJbIRBORiSYscUZ0Rg26EDU6g5rwWAMqoxHrrbdgvfWWvusF/H7cR4/iKi+n9+BBujd+RNPKX9H08CPoc3NRWywoQ0NRhYVhmDQR04wZKI1fcneRAT5bkjmJJHP/mc6LX5A/sMWZSRIozorBYKCnp/9K/z09PRjPUYATQoivikqlJGdqHDlT4+jt8XBkXwsnjnTSerybkg+P4/f2HyUVYtaQNTmW7PxYopJOTkZRKJXoUlPRpaYSOm8eUXfdhauyku733sOxZy/elhZ8R47ga2ujY/Xq4MLV06ZhmDgBlcWKyhKBOjIKXWrKOUsOhRiIJIHirKSkpODz+aitrSUlJQWA8vJyMjIyBrdiQgjxBehNGkZNj2fU9HgAfD4/3W29uJ1eXE4vzi43R/a2sH9zHSUfHscSbyRtXBRp46OITOzfhaxQKNBnZaH/1DjngNeLY88euv/1L7r/9S96Nm7sXwmFAk1iIrqsLPQjR6LPyyUkNxe1TKIT55gkgWJAXq8Xn8+H3+/H5/PhcrlQqVQYDAbmzp3L008/zcMPP0xZWRkbNmzgtddeG+wqCyHEWVOplIRHG/qVZU2JpdfuobK4iardzex+t5Zd79RituiJGmEmItZARJwRs1VPiElDiFmLzqDuSxAVajXGKVMwTplCzH334bc78HW042tvx9PUhKuqCldFJa6KiuBSNR/P11THxWGYMIGQiRMwTJiALjMTherzLxQtxGeR2cFiQKtWreKZZ57pV7Z06VKWLVuGzWbj/vvvZ9u2bYSHh3PXXXeds3UCZXawEOJC4ex2U1PayrEDbbSfsGNrdhLwn/qrVKlWoFIpUWmUjMi1kDsjgbj0sAFnJPvtdnrLynAeOIBzXwnO3bvxtrQAwTUMQ3Jz0Y8ZjT4nB21yMtrkZFRhYWe8nsROMRBJAsWQIIFMCHGh8nn9dDY7sdtcOLrdOLvduBxe/D4/Pm+AXruHmn0tuHt9RMQZycmPJWV0JBGxhs9coiYQCATXLNyzB2fpfpylpbjKygh4Tm6dp7Ja0eeOIiQvD31eHoZJk1CFhgISO8XApDtYCCGE+BJUaiWWeCOW+DNP7vC4fFTuauLglga2v17N9terCY3UM2KUlfBYA6GRIYRG6omIMaBUndy2TqFQoE1MRJuYSNiCBQD43W48x47hPnoUd+1RXNXV9B48SGvhH8DnA5UKw4QJmGbNOtcfXQxxkgQKIYQQ55hGp2LUtHhGTYunu72XowfaOLq/lcM7GvG4fH3nmSJ05M5IYOS0OIxhutNeS6nVosvIQPepiXh+p5Pegwfp2bKVno8+ovmJJ2DUyHP6ucTQJt3BYkiQLg0hxMUoEAjg7PbQ1ebE1uTgcFEjdeUdKJUKkkdbSRppITEngvCYz+46/jRPYyPXL1kisVOckbQECiGEEINEoVBgCNViCNUSmxpGztQ4bE0ODmyqp3pvMzUlrQCEhGoJteoxhukwhGmxxBlJyI4YcFyhJjb2tOVCfEKSQCGEEOICEh5jYPo3M5l2XQadLU7qD3ftO9PDAAAJRklEQVTQWN1Jd4eLjkY7dYc7cDuDG8IZQrXEpIYSYtKgNQR3OQmLDiEy0UTYp5a6EeLTJAkUQgghLkAKhYLwaAPh0QZyZyT0lQcCAbpandQftlF3uIPW49001XpxO7143f6+89Ra5ekuK0QfSQKFEEKIIUShUBAWZSAsytC308knvB4fHScctNb10FbXw/uyfr8YgCSBQgghxEVCrVERNcJM1IjgHsdPShIoBiBtxUIIIYQQw5AkgUIIIYQQw5AkgUIIIYQQw5AkgUIIIYQQw5AkgUIIIYQQw5AkgUIIIYQQw5AkgUIIIYQQw5AkgUIIIYQQw5AkgUIIIYQQw5AkgUIIIYQQw5AkgUIIIYQQw5AkgUIIIYQQw5AkgUIIIYQQw5B6sCsghp/S0lIeeeQR1Go1MTEx/Nd//RcajWawqyWEEEIMK9ISKM672NhY/vznP7NmzRoSEhLYsGHDYFdJCCGEGHakJVCcd9HR0X3/12g0KJXyt4gQQghxvslvXzGg1atXs3jxYvLy8rj33nv7HbPZbNx+++2MGzeOgoIC1q1b94WuXV9fT2FhIQUFBV9llYUQQgjxOUhLoBhQdHQ0S5YsYcuWLbhcrn7HVq5ciUajobCwkLKyMm677TZycnLIzMykpaWFO++885TrPfnkk0RFRdHT08M999zDo48+KuMBhRBCiEEgSaAY0BVXXAHA/v37aWpq6it3OBx88MEHrFu3DqPRyKRJk5g9ezb//Oc/WbFiBVFRUbz88sunvabX6+WOO+5g6dKlpKWlnZfPIYQQQoj+JAkUZ6W2thaVSkVqampfWU5ODsXFxZ/53rfeeovS0lKeffZZnn32Wb71rW/x9a9/fcD31NfXs3jx4i9dbyGEGE7q6+sHuwriAiZJoDgrDocDk8nUr8xsNmO32z/zvQsXLmThwoVf6H47duz4QucLIYQQYmAyMUScFYPBQE9PT7+ynp4ejEbjINVICCGEEF+EJIHirKSkpODz+aitre0rKy8vJyMjY/AqJYQQQojPTZJAMSCv14vL5cLv9+Pz+XC5XHi9XgwGA3PnzuXpp5/G4XCwe/duNmzYwDXXXDPYVRZCCCHE56AIBAKBwa6EuHCtWrWKZ555pl/Z0qVLWbZsGTabjfvvv59t27YRHh7OXXfdxfz58weppkIIIYT4IiQJFEIIIYQYhqQ7WAghhBBiGJIkUAghhBBiGJIkUFzQvuz+xEOZ2+3m/vvvp6CggPHjx3PNNdewadOmvuPbt2/nyiuvZOzYsdx0003DalHY2tpaRo8ezYoVK/rK1q1bR0FBAePGjWPJkiXYbLZBrOH58fbbbzNv3jzGjRvHnDlz2LVrFzA8vxt1dXX88Ic/ZPLkyUybNo2VK1fi9XoBKCsrY/HixYwdO5bFixdTVlY2yLUV4sIgSaC4oP37/sRPPPEE//mf/0llZeVgV+u88Hq9xMXF8fLLL7N7925++tOf8tOf/pS6ujra29tZunQpy5cvZ+fOneTl5XHHHXcMdpXPm5UrVzJ69Oi+15WVlfziF7/g8ccfp7CwkJCQEB566KFBrOG5V1hYyG9+8xseffRR9uzZw5o1a0hKShq2342HHnoIq9XK1q1bWbt2LcXFxbzyyiu43W6WLFnCggULKC4uZuHChSxZsgS32z3YVRZi0EkSKC5Yn+xPvHz58lP2Jx4ODAYDy5YtIzExEaVSSUFBAYmJiRw8eJD169eTmZnJvHnz0Ol0LFu2jPLycqqrqwe72ufc22+/jdlsJj8/v69s3bp1zJ49m8mTJ2M0Glm+fDnr168/ZUHzi8mqVatYsmQJ48aNQ6lUEhMTQ0xMzLD9btTV1fV95qioKKZPn05VVRU7d+7E6/Vy8803o9Vq+e53v0sgEKCoqGiwqyzEoJMkUFywzrQ/cVVV1SDWavC0trZSW1tLRkYGlZWVZGdn9x0zGAyMGDHion82PT09PP3009x33339yj/9PEaMGIFGo+m3mPnFxOfzceDAATo6Opg7dy6XXXYZK1eupLe3d9h+N26++WbefvttnE4nTU1NbNmyhRkzZlBVVUV2djYKhaLv3Ozs7Iv+eQjxeUgSKC5YX2Z/4ouNx+NhxYoVLFq0iPT0dBwOB2azud85JpPpon82//M//8O1115LbGxsv/Lh9jxaW1vxeDy89957rFmzhrVr13Lo0CF+97vfDbtn8YnJkydTVVXFxIkTueyyy8jLy2POnDnY7fZh+TyE+DwkCRQXLNmfOMjv93PPPfeg0Wh48MEHgdM/G7vdflE/m7KyMrZv3873vve9U44Nt++KXq8H4KabbiI6OhqLxcItt9zCpk2bhuV3w+/384Mf/IC5c+eyb98+ioqK6Ozs5IknnsBoNA675yHE5yVJoLhgyf7EEAgE+PnPf05rayurVq1Co9EAkJmZSXl5ed95DoeDY8eOXdTPZseOHdTX11NQUMC0adN44YUX+OCDD1i0aNEpz+P48eN4PB5SUlIGr8LnUFhYGLGxsf26OD/5/3D8bthsNhoaGvjOd76DVqslIiKCa6+9ls2bN5ORkcHhw4f5930RDh8+fFE/DyE+L0kCxQVL9ieGX/7yl1RXV/Pcc8/1tf4AzJ07l8rKSt5//31cLhf/+7//S3Z2Nunp6YNY23Pr+uuvZ/369axdu5a1a9dyww03MGvWLJ5//nnmz5/Pxo0b2bVrFw6Hg6eeeoq5c+eeMpzgYrJ48WJefvll2tra6Ozs5E9/+hOzZs0alt8Ni8VCYmIir776Kl6vl66uLt544w2ys7OZMmUKKpWKl156CbfbzerVqwGYOnXqINdaiMEn28aJC9pw3p+4vr6e2bNno9VqUavVfeUPPfQQCxYsYNu2baxcuZKGhgbGjh3Lo48+SmJi4iDW+PxatWoVR48e5Te/+Q0QnCH83//939hsNvLz83n00UcJDw8f5FqeOx6Ph0ceeYS33noLnU7HvHnzuPvuu9HpdMPyu1FWVsavf/1rysvLUSqVTJ06lQcffJDIyEgOHTrEAw88QFVVFenp6TzyyCOMGjVqsKssxKCTJFAIIYQQYhiS7mAhhBBCiGFIkkAhhBBCiGFIkkAhhBBCiGFIkkAhhBBCiGFIkkAhhBBCiGFIkkAhhBBCiGFIkkAhhBBCiGFIkkAhhBBCiGHo/wELLQfRARJloQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pt.lines(range(100), vals).y_label('Eigenvalues').data_labels(line_lables).show_legend() \\\n",
    "  .legend_out().y_min(0.01).y_scale('log').draw().save_as_pdf('fig-example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
