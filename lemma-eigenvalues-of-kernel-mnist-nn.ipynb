{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import tensorflow as tf\n",
    "\n",
    "from neural_tangents import stax\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "# Attacking\n",
    "from cleverhans.utils import clip_eta, one_hot\n",
    "\n",
    "# Plotting\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from utils import *\n",
    "\n",
    "sns.set_style(style='white')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\"\"\"\n",
    "diag_reg:\n",
    "    a scalar representing the strength of the diagonal regularization for\n",
    "    `k_train_train`, i.e. computing `k_train_train + diag_reg * I` during\n",
    "    Cholesky factorization or eigendecomposition.\n",
    "\"\"\"\n",
    "diag_reg = 1e-5\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.0\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'mnist'\n",
    "class_num   = 10\n",
    "image_shape = None\n",
    "\n",
    "train_size = 10000\n",
    "valid_size = 1024\n",
    "test_size  = 10000\n",
    "\n",
    "if DATASET =='mnist':\n",
    "    image_shape = (28, 28)\n",
    "elif DATASET == 'cifar10':\n",
    "    image_shape = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    }
   ],
   "source": [
    "x_train_all, y_train_all, x_test_all, y_test_all = tuple(onp.array(x) for x in get_dataset(DATASET, None, None, \n",
    "                                                                                  do_flatten_and_normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "seed = 0\n",
    "x_train_all, y_train_all = shaffle(x_train_all, y_train_all, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sample\n",
    "x_train = x_train_all[:train_size]\n",
    "y_train = y_train_all[:train_size]\n",
    "\n",
    "x_valid = x_train_all[train_size:train_size+valid_size]\n",
    "y_valid = y_train_all[train_size:train_size+valid_size]\n",
    "\n",
    "x_test = x_test_all[:test_size]\n",
    "y_test = y_test_all[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_valid, x_test = x_train.reshape((-1, *image_shape)), x_valid.reshape((-1, *image_shape)), x_test.reshape((-1, *image_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finite width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 64\n",
    "width = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_tick = [2**i for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "valid_ds = valid_ds.shuffle(5000)\n",
    "valid_ds = valid_ds.batch(batch)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.shuffle(20000)\n",
    "train_ds = train_ds.batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "re_lu_88 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_89 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_90 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_91 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_92 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_93 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_94 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_95 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 33,898\n",
      "Trainable params: 33,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.3002 - accuracy: 0.1350 - val_loss: 2.2982 - val_accuracy: 0.1152\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2938 - accuracy: 0.1440 - val_loss: 2.2894 - val_accuracy: 0.1895\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 2.2789 - accuracy: 0.1979 - val_loss: 2.2679 - val_accuracy: 0.2197\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2433 - accuracy: 0.2107 - val_loss: 2.2087 - val_accuracy: 0.2236\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.1296 - accuracy: 0.2129 - val_loss: 2.0227 - val_accuracy: 0.2246\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.9268 - accuracy: 0.2254 - val_loss: 1.8414 - val_accuracy: 0.2520\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.7596 - accuracy: 0.3088 - val_loss: 1.6666 - val_accuracy: 0.3535\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5584 - accuracy: 0.4081 - val_loss: 1.4455 - val_accuracy: 0.4336\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3089 - accuracy: 0.5170 - val_loss: 1.1830 - val_accuracy: 0.5381\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0444 - accuracy: 0.6632 - val_loss: 1.1673 - val_accuracy: 0.5459\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8187 - accuracy: 0.7402 - val_loss: 0.7798 - val_accuracy: 0.7588\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.7889 - val_loss: 0.6478 - val_accuracy: 0.7988\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.8303 - val_loss: 0.5687 - val_accuracy: 0.8418\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.8592 - val_loss: 0.4874 - val_accuracy: 0.8633\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8741 - val_loss: 0.4871 - val_accuracy: 0.8594\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8891 - val_loss: 0.5478 - val_accuracy: 0.8369\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.9012 - val_loss: 0.4020 - val_accuracy: 0.8965\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.9077 - val_loss: 0.3971 - val_accuracy: 0.8838\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.9158 - val_loss: 0.6229 - val_accuracy: 0.8330\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.9200 - val_loss: 0.3547 - val_accuracy: 0.9062\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.9306 - val_loss: 0.3450 - val_accuracy: 0.9121\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9333 - val_loss: 0.3627 - val_accuracy: 0.9023\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9382 - val_loss: 0.8041 - val_accuracy: 0.7832\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9405 - val_loss: 0.3594 - val_accuracy: 0.8984\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9448 - val_loss: 0.4259 - val_accuracy: 0.8896\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9468 - val_loss: 0.2979 - val_accuracy: 0.9238\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9517 - val_loss: 0.3505 - val_accuracy: 0.9141\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9535 - val_loss: 0.3351 - val_accuracy: 0.9180\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 0.9581 - val_loss: 0.3158 - val_accuracy: 0.9258\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1425 - accuracy: 0.9576 - val_loss: 0.2927 - val_accuracy: 0.9180\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9620 - val_loss: 0.3517 - val_accuracy: 0.9121\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9616 - val_loss: 0.3028 - val_accuracy: 0.9238\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9640 - val_loss: 1.4399 - val_accuracy: 0.7031\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1343 - accuracy: 0.9646 - val_loss: 0.4094 - val_accuracy: 0.8906\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.9690 - val_loss: 0.4160 - val_accuracy: 0.8975\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9731 - val_loss: 0.4910 - val_accuracy: 0.8818\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9705 - val_loss: 0.3291 - val_accuracy: 0.9238\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9770 - val_loss: 0.4447 - val_accuracy: 0.8936\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9749 - val_loss: 0.4287 - val_accuracy: 0.9141\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.9771 - val_loss: 0.3301 - val_accuracy: 0.9199\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9792 - val_loss: 0.3273 - val_accuracy: 0.9268\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9835 - val_loss: 0.4836 - val_accuracy: 0.9004\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9813 - val_loss: 0.3805 - val_accuracy: 0.9150\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9819 - val_loss: 1.3978 - val_accuracy: 0.7393\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9533 - val_loss: 0.3792 - val_accuracy: 0.9180\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9842 - val_loss: 0.4052 - val_accuracy: 0.9180\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9857 - val_loss: 0.3900 - val_accuracy: 0.9170\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9868 - val_loss: 0.3862 - val_accuracy: 0.9199\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9887 - val_loss: 0.3498 - val_accuracy: 0.9248\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9900 - val_loss: 0.3620 - val_accuracy: 0.9258\n",
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "re_lu_96 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_97 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_98 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_99 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_100 (ReLU)             (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_101 (ReLU)             (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_102 (ReLU)             (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_103 (ReLU)             (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 84,170\n",
      "Trainable params: 84,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.2983 - accuracy: 0.1126 - val_loss: 2.2930 - val_accuracy: 0.1250\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2817 - accuracy: 0.1587 - val_loss: 2.2689 - val_accuracy: 0.2236\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 2.2308 - accuracy: 0.2566 - val_loss: 2.1692 - val_accuracy: 0.2646\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.9640 - accuracy: 0.3321 - val_loss: 1.7085 - val_accuracy: 0.3740\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4433 - accuracy: 0.4877 - val_loss: 1.2752 - val_accuracy: 0.5459\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.1348 - accuracy: 0.6115 - val_loss: 1.0175 - val_accuracy: 0.6455\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8502 - accuracy: 0.7199 - val_loss: 0.7774 - val_accuracy: 0.7588\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.7919 - val_loss: 0.7344 - val_accuracy: 0.7646\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.8268 - val_loss: 0.7895 - val_accuracy: 0.7402\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8619 - val_loss: 0.6529 - val_accuracy: 0.7725\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8758 - val_loss: 0.4552 - val_accuracy: 0.8652\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8923 - val_loss: 0.4943 - val_accuracy: 0.8467\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.9001 - val_loss: 0.4467 - val_accuracy: 0.8740\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.9125 - val_loss: 0.4009 - val_accuracy: 0.8926\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.9197 - val_loss: 0.7749 - val_accuracy: 0.7637\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.9274 - val_loss: 0.7307 - val_accuracy: 0.7871\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9327 - val_loss: 0.3265 - val_accuracy: 0.9014\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9397 - val_loss: 0.2988 - val_accuracy: 0.9062\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9462 - val_loss: 0.2931 - val_accuracy: 0.9092\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9455 - val_loss: 0.3127 - val_accuracy: 0.9248\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9514 - val_loss: 0.2791 - val_accuracy: 0.9297\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9564 - val_loss: 0.2920 - val_accuracy: 0.9111\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9562 - val_loss: 0.3285 - val_accuracy: 0.9199\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9609 - val_loss: 0.2865 - val_accuracy: 0.9209\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.9628 - val_loss: 0.2673 - val_accuracy: 0.9307\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1133 - accuracy: 0.9670 - val_loss: 0.2734 - val_accuracy: 0.9326\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9710 - val_loss: 0.4764 - val_accuracy: 0.8828\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9684 - val_loss: 0.2597 - val_accuracy: 0.9326\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.9737 - val_loss: 0.8089 - val_accuracy: 0.8164\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9735 - val_loss: 0.3469 - val_accuracy: 0.9180\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9764 - val_loss: 0.3513 - val_accuracy: 0.9004\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9804 - val_loss: 0.3293 - val_accuracy: 0.9238\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9815 - val_loss: 0.3146 - val_accuracy: 0.9326\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9854 - val_loss: 0.3649 - val_accuracy: 0.9268\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9869 - val_loss: 0.3067 - val_accuracy: 0.9307\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9833 - val_loss: 0.2972 - val_accuracy: 0.9316\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9897 - val_loss: 0.2999 - val_accuracy: 0.9336\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9894 - val_loss: 0.3250 - val_accuracy: 0.9248\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9882 - val_loss: 0.3127 - val_accuracy: 0.9355\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9915 - val_loss: 0.3129 - val_accuracy: 0.9404\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9919 - val_loss: 0.4934 - val_accuracy: 0.8838\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9907 - val_loss: 0.3294 - val_accuracy: 0.9346\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9943 - val_loss: 0.3590 - val_accuracy: 0.9307\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9959 - val_loss: 0.3451 - val_accuracy: 0.9336\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9961 - val_loss: 0.3275 - val_accuracy: 0.9346\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9968 - val_loss: 0.6134 - val_accuracy: 0.8916\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.3614 - val_accuracy: 0.9385\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9978 - val_loss: 0.3679 - val_accuracy: 0.9385\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9975 - val_loss: 0.3645 - val_accuracy: 0.9395\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9742 - val_loss: 0.3220 - val_accuracy: 0.9316\n",
      "Model: \"functional_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "re_lu_104 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_105 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_106 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_107 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_108 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_109 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_110 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_111 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 233,866\n",
      "Trainable params: 233,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.2906 - accuracy: 0.1693 - val_loss: 2.2793 - val_accuracy: 0.2080\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2486 - accuracy: 0.2886 - val_loss: 2.2030 - val_accuracy: 0.3203\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 1.9668 - accuracy: 0.4147 - val_loss: 1.5558 - val_accuracy: 0.4922\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.1752 - accuracy: 0.6009 - val_loss: 1.3066 - val_accuracy: 0.5449\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.7765 - accuracy: 0.7435 - val_loss: 1.0907 - val_accuracy: 0.6494\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.8062 - val_loss: 0.8674 - val_accuracy: 0.7002\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8517 - val_loss: 0.6448 - val_accuracy: 0.8018\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8728 - val_loss: 0.4811 - val_accuracy: 0.8545\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8942 - val_loss: 0.4598 - val_accuracy: 0.8516\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.9061 - val_loss: 0.3606 - val_accuracy: 0.8926\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.9139 - val_loss: 0.4375 - val_accuracy: 0.8594\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.9225 - val_loss: 0.3315 - val_accuracy: 0.9004\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9289 - val_loss: 0.3379 - val_accuracy: 0.9092\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9377 - val_loss: 0.3724 - val_accuracy: 0.8896\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9424 - val_loss: 0.3142 - val_accuracy: 0.9033\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9483 - val_loss: 0.2729 - val_accuracy: 0.9199\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9524 - val_loss: 0.2895 - val_accuracy: 0.9150\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9569 - val_loss: 0.4830 - val_accuracy: 0.8662\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.9566 - val_loss: 0.2751 - val_accuracy: 0.9219\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9618 - val_loss: 0.2806 - val_accuracy: 0.9170\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9633 - val_loss: 0.2385 - val_accuracy: 0.9346\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9708 - val_loss: 0.7613 - val_accuracy: 0.8418\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9716 - val_loss: 0.2360 - val_accuracy: 0.9404\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9750 - val_loss: 0.3822 - val_accuracy: 0.8984\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9789 - val_loss: 0.2173 - val_accuracy: 0.9463\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9815 - val_loss: 0.3103 - val_accuracy: 0.9238\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9809 - val_loss: 0.2418 - val_accuracy: 0.9395\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9834 - val_loss: 0.2145 - val_accuracy: 0.9531\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9851 - val_loss: 0.2329 - val_accuracy: 0.9482\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9850 - val_loss: 0.2483 - val_accuracy: 0.9404\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9879 - val_loss: 0.3712 - val_accuracy: 0.9121\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9902 - val_loss: 0.2303 - val_accuracy: 0.9453\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9918 - val_loss: 0.2658 - val_accuracy: 0.9346\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9934 - val_loss: 0.2457 - val_accuracy: 0.9424\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9719 - val_loss: 0.3392 - val_accuracy: 0.9150\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9930 - val_loss: 0.2796 - val_accuracy: 0.9375\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9951 - val_loss: 0.2523 - val_accuracy: 0.9424\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9962 - val_loss: 0.2456 - val_accuracy: 0.9482\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9962 - val_loss: 0.2527 - val_accuracy: 0.9453\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9978 - val_loss: 0.2402 - val_accuracy: 0.9512\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.9980 - val_loss: 0.2384 - val_accuracy: 0.9512\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9986 - val_loss: 0.2566 - val_accuracy: 0.9482\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9984 - val_loss: 0.2538 - val_accuracy: 0.9473\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.2633 - val_accuracy: 0.9453\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9987 - val_loss: 0.2679 - val_accuracy: 0.9492\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9987 - val_loss: 0.2737 - val_accuracy: 0.9463\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.2751 - val_accuracy: 0.9502\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.2817 - val_accuracy: 0.9502\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.2873 - val_accuracy: 0.9492\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9997 - val_loss: 0.3009 - val_accuracy: 0.9482\n",
      "Model: \"functional_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "re_lu_112 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_113 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_114 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_115 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_116 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_117 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_118 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_119 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 729,866\n",
      "Trainable params: 729,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.2937 - accuracy: 0.1690 - val_loss: 2.2840 - val_accuracy: 0.2373\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2594 - accuracy: 0.3405 - val_loss: 2.2247 - val_accuracy: 0.3799\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 2.0382 - accuracy: 0.4519 - val_loss: 1.6499 - val_accuracy: 0.5049\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.1436 - accuracy: 0.6504 - val_loss: 0.8184 - val_accuracy: 0.7432\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.7722 - val_loss: 0.6477 - val_accuracy: 0.7988\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.8465 - val_loss: 0.6478 - val_accuracy: 0.7910\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8713 - val_loss: 0.4944 - val_accuracy: 0.8428\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8898 - val_loss: 0.4022 - val_accuracy: 0.8682\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.9084 - val_loss: 0.4135 - val_accuracy: 0.8740\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.9187 - val_loss: 0.3834 - val_accuracy: 0.8857\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.9251 - val_loss: 0.4113 - val_accuracy: 0.8818\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9326 - val_loss: 0.3013 - val_accuracy: 0.9072\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9416 - val_loss: 0.7250 - val_accuracy: 0.7764\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9457 - val_loss: 0.2918 - val_accuracy: 0.9131\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1573 - accuracy: 0.9540 - val_loss: 0.2261 - val_accuracy: 0.9375\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9560 - val_loss: 0.2352 - val_accuracy: 0.9268\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.9656 - val_loss: 0.2198 - val_accuracy: 0.9375\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9662 - val_loss: 0.2308 - val_accuracy: 0.9297\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.9683 - val_loss: 1.4818 - val_accuracy: 0.6738\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9696 - val_loss: 0.3413 - val_accuracy: 0.9043\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.9762 - val_loss: 0.2378 - val_accuracy: 0.9346\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.9784 - val_loss: 0.2874 - val_accuracy: 0.9150\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9819 - val_loss: 0.1945 - val_accuracy: 0.9482\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9831 - val_loss: 0.2002 - val_accuracy: 0.9463\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9865 - val_loss: 0.2794 - val_accuracy: 0.9219\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9874 - val_loss: 0.2088 - val_accuracy: 0.9463\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9882 - val_loss: 0.2159 - val_accuracy: 0.9404\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9898 - val_loss: 0.1881 - val_accuracy: 0.9541\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9902 - val_loss: 0.1925 - val_accuracy: 0.9551\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9937 - val_loss: 0.2087 - val_accuracy: 0.9424\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9941 - val_loss: 0.2113 - val_accuracy: 0.9473\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9960 - val_loss: 0.2151 - val_accuracy: 0.9443\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9962 - val_loss: 0.1960 - val_accuracy: 0.9551\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9970 - val_loss: 0.1968 - val_accuracy: 0.9531\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 0.2189 - val_accuracy: 0.9473\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9981 - val_loss: 0.9591 - val_accuracy: 0.8076\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9640 - val_loss: 0.1881 - val_accuracy: 0.9482\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9959 - val_loss: 0.1899 - val_accuracy: 0.9531\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9988 - val_loss: 0.4001 - val_accuracy: 0.9004\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.2097 - val_accuracy: 0.9551\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9994 - val_loss: 0.2203 - val_accuracy: 0.9502\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.2111 - val_accuracy: 0.9531\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.2225 - val_accuracy: 0.9531\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.2200 - val_accuracy: 0.9521\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.2229 - val_accuracy: 0.9531\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.2243 - val_accuracy: 0.9541\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.2274 - val_accuracy: 0.9512\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.2383 - val_accuracy: 0.9541\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.2410 - val_accuracy: 0.9541\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.2377 - val_accuracy: 0.9521\n",
      "Model: \"functional_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "re_lu_120 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_121 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_122 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_123 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_124 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_125 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_126 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_127 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,508,298\n",
      "Trainable params: 2,508,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 2.2825 - accuracy: 0.2333 - val_loss: 2.2565 - val_accuracy: 0.4902\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 2.1509 - accuracy: 0.4839 - val_loss: 1.9040 - val_accuracy: 0.5361\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.3109 - accuracy: 0.6573 - val_loss: 0.7944 - val_accuracy: 0.7412\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.7937 - val_loss: 0.6146 - val_accuracy: 0.8018\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.8489 - val_loss: 1.2339 - val_accuracy: 0.5664\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8826 - val_loss: 0.5142 - val_accuracy: 0.8418\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8973 - val_loss: 0.7334 - val_accuracy: 0.7793\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.9126 - val_loss: 0.3417 - val_accuracy: 0.9014\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.9248 - val_loss: 0.3167 - val_accuracy: 0.9141\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.2185 - accuracy: 0.9335 - val_loss: 0.2765 - val_accuracy: 0.9180\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9415 - val_loss: 0.3155 - val_accuracy: 0.9043\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1713 - accuracy: 0.9486 - val_loss: 0.2307 - val_accuracy: 0.9297\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9570 - val_loss: 0.2230 - val_accuracy: 0.9316\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9599 - val_loss: 0.2265 - val_accuracy: 0.9375\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1173 - accuracy: 0.9667 - val_loss: 0.2240 - val_accuracy: 0.9326\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.9698 - val_loss: 0.1983 - val_accuracy: 0.9414\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0943 - accuracy: 0.9722 - val_loss: 0.1979 - val_accuracy: 0.9473\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.9757 - val_loss: 0.1871 - val_accuracy: 0.9473\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9811 - val_loss: 0.1914 - val_accuracy: 0.9482\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9824 - val_loss: 0.2300 - val_accuracy: 0.9365\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9868 - val_loss: 0.3172 - val_accuracy: 0.9160\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9874 - val_loss: 1.3904 - val_accuracy: 0.7061\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9617 - val_loss: 0.1758 - val_accuracy: 0.9512\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9909 - val_loss: 0.1749 - val_accuracy: 0.9531\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9939 - val_loss: 0.1864 - val_accuracy: 0.9492\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9946 - val_loss: 0.1912 - val_accuracy: 0.9502\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9965 - val_loss: 0.1924 - val_accuracy: 0.9492\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9966 - val_loss: 0.2444 - val_accuracy: 0.9414\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9972 - val_loss: 0.2042 - val_accuracy: 0.9541\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9982 - val_loss: 0.2295 - val_accuracy: 0.9463\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 0.2079 - val_accuracy: 0.9551\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9993 - val_loss: 0.2182 - val_accuracy: 0.9521\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9996 - val_loss: 0.2216 - val_accuracy: 0.9502\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.2194 - val_accuracy: 0.9561\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9997 - val_loss: 0.2182 - val_accuracy: 0.9512\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.2258 - val_accuracy: 0.9541\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.2326 - val_accuracy: 0.9531\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.2358 - val_accuracy: 0.9512\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.2506 - val_accuracy: 0.9541\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.2433 - val_accuracy: 0.9561\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.2408 - val_accuracy: 0.9570\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.2443 - val_accuracy: 0.9541\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.2531 - val_accuracy: 0.9551\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9492\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9551\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9512\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9541\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9541\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9541\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9551\n",
      "Model: \"functional_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "re_lu_128 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_129 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_130 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_131 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_132 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_133 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_134 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_135 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 9,210,890\n",
      "Trainable params: 9,210,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 2.2783 - accuracy: 0.3117 - val_loss: 2.2434 - val_accuracy: 0.4375\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 2.0847 - accuracy: 0.4940 - val_loss: 1.7426 - val_accuracy: 0.5322\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.1281 - accuracy: 0.6858 - val_loss: 0.7109 - val_accuracy: 0.8115\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.5845 - accuracy: 0.8234 - val_loss: 0.5029 - val_accuracy: 0.8389\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.4031 - accuracy: 0.8787 - val_loss: 0.4570 - val_accuracy: 0.8691\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8979 - val_loss: 0.3679 - val_accuracy: 0.8916\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.9135 - val_loss: 0.3150 - val_accuracy: 0.9072\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.2461 - accuracy: 0.9257 - val_loss: 0.3220 - val_accuracy: 0.9141\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.2124 - accuracy: 0.9386 - val_loss: 0.4945 - val_accuracy: 0.8311\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.2007 - accuracy: 0.9403 - val_loss: 0.3721 - val_accuracy: 0.8916\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1678 - accuracy: 0.9514 - val_loss: 0.2453 - val_accuracy: 0.9346\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1510 - accuracy: 0.9554 - val_loss: 0.2623 - val_accuracy: 0.9219\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1384 - accuracy: 0.9601 - val_loss: 0.2154 - val_accuracy: 0.9385\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1173 - accuracy: 0.9693 - val_loss: 0.2369 - val_accuracy: 0.9307\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1060 - accuracy: 0.9708 - val_loss: 0.2633 - val_accuracy: 0.9287\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0882 - accuracy: 0.9771 - val_loss: 0.3383 - val_accuracy: 0.9111\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9767 - val_loss: 0.2175 - val_accuracy: 0.9365\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0696 - accuracy: 0.9807 - val_loss: 0.2020 - val_accuracy: 0.9482\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9839 - val_loss: 0.1893 - val_accuracy: 0.9502\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0501 - accuracy: 0.9878 - val_loss: 0.1920 - val_accuracy: 0.9521\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0429 - accuracy: 0.9903 - val_loss: 0.1891 - val_accuracy: 0.9463\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0381 - accuracy: 0.9909 - val_loss: 0.1902 - val_accuracy: 0.9482\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.9932 - val_loss: 0.1932 - val_accuracy: 0.9482\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0269 - accuracy: 0.9946 - val_loss: 0.2981 - val_accuracy: 0.9336\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0228 - accuracy: 0.9959 - val_loss: 0.1936 - val_accuracy: 0.9502\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9973 - val_loss: 0.1964 - val_accuracy: 0.9482\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1422 - accuracy: 0.9767 - val_loss: 0.1980 - val_accuracy: 0.9453\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9924 - val_loss: 0.1884 - val_accuracy: 0.9502\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0190 - accuracy: 0.9977 - val_loss: 0.1907 - val_accuracy: 0.9541\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0131 - accuracy: 0.9989 - val_loss: 0.1929 - val_accuracy: 0.9482\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9991 - val_loss: 0.1874 - val_accuracy: 0.9551\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9995 - val_loss: 0.1975 - val_accuracy: 0.9531\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9998 - val_loss: 0.1958 - val_accuracy: 0.9551\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9998 - val_loss: 0.2104 - val_accuracy: 0.9541\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.2013 - val_accuracy: 0.9551\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 0.2048 - val_accuracy: 0.9561\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.2087 - val_accuracy: 0.9570\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 0.2104 - val_accuracy: 0.9541\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.2142 - val_accuracy: 0.9531\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.2178 - val_accuracy: 0.9570\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.2165 - val_accuracy: 0.9541\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.2229 - val_accuracy: 0.9521\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.2199 - val_accuracy: 0.9551\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.2421 - val_accuracy: 0.9443\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.2233 - val_accuracy: 0.9541\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.2321 - val_accuracy: 0.9521\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.2275 - val_accuracy: 0.9541\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9521\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9541\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9541\n",
      "Model: \"functional_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 2048)              1607680   \n",
      "_________________________________________________________________\n",
      "re_lu_136 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_137 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_138 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_139 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_140 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_141 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_142 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_143 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 35,198,986\n",
      "Trainable params: 35,198,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 15ms/step - loss: 2.2653 - accuracy: 0.2859 - val_loss: 2.2027 - val_accuracy: 0.5049\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.8275 - accuracy: 0.5903 - val_loss: 1.1572 - val_accuracy: 0.6289\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.7908 - accuracy: 0.7653 - val_loss: 0.9071 - val_accuracy: 0.6836\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4946 - accuracy: 0.8516 - val_loss: 0.4348 - val_accuracy: 0.8672\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3763 - accuracy: 0.8866 - val_loss: 0.3917 - val_accuracy: 0.8838\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3018 - accuracy: 0.9097 - val_loss: 0.3094 - val_accuracy: 0.9131\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2489 - accuracy: 0.9258 - val_loss: 0.4694 - val_accuracy: 0.8691\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2192 - accuracy: 0.9344 - val_loss: 0.5085 - val_accuracy: 0.8447\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1880 - accuracy: 0.9451 - val_loss: 0.3480 - val_accuracy: 0.8955\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1640 - accuracy: 0.9527 - val_loss: 0.3463 - val_accuracy: 0.8906\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1425 - accuracy: 0.9564 - val_loss: 0.3739 - val_accuracy: 0.8838\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1205 - accuracy: 0.9670 - val_loss: 0.2110 - val_accuracy: 0.9375\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1505 - accuracy: 0.9606 - val_loss: 0.2134 - val_accuracy: 0.9365\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0989 - accuracy: 0.9741 - val_loss: 0.2885 - val_accuracy: 0.9150\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0825 - accuracy: 0.9779 - val_loss: 0.1876 - val_accuracy: 0.9492\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0698 - accuracy: 0.9824 - val_loss: 0.5365 - val_accuracy: 0.8672\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0657 - accuracy: 0.9842 - val_loss: 0.1647 - val_accuracy: 0.9590\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0537 - accuracy: 0.9858 - val_loss: 0.1708 - val_accuracy: 0.9561\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0453 - accuracy: 0.9895 - val_loss: 0.1747 - val_accuracy: 0.9541\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0377 - accuracy: 0.9918 - val_loss: 0.1770 - val_accuracy: 0.9492\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9928 - val_loss: 0.1668 - val_accuracy: 0.9561\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0240 - accuracy: 0.9956 - val_loss: 0.1913 - val_accuracy: 0.9463\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0215 - accuracy: 0.9959 - val_loss: 0.1715 - val_accuracy: 0.9619\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0171 - accuracy: 0.9973 - val_loss: 0.1976 - val_accuracy: 0.9609\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0143 - accuracy: 0.9985 - val_loss: 0.1886 - val_accuracy: 0.9600\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0107 - accuracy: 0.9989 - val_loss: 0.1852 - val_accuracy: 0.9561\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0091 - accuracy: 0.9994 - val_loss: 0.1728 - val_accuracy: 0.9639\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0081 - accuracy: 0.9996 - val_loss: 0.1804 - val_accuracy: 0.9580\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0068 - accuracy: 0.9997 - val_loss: 0.1854 - val_accuracy: 0.9590\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 0.1863 - val_accuracy: 0.9600\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.1964 - val_accuracy: 0.9580\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 0.9998 - val_loss: 0.2188 - val_accuracy: 0.9531\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.1860 - val_accuracy: 0.9639\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.1891 - val_accuracy: 0.9590\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.1899 - val_accuracy: 0.9619\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.2029 - val_accuracy: 0.9541\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.2041 - val_accuracy: 0.9561\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.2001 - val_accuracy: 0.9580\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9561\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9570\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9570\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9561\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9590\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9580\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9561\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9561\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9590\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9551\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9570\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9570\n"
     ]
    }
   ],
   "source": [
    "# for multi in width_tick:\n",
    "#     img_input = layers.Input(shape=(28*28,))\n",
    "#     x = layers.Dense(width * multi)(img_input)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.Flatten()(x)\n",
    "#     out = layers.Dense(10)(x)\n",
    "    \n",
    "#     model = tf.keras.Model(img_input, out)\n",
    "#     model.summary()\n",
    "#     model.compile(optimizer='sgd',\n",
    "#               loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "#     model.fit(x=train_ds, validation_data=valid_ds, epochs=50)\n",
    "#     model.save_weights('./dense_10_weights/dense_10_with_multi_%s'%(str(multi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "100%|| 10000/10000 [56:53<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "100%|| 10000/10000 [58:11<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "100%|| 10000/10000 [57:48<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "100%|| 10000/10000 [1:13:34<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "100%|| 10000/10000 [1:14:33<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "100%|| 10000/10000 [1:14:34<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "100%|| 10000/10000 [1:49:31<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for multi in width_tick:\n",
    "    img_input = layers.Input(shape=(28*28,))\n",
    "    x = layers.Dense(width * multi)(img_input)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    out = layers.Dense(10)(x)\n",
    "    \n",
    "    model = tf.keras.Model(img_input, out)\n",
    "    model.load_weights('./dense_10_weights/dense_10_with_multi_%s'%(str(multi)))\n",
    "    \n",
    "    @tf.function\n",
    "    def get_cross_entropy_hessian(y, x):\n",
    "        y_pred = model(x)\n",
    "        cross_en = loss(y, y_pred)\n",
    "        return tf.hessians(cross_en, x)\n",
    "\n",
    "    hessians = 0\n",
    "    for x, y in zip(tqdm(x_test), y_test):\n",
    "        x_tensor = tf.convert_to_tensor(x.reshape(-1, 28*28))\n",
    "        y_tensor = tf.convert_to_tensor(y.reshape(-1, class_num))\n",
    "        hs = get_cross_entropy_hessian(y_tensor, x_tensor)\n",
    "        hs = tf.reshape(hs, (784, 784))\n",
    "        hessians += hs\n",
    "        \n",
    "    onp.save('./dense_10_hessians/dense_10_hessians_with_multi_%s'%(str(multi)), hessians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian = {\n",
    "    i : onp.load('./dense_10_hessians/dense_10_hessians_with_multi_%s.npy'%(str(i))) for i in width_tick\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return onp.allclose(a, a.T, rtol=rtol, atol=atol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[::-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paper_plot as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = []\n",
    "line_lables = []\n",
    "for k, v in hessian.items():\n",
    "    val, vec = onp.linalg.eigh(v)\n",
    "    vals.append(val[:-21:-1])\n",
    "    line_lables.append(\"width = %s\"%(str(k*width)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<paper_plot.FigureBuilder at 0x7f0e2491d6d8>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pt.lines(range(20), vals).y_label('Eigenvalues').data_labels(line_lables).show_legend() \\\n",
    "  .legend_out().y_min(100).y_scale('log').x_ticks([1, 5, 10, 15, 20]).draw().save_as_pdf('fig-example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infinite width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nthudatalab1/yurong/ntk-env/lib/python3.6/site-packages/neural_tangents/utils/batch.py:616: UserWarning: Batch size is reduced from requested 256 to effective 64 to fit the dataset.\n",
      "  'fit the dataset.' % (batch_size, n2_batch_size))\n"
     ]
    }
   ],
   "source": [
    "batch_inf_kernel_fn = nt.batch(kernel_fn, batch_size=256, store_on_device=False)\n",
    "\n",
    "kernel_train_m = batch_inf_kernel_fn(x_train_down, None, 'ntk')\n",
    "\n",
    "eigval_inf, eigv_inf = np.linalg.eigh(kernel_train_m + np.eye(train_size)*diag_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_samples(arr, attack_type, layer):\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(6, 3), sharex=True)\n",
    "    for row, ax in enumerate(axs):\n",
    "        for idx, a in enumerate(ax):\n",
    "            img = arr[idx + row*4].reshape(image_shape)\n",
    "            a.axis('off')\n",
    "            a.xaxis.set_visible(False)\n",
    "            a.yaxis.set_visible(False)\n",
    "            a.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(arr, attack_type, layer):\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(6, 3), sharex=True)\n",
    "    for row, ax in enumerate(axs):\n",
    "        for idx, a in enumerate(ax):\n",
    "            img = arr[idx + row*4].reshape(image_shape)\n",
    "            a.axis('off')\n",
    "            a.xaxis.set_visible(False)\n",
    "            a.yaxis.set_visible(False)\n",
    "            a.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./fig-%s-untargeted/%s_layer_%d.png\"%(DATASET ,attack_type, layer+1), dpi=150)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
