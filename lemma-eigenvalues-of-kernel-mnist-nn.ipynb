{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import tensorflow as tf\n",
    "\n",
    "from neural_tangents import stax\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "# Attacking\n",
    "from cleverhans.utils import clip_eta, one_hot\n",
    "\n",
    "# Plotting\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from utils import *\n",
    "\n",
    "sns.set_style(style='white')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\"\"\"\n",
    "diag_reg:\n",
    "    a scalar representing the strength of the diagonal regularization for\n",
    "    `k_train_train`, i.e. computing `k_train_train + diag_reg * I` during\n",
    "    Cholesky factorization or eigendecomposition.\n",
    "\"\"\"\n",
    "diag_reg = 1e-5\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.0\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'mnist'\n",
    "class_num   = 10\n",
    "image_shape = None\n",
    "\n",
    "train_size = 10000\n",
    "valid_size = 1024\n",
    "test_size  = 64\n",
    "\n",
    "if DATASET =='mnist':\n",
    "    image_shape = (28, 28)\n",
    "elif DATASET == 'cifar10':\n",
    "    image_shape = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    }
   ],
   "source": [
    "x_train_all, y_train_all, x_test_all, y_test_all = tuple(onp.array(x) for x in get_dataset(DATASET, None, None, \n",
    "                                                                                  do_flatten_and_normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "seed = 0\n",
    "x_train_all, y_train_all = shaffle(x_train_all, y_train_all, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sample\n",
    "x_train = x_train_all[:train_size]\n",
    "y_train = y_train_all[:train_size]\n",
    "\n",
    "x_valid = x_train_all[train_size:train_size+valid_size]\n",
    "y_valid = y_train_all[train_size:train_size+valid_size]\n",
    "\n",
    "x_test = x_test_all[:test_size]\n",
    "y_test = y_test_all[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_valid, x_test = x_train.reshape((-1, *image_shape)), x_valid.reshape((-1, *image_shape)), x_test.reshape((-1, *image_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finite width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 64\n",
    "width = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_tick = [2**i for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "valid_ds = valid_ds.shuffle(5000)\n",
    "valid_ds = valid_ds.batch(batch)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.shuffle(20000)\n",
    "train_ds = train_ds.batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "re_lu_88 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_89 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_90 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_91 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_92 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_93 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_94 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_95 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 33,898\n",
      "Trainable params: 33,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.3002 - accuracy: 0.1350 - val_loss: 2.2982 - val_accuracy: 0.1152\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2938 - accuracy: 0.1440 - val_loss: 2.2894 - val_accuracy: 0.1895\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 2.2789 - accuracy: 0.1979 - val_loss: 2.2679 - val_accuracy: 0.2197\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2433 - accuracy: 0.2107 - val_loss: 2.2087 - val_accuracy: 0.2236\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.1296 - accuracy: 0.2129 - val_loss: 2.0227 - val_accuracy: 0.2246\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.9268 - accuracy: 0.2254 - val_loss: 1.8414 - val_accuracy: 0.2520\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.7596 - accuracy: 0.3088 - val_loss: 1.6666 - val_accuracy: 0.3535\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5584 - accuracy: 0.4081 - val_loss: 1.4455 - val_accuracy: 0.4336\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3089 - accuracy: 0.5170 - val_loss: 1.1830 - val_accuracy: 0.5381\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0444 - accuracy: 0.6632 - val_loss: 1.1673 - val_accuracy: 0.5459\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8187 - accuracy: 0.7402 - val_loss: 0.7798 - val_accuracy: 0.7588\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.7889 - val_loss: 0.6478 - val_accuracy: 0.7988\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.8303 - val_loss: 0.5687 - val_accuracy: 0.8418\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.8592 - val_loss: 0.4874 - val_accuracy: 0.8633\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8741 - val_loss: 0.4871 - val_accuracy: 0.8594\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8891 - val_loss: 0.5478 - val_accuracy: 0.8369\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.9012 - val_loss: 0.4020 - val_accuracy: 0.8965\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.9077 - val_loss: 0.3971 - val_accuracy: 0.8838\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.9158 - val_loss: 0.6229 - val_accuracy: 0.8330\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.9200 - val_loss: 0.3547 - val_accuracy: 0.9062\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.9306 - val_loss: 0.3450 - val_accuracy: 0.9121\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9333 - val_loss: 0.3627 - val_accuracy: 0.9023\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9382 - val_loss: 0.8041 - val_accuracy: 0.7832\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9405 - val_loss: 0.3594 - val_accuracy: 0.8984\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9448 - val_loss: 0.4259 - val_accuracy: 0.8896\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9468 - val_loss: 0.2979 - val_accuracy: 0.9238\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9517 - val_loss: 0.3505 - val_accuracy: 0.9141\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9535 - val_loss: 0.3351 - val_accuracy: 0.9180\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 0.9581 - val_loss: 0.3158 - val_accuracy: 0.9258\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1425 - accuracy: 0.9576 - val_loss: 0.2927 - val_accuracy: 0.9180\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9620 - val_loss: 0.3517 - val_accuracy: 0.9121\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9616 - val_loss: 0.3028 - val_accuracy: 0.9238\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9640 - val_loss: 1.4399 - val_accuracy: 0.7031\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1343 - accuracy: 0.9646 - val_loss: 0.4094 - val_accuracy: 0.8906\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.9690 - val_loss: 0.4160 - val_accuracy: 0.8975\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9731 - val_loss: 0.4910 - val_accuracy: 0.8818\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9705 - val_loss: 0.3291 - val_accuracy: 0.9238\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9770 - val_loss: 0.4447 - val_accuracy: 0.8936\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9749 - val_loss: 0.4287 - val_accuracy: 0.9141\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.9771 - val_loss: 0.3301 - val_accuracy: 0.9199\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9792 - val_loss: 0.3273 - val_accuracy: 0.9268\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9835 - val_loss: 0.4836 - val_accuracy: 0.9004\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9813 - val_loss: 0.3805 - val_accuracy: 0.9150\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9819 - val_loss: 1.3978 - val_accuracy: 0.7393\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9533 - val_loss: 0.3792 - val_accuracy: 0.9180\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9842 - val_loss: 0.4052 - val_accuracy: 0.9180\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9857 - val_loss: 0.3900 - val_accuracy: 0.9170\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9868 - val_loss: 0.3862 - val_accuracy: 0.9199\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9887 - val_loss: 0.3498 - val_accuracy: 0.9248\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9900 - val_loss: 0.3620 - val_accuracy: 0.9258\n",
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "re_lu_96 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_97 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_98 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_99 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_100 (ReLU)             (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_101 (ReLU)             (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_102 (ReLU)             (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_103 (ReLU)             (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 84,170\n",
      "Trainable params: 84,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.2983 - accuracy: 0.1126 - val_loss: 2.2930 - val_accuracy: 0.1250\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2817 - accuracy: 0.1587 - val_loss: 2.2689 - val_accuracy: 0.2236\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 2.2308 - accuracy: 0.2566 - val_loss: 2.1692 - val_accuracy: 0.2646\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.9640 - accuracy: 0.3321 - val_loss: 1.7085 - val_accuracy: 0.3740\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4433 - accuracy: 0.4877 - val_loss: 1.2752 - val_accuracy: 0.5459\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.1348 - accuracy: 0.6115 - val_loss: 1.0175 - val_accuracy: 0.6455\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8502 - accuracy: 0.7199 - val_loss: 0.7774 - val_accuracy: 0.7588\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.7919 - val_loss: 0.7344 - val_accuracy: 0.7646\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.8268 - val_loss: 0.7895 - val_accuracy: 0.7402\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8619 - val_loss: 0.6529 - val_accuracy: 0.7725\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8758 - val_loss: 0.4552 - val_accuracy: 0.8652\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8923 - val_loss: 0.4943 - val_accuracy: 0.8467\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.9001 - val_loss: 0.4467 - val_accuracy: 0.8740\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.9125 - val_loss: 0.4009 - val_accuracy: 0.8926\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.9197 - val_loss: 0.7749 - val_accuracy: 0.7637\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.9274 - val_loss: 0.7307 - val_accuracy: 0.7871\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9327 - val_loss: 0.3265 - val_accuracy: 0.9014\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9397 - val_loss: 0.2988 - val_accuracy: 0.9062\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9462 - val_loss: 0.2931 - val_accuracy: 0.9092\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9455 - val_loss: 0.3127 - val_accuracy: 0.9248\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9514 - val_loss: 0.2791 - val_accuracy: 0.9297\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9564 - val_loss: 0.2920 - val_accuracy: 0.9111\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9562 - val_loss: 0.3285 - val_accuracy: 0.9199\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9609 - val_loss: 0.2865 - val_accuracy: 0.9209\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.9628 - val_loss: 0.2673 - val_accuracy: 0.9307\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1133 - accuracy: 0.9670 - val_loss: 0.2734 - val_accuracy: 0.9326\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9710 - val_loss: 0.4764 - val_accuracy: 0.8828\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9684 - val_loss: 0.2597 - val_accuracy: 0.9326\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.9737 - val_loss: 0.8089 - val_accuracy: 0.8164\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9735 - val_loss: 0.3469 - val_accuracy: 0.9180\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9764 - val_loss: 0.3513 - val_accuracy: 0.9004\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9804 - val_loss: 0.3293 - val_accuracy: 0.9238\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9815 - val_loss: 0.3146 - val_accuracy: 0.9326\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9854 - val_loss: 0.3649 - val_accuracy: 0.9268\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9869 - val_loss: 0.3067 - val_accuracy: 0.9307\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9833 - val_loss: 0.2972 - val_accuracy: 0.9316\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9897 - val_loss: 0.2999 - val_accuracy: 0.9336\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9894 - val_loss: 0.3250 - val_accuracy: 0.9248\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9882 - val_loss: 0.3127 - val_accuracy: 0.9355\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9915 - val_loss: 0.3129 - val_accuracy: 0.9404\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9919 - val_loss: 0.4934 - val_accuracy: 0.8838\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9907 - val_loss: 0.3294 - val_accuracy: 0.9346\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9943 - val_loss: 0.3590 - val_accuracy: 0.9307\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9959 - val_loss: 0.3451 - val_accuracy: 0.9336\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9961 - val_loss: 0.3275 - val_accuracy: 0.9346\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9968 - val_loss: 0.6134 - val_accuracy: 0.8916\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.3614 - val_accuracy: 0.9385\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9978 - val_loss: 0.3679 - val_accuracy: 0.9385\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9975 - val_loss: 0.3645 - val_accuracy: 0.9395\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9742 - val_loss: 0.3220 - val_accuracy: 0.9316\n",
      "Model: \"functional_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "re_lu_104 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_105 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_106 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_107 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_108 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_109 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_110 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_111 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 233,866\n",
      "Trainable params: 233,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.2906 - accuracy: 0.1693 - val_loss: 2.2793 - val_accuracy: 0.2080\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2486 - accuracy: 0.2886 - val_loss: 2.2030 - val_accuracy: 0.3203\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 1.9668 - accuracy: 0.4147 - val_loss: 1.5558 - val_accuracy: 0.4922\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.1752 - accuracy: 0.6009 - val_loss: 1.3066 - val_accuracy: 0.5449\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.7765 - accuracy: 0.7435 - val_loss: 1.0907 - val_accuracy: 0.6494\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.8062 - val_loss: 0.8674 - val_accuracy: 0.7002\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8517 - val_loss: 0.6448 - val_accuracy: 0.8018\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8728 - val_loss: 0.4811 - val_accuracy: 0.8545\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8942 - val_loss: 0.4598 - val_accuracy: 0.8516\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.9061 - val_loss: 0.3606 - val_accuracy: 0.8926\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.9139 - val_loss: 0.4375 - val_accuracy: 0.8594\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.9225 - val_loss: 0.3315 - val_accuracy: 0.9004\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9289 - val_loss: 0.3379 - val_accuracy: 0.9092\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9377 - val_loss: 0.3724 - val_accuracy: 0.8896\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9424 - val_loss: 0.3142 - val_accuracy: 0.9033\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9483 - val_loss: 0.2729 - val_accuracy: 0.9199\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9524 - val_loss: 0.2895 - val_accuracy: 0.9150\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9569 - val_loss: 0.4830 - val_accuracy: 0.8662\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.9566 - val_loss: 0.2751 - val_accuracy: 0.9219\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9618 - val_loss: 0.2806 - val_accuracy: 0.9170\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9633 - val_loss: 0.2385 - val_accuracy: 0.9346\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9708 - val_loss: 0.7613 - val_accuracy: 0.8418\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9716 - val_loss: 0.2360 - val_accuracy: 0.9404\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9750 - val_loss: 0.3822 - val_accuracy: 0.8984\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9789 - val_loss: 0.2173 - val_accuracy: 0.9463\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9815 - val_loss: 0.3103 - val_accuracy: 0.9238\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9809 - val_loss: 0.2418 - val_accuracy: 0.9395\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9834 - val_loss: 0.2145 - val_accuracy: 0.9531\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9851 - val_loss: 0.2329 - val_accuracy: 0.9482\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9850 - val_loss: 0.2483 - val_accuracy: 0.9404\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9879 - val_loss: 0.3712 - val_accuracy: 0.9121\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9902 - val_loss: 0.2303 - val_accuracy: 0.9453\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9918 - val_loss: 0.2658 - val_accuracy: 0.9346\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9934 - val_loss: 0.2457 - val_accuracy: 0.9424\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9719 - val_loss: 0.3392 - val_accuracy: 0.9150\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9930 - val_loss: 0.2796 - val_accuracy: 0.9375\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9951 - val_loss: 0.2523 - val_accuracy: 0.9424\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9962 - val_loss: 0.2456 - val_accuracy: 0.9482\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9962 - val_loss: 0.2527 - val_accuracy: 0.9453\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9978 - val_loss: 0.2402 - val_accuracy: 0.9512\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.9980 - val_loss: 0.2384 - val_accuracy: 0.9512\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9986 - val_loss: 0.2566 - val_accuracy: 0.9482\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9984 - val_loss: 0.2538 - val_accuracy: 0.9473\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.2633 - val_accuracy: 0.9453\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9987 - val_loss: 0.2679 - val_accuracy: 0.9492\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9987 - val_loss: 0.2737 - val_accuracy: 0.9463\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.2751 - val_accuracy: 0.9502\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.2817 - val_accuracy: 0.9502\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.2873 - val_accuracy: 0.9492\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9997 - val_loss: 0.3009 - val_accuracy: 0.9482\n",
      "Model: \"functional_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "re_lu_112 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_113 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_114 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_115 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_116 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_117 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_118 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "re_lu_119 (ReLU)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 729,866\n",
      "Trainable params: 729,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.2937 - accuracy: 0.1690 - val_loss: 2.2840 - val_accuracy: 0.2373\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 2.2594 - accuracy: 0.3405 - val_loss: 2.2247 - val_accuracy: 0.3799\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 2.0382 - accuracy: 0.4519 - val_loss: 1.6499 - val_accuracy: 0.5049\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.1436 - accuracy: 0.6504 - val_loss: 0.8184 - val_accuracy: 0.7432\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.7722 - val_loss: 0.6477 - val_accuracy: 0.7988\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.8465 - val_loss: 0.6478 - val_accuracy: 0.7910\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8713 - val_loss: 0.4944 - val_accuracy: 0.8428\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8898 - val_loss: 0.4022 - val_accuracy: 0.8682\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.9084 - val_loss: 0.4135 - val_accuracy: 0.8740\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.9187 - val_loss: 0.3834 - val_accuracy: 0.8857\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.9251 - val_loss: 0.4113 - val_accuracy: 0.8818\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9326 - val_loss: 0.3013 - val_accuracy: 0.9072\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9416 - val_loss: 0.7250 - val_accuracy: 0.7764\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9457 - val_loss: 0.2918 - val_accuracy: 0.9131\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1573 - accuracy: 0.9540 - val_loss: 0.2261 - val_accuracy: 0.9375\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9560 - val_loss: 0.2352 - val_accuracy: 0.9268\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.9656 - val_loss: 0.2198 - val_accuracy: 0.9375\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9662 - val_loss: 0.2308 - val_accuracy: 0.9297\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.9683 - val_loss: 1.4818 - val_accuracy: 0.6738\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9696 - val_loss: 0.3413 - val_accuracy: 0.9043\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.9762 - val_loss: 0.2378 - val_accuracy: 0.9346\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.9784 - val_loss: 0.2874 - val_accuracy: 0.9150\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9819 - val_loss: 0.1945 - val_accuracy: 0.9482\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9831 - val_loss: 0.2002 - val_accuracy: 0.9463\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9865 - val_loss: 0.2794 - val_accuracy: 0.9219\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9874 - val_loss: 0.2088 - val_accuracy: 0.9463\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9882 - val_loss: 0.2159 - val_accuracy: 0.9404\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9898 - val_loss: 0.1881 - val_accuracy: 0.9541\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9902 - val_loss: 0.1925 - val_accuracy: 0.9551\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9937 - val_loss: 0.2087 - val_accuracy: 0.9424\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9941 - val_loss: 0.2113 - val_accuracy: 0.9473\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9960 - val_loss: 0.2151 - val_accuracy: 0.9443\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9962 - val_loss: 0.1960 - val_accuracy: 0.9551\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9970 - val_loss: 0.1968 - val_accuracy: 0.9531\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 0.2189 - val_accuracy: 0.9473\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9981 - val_loss: 0.9591 - val_accuracy: 0.8076\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9640 - val_loss: 0.1881 - val_accuracy: 0.9482\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9959 - val_loss: 0.1899 - val_accuracy: 0.9531\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9988 - val_loss: 0.4001 - val_accuracy: 0.9004\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.2097 - val_accuracy: 0.9551\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9994 - val_loss: 0.2203 - val_accuracy: 0.9502\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.2111 - val_accuracy: 0.9531\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.2225 - val_accuracy: 0.9531\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.2200 - val_accuracy: 0.9521\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.2229 - val_accuracy: 0.9531\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.2243 - val_accuracy: 0.9541\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.2274 - val_accuracy: 0.9512\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.2383 - val_accuracy: 0.9541\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.2410 - val_accuracy: 0.9541\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.2377 - val_accuracy: 0.9521\n",
      "Model: \"functional_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "re_lu_120 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_121 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_122 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_123 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_124 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_125 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_126 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_127 (ReLU)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,508,298\n",
      "Trainable params: 2,508,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 2.2825 - accuracy: 0.2333 - val_loss: 2.2565 - val_accuracy: 0.4902\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 2.1509 - accuracy: 0.4839 - val_loss: 1.9040 - val_accuracy: 0.5361\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.3109 - accuracy: 0.6573 - val_loss: 0.7944 - val_accuracy: 0.7412\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.7937 - val_loss: 0.6146 - val_accuracy: 0.8018\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.8489 - val_loss: 1.2339 - val_accuracy: 0.5664\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8826 - val_loss: 0.5142 - val_accuracy: 0.8418\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8973 - val_loss: 0.7334 - val_accuracy: 0.7793\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.9126 - val_loss: 0.3417 - val_accuracy: 0.9014\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.9248 - val_loss: 0.3167 - val_accuracy: 0.9141\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.2185 - accuracy: 0.9335 - val_loss: 0.2765 - val_accuracy: 0.9180\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9415 - val_loss: 0.3155 - val_accuracy: 0.9043\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1713 - accuracy: 0.9486 - val_loss: 0.2307 - val_accuracy: 0.9297\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9570 - val_loss: 0.2230 - val_accuracy: 0.9316\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9599 - val_loss: 0.2265 - val_accuracy: 0.9375\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1173 - accuracy: 0.9667 - val_loss: 0.2240 - val_accuracy: 0.9326\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.9698 - val_loss: 0.1983 - val_accuracy: 0.9414\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0943 - accuracy: 0.9722 - val_loss: 0.1979 - val_accuracy: 0.9473\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.9757 - val_loss: 0.1871 - val_accuracy: 0.9473\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9811 - val_loss: 0.1914 - val_accuracy: 0.9482\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9824 - val_loss: 0.2300 - val_accuracy: 0.9365\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9868 - val_loss: 0.3172 - val_accuracy: 0.9160\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9874 - val_loss: 1.3904 - val_accuracy: 0.7061\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9617 - val_loss: 0.1758 - val_accuracy: 0.9512\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9909 - val_loss: 0.1749 - val_accuracy: 0.9531\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9939 - val_loss: 0.1864 - val_accuracy: 0.9492\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9946 - val_loss: 0.1912 - val_accuracy: 0.9502\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9965 - val_loss: 0.1924 - val_accuracy: 0.9492\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9966 - val_loss: 0.2444 - val_accuracy: 0.9414\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9972 - val_loss: 0.2042 - val_accuracy: 0.9541\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9982 - val_loss: 0.2295 - val_accuracy: 0.9463\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 0.2079 - val_accuracy: 0.9551\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9993 - val_loss: 0.2182 - val_accuracy: 0.9521\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9996 - val_loss: 0.2216 - val_accuracy: 0.9502\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.2194 - val_accuracy: 0.9561\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9997 - val_loss: 0.2182 - val_accuracy: 0.9512\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.2258 - val_accuracy: 0.9541\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.2326 - val_accuracy: 0.9531\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.2358 - val_accuracy: 0.9512\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.2506 - val_accuracy: 0.9541\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.2433 - val_accuracy: 0.9561\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.2408 - val_accuracy: 0.9570\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.2443 - val_accuracy: 0.9541\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.2531 - val_accuracy: 0.9551\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9492\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9551\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9512\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9541\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9541\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9541\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9551\n",
      "Model: \"functional_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "re_lu_128 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_129 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_130 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_131 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_132 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_133 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_134 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_135 (ReLU)             (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 9,210,890\n",
      "Trainable params: 9,210,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 2.2783 - accuracy: 0.3117 - val_loss: 2.2434 - val_accuracy: 0.4375\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 2.0847 - accuracy: 0.4940 - val_loss: 1.7426 - val_accuracy: 0.5322\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.1281 - accuracy: 0.6858 - val_loss: 0.7109 - val_accuracy: 0.8115\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.5845 - accuracy: 0.8234 - val_loss: 0.5029 - val_accuracy: 0.8389\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.4031 - accuracy: 0.8787 - val_loss: 0.4570 - val_accuracy: 0.8691\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8979 - val_loss: 0.3679 - val_accuracy: 0.8916\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.9135 - val_loss: 0.3150 - val_accuracy: 0.9072\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.2461 - accuracy: 0.9257 - val_loss: 0.3220 - val_accuracy: 0.9141\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.2124 - accuracy: 0.9386 - val_loss: 0.4945 - val_accuracy: 0.8311\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.2007 - accuracy: 0.9403 - val_loss: 0.3721 - val_accuracy: 0.8916\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1678 - accuracy: 0.9514 - val_loss: 0.2453 - val_accuracy: 0.9346\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1510 - accuracy: 0.9554 - val_loss: 0.2623 - val_accuracy: 0.9219\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1384 - accuracy: 0.9601 - val_loss: 0.2154 - val_accuracy: 0.9385\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1173 - accuracy: 0.9693 - val_loss: 0.2369 - val_accuracy: 0.9307\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1060 - accuracy: 0.9708 - val_loss: 0.2633 - val_accuracy: 0.9287\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0882 - accuracy: 0.9771 - val_loss: 0.3383 - val_accuracy: 0.9111\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9767 - val_loss: 0.2175 - val_accuracy: 0.9365\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0696 - accuracy: 0.9807 - val_loss: 0.2020 - val_accuracy: 0.9482\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9839 - val_loss: 0.1893 - val_accuracy: 0.9502\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0501 - accuracy: 0.9878 - val_loss: 0.1920 - val_accuracy: 0.9521\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0429 - accuracy: 0.9903 - val_loss: 0.1891 - val_accuracy: 0.9463\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0381 - accuracy: 0.9909 - val_loss: 0.1902 - val_accuracy: 0.9482\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.9932 - val_loss: 0.1932 - val_accuracy: 0.9482\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0269 - accuracy: 0.9946 - val_loss: 0.2981 - val_accuracy: 0.9336\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0228 - accuracy: 0.9959 - val_loss: 0.1936 - val_accuracy: 0.9502\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9973 - val_loss: 0.1964 - val_accuracy: 0.9482\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1422 - accuracy: 0.9767 - val_loss: 0.1980 - val_accuracy: 0.9453\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9924 - val_loss: 0.1884 - val_accuracy: 0.9502\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0190 - accuracy: 0.9977 - val_loss: 0.1907 - val_accuracy: 0.9541\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0131 - accuracy: 0.9989 - val_loss: 0.1929 - val_accuracy: 0.9482\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9991 - val_loss: 0.1874 - val_accuracy: 0.9551\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9995 - val_loss: 0.1975 - val_accuracy: 0.9531\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9998 - val_loss: 0.1958 - val_accuracy: 0.9551\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9998 - val_loss: 0.2104 - val_accuracy: 0.9541\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.2013 - val_accuracy: 0.9551\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 0.2048 - val_accuracy: 0.9561\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.2087 - val_accuracy: 0.9570\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 0.2104 - val_accuracy: 0.9541\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.2142 - val_accuracy: 0.9531\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.2178 - val_accuracy: 0.9570\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.2165 - val_accuracy: 0.9541\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.2229 - val_accuracy: 0.9521\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.2199 - val_accuracy: 0.9551\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.2421 - val_accuracy: 0.9443\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.2233 - val_accuracy: 0.9541\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.2321 - val_accuracy: 0.9521\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.2275 - val_accuracy: 0.9541\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9521\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9541\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9541\n",
      "Model: \"functional_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 2048)              1607680   \n",
      "_________________________________________________________________\n",
      "re_lu_136 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_137 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_138 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_139 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_140 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_141 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_142 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "re_lu_143 (ReLU)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 35,198,986\n",
      "Trainable params: 35,198,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 15ms/step - loss: 2.2653 - accuracy: 0.2859 - val_loss: 2.2027 - val_accuracy: 0.5049\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.8275 - accuracy: 0.5903 - val_loss: 1.1572 - val_accuracy: 0.6289\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.7908 - accuracy: 0.7653 - val_loss: 0.9071 - val_accuracy: 0.6836\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4946 - accuracy: 0.8516 - val_loss: 0.4348 - val_accuracy: 0.8672\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3763 - accuracy: 0.8866 - val_loss: 0.3917 - val_accuracy: 0.8838\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3018 - accuracy: 0.9097 - val_loss: 0.3094 - val_accuracy: 0.9131\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2489 - accuracy: 0.9258 - val_loss: 0.4694 - val_accuracy: 0.8691\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2192 - accuracy: 0.9344 - val_loss: 0.5085 - val_accuracy: 0.8447\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1880 - accuracy: 0.9451 - val_loss: 0.3480 - val_accuracy: 0.8955\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1640 - accuracy: 0.9527 - val_loss: 0.3463 - val_accuracy: 0.8906\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1425 - accuracy: 0.9564 - val_loss: 0.3739 - val_accuracy: 0.8838\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1205 - accuracy: 0.9670 - val_loss: 0.2110 - val_accuracy: 0.9375\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1505 - accuracy: 0.9606 - val_loss: 0.2134 - val_accuracy: 0.9365\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0989 - accuracy: 0.9741 - val_loss: 0.2885 - val_accuracy: 0.9150\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0825 - accuracy: 0.9779 - val_loss: 0.1876 - val_accuracy: 0.9492\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0698 - accuracy: 0.9824 - val_loss: 0.5365 - val_accuracy: 0.8672\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0657 - accuracy: 0.9842 - val_loss: 0.1647 - val_accuracy: 0.9590\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0537 - accuracy: 0.9858 - val_loss: 0.1708 - val_accuracy: 0.9561\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0453 - accuracy: 0.9895 - val_loss: 0.1747 - val_accuracy: 0.9541\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0377 - accuracy: 0.9918 - val_loss: 0.1770 - val_accuracy: 0.9492\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9928 - val_loss: 0.1668 - val_accuracy: 0.9561\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0240 - accuracy: 0.9956 - val_loss: 0.1913 - val_accuracy: 0.9463\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0215 - accuracy: 0.9959 - val_loss: 0.1715 - val_accuracy: 0.9619\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0171 - accuracy: 0.9973 - val_loss: 0.1976 - val_accuracy: 0.9609\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0143 - accuracy: 0.9985 - val_loss: 0.1886 - val_accuracy: 0.9600\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0107 - accuracy: 0.9989 - val_loss: 0.1852 - val_accuracy: 0.9561\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0091 - accuracy: 0.9994 - val_loss: 0.1728 - val_accuracy: 0.9639\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0081 - accuracy: 0.9996 - val_loss: 0.1804 - val_accuracy: 0.9580\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0068 - accuracy: 0.9997 - val_loss: 0.1854 - val_accuracy: 0.9590\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 0.1863 - val_accuracy: 0.9600\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.1964 - val_accuracy: 0.9580\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 0.9998 - val_loss: 0.2188 - val_accuracy: 0.9531\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.1860 - val_accuracy: 0.9639\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.1891 - val_accuracy: 0.9590\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.1899 - val_accuracy: 0.9619\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.2029 - val_accuracy: 0.9541\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.2041 - val_accuracy: 0.9561\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.2001 - val_accuracy: 0.9580\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9561\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9570\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9570\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9561\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9590\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9580\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9561\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9561\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9590\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9551\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9570\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9570\n"
     ]
    }
   ],
   "source": [
    "# for multi in width_tick:\n",
    "#     img_input = layers.Input(shape=(28*28,))\n",
    "#     x = layers.Dense(width * multi)(img_input)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Dense(width * multi)(x)\n",
    "#     x = layers.Flatten()(x)\n",
    "#     out = layers.Dense(10)(x)\n",
    "    \n",
    "#     model = tf.keras.Model(img_input, out)\n",
    "#     model.summary()\n",
    "#     model.compile(optimizer='sgd',\n",
    "#               loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "#     model.fit(x=train_ds, validation_data=valid_ds, epochs=50)\n",
    "#     model.save_weights('./dense_10_weights/dense_10_with_multi_%s'%(str(multi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 181/10000 [01:08<54:30,  3.00it/s] "
     ]
    }
   ],
   "source": [
    "for multi in width_tick:\n",
    "    img_input = layers.Input(shape=(28*28,))\n",
    "    x = layers.Dense(width * multi)(img_input)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(width * multi)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    out = layers.Dense(10)(x)\n",
    "    \n",
    "    model = tf.keras.Model(img_input, out)\n",
    "    model.load_weights('./dense_10_weights/dense_10_with_multi_%s'%(str(multi)))\n",
    "    \n",
    "    @tf.function\n",
    "    def get_cross_entropy_hessian(y, x):\n",
    "        y_pred = model(x)\n",
    "        cross_en = loss(y, y_pred)\n",
    "        return tf.hessians(cross_en, x)\n",
    "\n",
    "    hessians = 0\n",
    "    for x, y in zip(tqdm(x_train), y_train):\n",
    "        x_tensor = tf.convert_to_tensor(x.reshape(-1, 28*28))\n",
    "        y_tensor = tf.convert_to_tensor(y.reshape(-1, class_num))\n",
    "        hs = get_cross_entropy_hessian(y_tensor, x_tensor)\n",
    "        hs = tf.reshape(hs, (784, 784))\n",
    "        hessians += hs\n",
    "        \n",
    "    onp.save('./dense_10_hessians/dense_10_hessians_with_multi_%s'%(str(multi)), hessians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [57:26<00:00,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# hessians = 0\n",
    "# for x, y in zip(tqdm(x_train), y_train):\n",
    "#     x_tensor = tf.convert_to_tensor(x.reshape(-1, 28*28))\n",
    "#     y_tensor = tf.convert_to_tensor(y.reshape(-1, class_num))\n",
    "#     hs = get_cross_entropy_hessian(y_tensor, x_tensor)\n",
    "#     hs = tf.reshape(hs, (784, 784))\n",
    "#     hessians += hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, vec = onp.linalg.eigh(hessians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.04713931e+04,  4.00029059e+04,  2.97010789e+04,  2.44528779e+04,\n",
       "        1.38275989e+04,  1.08146291e+04,  8.39923966e+03,  7.66292287e+03,\n",
       "        7.21473106e+03,  6.82033426e+03,  6.16921225e+03,  5.13493307e+03,\n",
       "        4.95812361e+03,  3.73866676e+03,  3.53657398e+03,  3.20276431e+03,\n",
       "        2.91356548e+03,  2.76433238e+03,  2.52143384e+03,  2.49470612e+03,\n",
       "        2.06812465e+03,  2.02281311e+03,  1.80656889e+03,  1.64437297e+03,\n",
       "        1.53903673e+03,  1.40323269e+03,  1.37712700e+03,  1.12296359e+03,\n",
       "        1.02487606e+03,  8.40873942e+02,  5.48478278e+02,  1.50508651e+02,\n",
       "        2.74206513e-11,  2.43499441e-11,  2.25565927e-11,  2.22211856e-11,\n",
       "        2.18448583e-11,  2.13530989e-11,  2.05006697e-11,  2.02090855e-11,\n",
       "        1.99461940e-11,  1.93458858e-11,  1.87728560e-11,  1.86817168e-11,\n",
       "        1.83592580e-11,  1.81470074e-11,  1.76892852e-11,  1.76231653e-11,\n",
       "        1.73338095e-11,  1.68101672e-11,  1.63611442e-11,  1.63254754e-11,\n",
       "        1.62921085e-11,  1.60868132e-11,  1.59906688e-11,  1.56803999e-11,\n",
       "        1.54429971e-11,  1.52626251e-11,  1.51231336e-11,  1.49073911e-11,\n",
       "        1.48527985e-11,  1.47941220e-11,  1.47376621e-11,  1.45307352e-11,\n",
       "        1.44652767e-11,  1.41114248e-11,  1.40410450e-11,  1.38702476e-11,\n",
       "        1.37622939e-11,  1.36763360e-11,  1.34926268e-11,  1.34625012e-11,\n",
       "        1.33106040e-11,  1.32918237e-11,  1.31362463e-11,  1.30584843e-11,\n",
       "        1.28917192e-11,  1.28369994e-11,  1.26033031e-11,  1.25374845e-11,\n",
       "        1.24640180e-11,  1.24369573e-11,  1.23644418e-11,  1.22897564e-11,\n",
       "        1.20819166e-11,  1.18936210e-11,  1.16890028e-11,  1.15081603e-11,\n",
       "        1.13825926e-11,  1.13776869e-11,  1.13620155e-11,  1.12498864e-11,\n",
       "        1.11727135e-11,  1.11702427e-11,  1.11101904e-11,  1.10706824e-11,\n",
       "        1.10679235e-11,  1.10230582e-11,  1.09879293e-11,  1.09520749e-11,\n",
       "        1.09247026e-11,  1.08719941e-11,  1.08206552e-11,  1.06919762e-11,\n",
       "        1.06904398e-11,  1.03244781e-11,  1.02328226e-11,  1.01940627e-11,\n",
       "        1.00765932e-11,  1.00221781e-11,  9.98842034e-12,  9.93206680e-12,\n",
       "        9.83438650e-12,  9.79162640e-12,  9.75630315e-12,  9.72306967e-12,\n",
       "        9.59648556e-12,  9.51808048e-12,  9.49230022e-12,  9.35837442e-12,\n",
       "        9.29133810e-12,  9.15131947e-12,  9.13151855e-12,  9.05903952e-12,\n",
       "        9.00429380e-12,  8.93153289e-12,  8.89902641e-12,  8.75163015e-12,\n",
       "        8.71219660e-12,  8.69386220e-12,  8.69337222e-12,  8.60442862e-12,\n",
       "        8.60274342e-12,  8.49922102e-12,  8.39718278e-12,  8.33903114e-12,\n",
       "        8.22619961e-12,  8.18582019e-12,  8.17281969e-12,  8.12928012e-12,\n",
       "        8.11232411e-12,  8.04235461e-12,  8.02545590e-12,  7.98612507e-12,\n",
       "        7.95655296e-12,  7.86368130e-12,  7.74335574e-12,  7.64485268e-12,\n",
       "        7.61608601e-12,  7.55816824e-12,  7.44833319e-12,  7.42476371e-12,\n",
       "        7.42159408e-12,  7.38615122e-12,  7.34239589e-12,  7.28355769e-12,\n",
       "        7.26836463e-12,  7.20015204e-12,  7.18132952e-12,  7.13029190e-12,\n",
       "        7.09374608e-12,  7.08161842e-12,  7.06608161e-12,  6.97799055e-12,\n",
       "        6.90969418e-12,  6.84005213e-12,  6.78419362e-12,  6.76191918e-12,\n",
       "        6.71387466e-12,  6.70228841e-12,  6.65361947e-12,  6.60040111e-12,\n",
       "        6.54546162e-12,  6.53205770e-12,  6.47882132e-12,  6.46979668e-12,\n",
       "        6.41690091e-12,  6.35593625e-12,  6.34326840e-12,  6.29371905e-12,\n",
       "        6.27156006e-12,  6.19137801e-12,  6.10630482e-12,  5.99169473e-12,\n",
       "        5.97818034e-12,  5.92528905e-12,  5.90810108e-12,  5.89370510e-12,\n",
       "        5.89236590e-12,  5.81564427e-12,  5.77567342e-12,  5.72032198e-12,\n",
       "        5.71347385e-12,  5.58093309e-12,  5.55666419e-12,  5.53424685e-12,\n",
       "        5.52749396e-12,  5.50499959e-12,  5.43808998e-12,  5.39000106e-12,\n",
       "        5.36411147e-12,  5.36110914e-12,  5.34780450e-12,  5.26147155e-12,\n",
       "        5.25523505e-12,  5.23902763e-12,  5.18809061e-12,  5.15121490e-12,\n",
       "        5.06136307e-12,  5.04408829e-12,  4.95482891e-12,  4.92234271e-12,\n",
       "        4.89335735e-12,  4.87947791e-12,  4.78722432e-12,  4.74968160e-12,\n",
       "        4.73553987e-12,  4.68031904e-12,  4.66922770e-12,  4.66577004e-12,\n",
       "        4.66470486e-12,  4.64608861e-12,  4.60016017e-12,  4.54427807e-12,\n",
       "        4.44971759e-12,  4.44639638e-12,  4.38466631e-12,  4.36468186e-12,\n",
       "        4.33509931e-12,  4.30824164e-12,  4.30753514e-12,  4.30617615e-12,\n",
       "        4.28955389e-12,  4.19718195e-12,  4.14141563e-12,  4.13705419e-12,\n",
       "        4.10565240e-12,  4.03750739e-12,  4.02243053e-12,  3.98793020e-12,\n",
       "        3.93808187e-12,  3.89607443e-12,  3.86200545e-12,  3.80301364e-12,\n",
       "        3.77301255e-12,  3.75327967e-12,  3.73078449e-12,  3.70722354e-12,\n",
       "        3.68040184e-12,  3.64492340e-12,  3.63555693e-12,  3.62996345e-12,\n",
       "        3.62223349e-12,  3.59383433e-12,  3.55629031e-12,  3.53993392e-12,\n",
       "        3.53883238e-12,  3.40541164e-12,  3.40077463e-12,  3.37614781e-12,\n",
       "        3.33894886e-12,  3.30813048e-12,  3.24492099e-12,  3.23206387e-12,\n",
       "        3.13925198e-12,  3.10321650e-12,  3.08004579e-12,  3.06880841e-12,\n",
       "        3.06136166e-12,  3.04999682e-12,  3.02890077e-12,  3.02475225e-12,\n",
       "        3.01809809e-12,  2.96821081e-12,  2.92989958e-12,  2.89951687e-12,\n",
       "        2.89327589e-12,  2.86868629e-12,  2.86179863e-12,  2.85749867e-12,\n",
       "        2.85175757e-12,  2.81515472e-12,  2.67370037e-12,  2.62992974e-12,\n",
       "        2.62522639e-12,  2.62059069e-12,  2.58371164e-12,  2.56306827e-12,\n",
       "        2.54025762e-12,  2.52659577e-12,  2.50485781e-12,  2.50308633e-12,\n",
       "        2.49768664e-12,  2.47550176e-12,  2.46610579e-12,  2.42620186e-12,\n",
       "        2.39807021e-12,  2.36333060e-12,  2.28946282e-12,  2.23862911e-12,\n",
       "        2.23243594e-12,  2.15523036e-12,  2.15278130e-12,  2.14390189e-12,\n",
       "        2.04068973e-12,  2.03754385e-12,  2.02380829e-12,  2.02039593e-12,\n",
       "        2.01955944e-12,  2.01919199e-12,  1.96361304e-12,  1.95694232e-12,\n",
       "        1.90528059e-12,  1.88676658e-12,  1.84702966e-12,  1.83834668e-12,\n",
       "        1.79478336e-12,  1.79299079e-12,  1.77456007e-12,  1.76308003e-12,\n",
       "        1.74335918e-12,  1.72765592e-12,  1.62639527e-12,  1.60911934e-12,\n",
       "        1.60511992e-12,  1.59254978e-12,  1.56877088e-12,  1.55001447e-12,\n",
       "        1.53768243e-12,  1.53032821e-12,  1.51670852e-12,  1.45742834e-12,\n",
       "        1.43018052e-12,  1.35519158e-12,  1.32024036e-12,  1.28402950e-12,\n",
       "        1.27855977e-12,  1.27258147e-12,  1.26718551e-12,  1.25386977e-12,\n",
       "        1.24085252e-12,  1.24045574e-12,  1.19812111e-12,  1.14912047e-12,\n",
       "        1.13155859e-12,  1.11069025e-12,  1.09961759e-12,  1.07855902e-12,\n",
       "        1.07333688e-12,  1.03550332e-12,  9.82056437e-13,  9.70070233e-13,\n",
       "        9.53959252e-13,  8.59642234e-13,  8.58540735e-13,  8.45625945e-13,\n",
       "        8.23013974e-13,  8.11332130e-13,  7.86682462e-13,  7.70272146e-13,\n",
       "        7.56230449e-13,  7.52108651e-13,  7.34701129e-13,  7.33192535e-13,\n",
       "        7.16757555e-13,  7.02512840e-13,  6.90439051e-13,  6.87901226e-13,\n",
       "        6.49025048e-13,  5.49830611e-13,  5.31804931e-13,  5.28424364e-13,\n",
       "        5.17392487e-13,  5.12195137e-13,  4.96112943e-13,  4.91389557e-13,\n",
       "        4.27956489e-13,  3.52893375e-13,  3.45908293e-13,  2.74345579e-13,\n",
       "        2.67390861e-13,  2.51541951e-13,  2.45852585e-13,  2.35085581e-13,\n",
       "        2.30379759e-13,  1.59797025e-13,  1.57746993e-13,  1.35578286e-13,\n",
       "        1.22810513e-13,  1.13571860e-13,  1.01264660e-13,  7.58534225e-14,\n",
       "        7.32823163e-14,  3.79703998e-14,  2.67537139e-14,  2.51256357e-14,\n",
       "        3.63516307e-15,  2.08372312e-15, -7.11331056e-14, -9.09736009e-14,\n",
       "       -1.56407324e-13, -1.62205972e-13, -1.67457840e-13, -1.75207827e-13,\n",
       "       -1.78160382e-13, -2.22552452e-13, -2.61917826e-13, -2.93663309e-13,\n",
       "       -3.13649453e-13, -3.26264760e-13, -3.66771164e-13, -3.80257390e-13,\n",
       "       -3.97642734e-13, -4.46034457e-13, -4.62698712e-13, -4.76518291e-13,\n",
       "       -5.06169869e-13, -5.24814273e-13, -5.29247858e-13, -5.89717462e-13,\n",
       "       -6.07490997e-13, -6.77684511e-13, -6.83529239e-13, -6.86510235e-13,\n",
       "       -6.94391741e-13, -6.99644586e-13, -7.04299444e-13, -7.27192530e-13,\n",
       "       -7.53936182e-13, -7.83404244e-13, -7.90588836e-13, -8.13532242e-13,\n",
       "       -8.59760626e-13, -9.12172119e-13, -9.55873734e-13, -9.61788191e-13,\n",
       "       -1.06262721e-12, -1.07413460e-12, -1.07846663e-12, -1.08184818e-12,\n",
       "       -1.08413766e-12, -1.10040897e-12, -1.10306643e-12, -1.11882598e-12,\n",
       "       -1.12278824e-12, -1.13121834e-12, -1.17975571e-12, -1.19489785e-12,\n",
       "       -1.19927478e-12, -1.25948677e-12, -1.26208869e-12, -1.28710810e-12,\n",
       "       -1.32839365e-12, -1.34544356e-12, -1.34826092e-12, -1.38718309e-12,\n",
       "       -1.42056581e-12, -1.43275404e-12, -1.49658374e-12, -1.52955785e-12,\n",
       "       -1.56747929e-12, -1.58171980e-12, -1.61880459e-12, -1.61925493e-12,\n",
       "       -1.62965280e-12, -1.64831920e-12, -1.66942172e-12, -1.69406529e-12,\n",
       "       -1.69805380e-12, -1.74423175e-12, -1.74632339e-12, -1.75296395e-12,\n",
       "       -1.76762426e-12, -1.79292892e-12, -1.80689748e-12, -1.85929404e-12,\n",
       "       -1.89973567e-12, -2.01794827e-12, -2.02167038e-12, -2.04262168e-12,\n",
       "       -2.04712578e-12, -2.06419056e-12, -2.11873927e-12, -2.12358721e-12,\n",
       "       -2.12683990e-12, -2.19412509e-12, -2.20599874e-12, -2.22326668e-12,\n",
       "       -2.32892506e-12, -2.33545626e-12, -2.34658703e-12, -2.35964227e-12,\n",
       "       -2.36674226e-12, -2.42129705e-12, -2.42764311e-12, -2.44503261e-12,\n",
       "       -2.44784278e-12, -2.44931229e-12, -2.45631996e-12, -2.46299974e-12,\n",
       "       -2.48697629e-12, -2.49090806e-12, -2.53790493e-12, -2.59026275e-12,\n",
       "       -2.59893262e-12, -2.60182761e-12, -2.62927434e-12, -2.66708162e-12,\n",
       "       -2.71567435e-12, -2.75116224e-12, -2.76131397e-12, -2.84444219e-12,\n",
       "       -2.88476781e-12, -2.90959550e-12, -2.93840258e-12, -2.95512464e-12,\n",
       "       -2.95768406e-12, -2.97642086e-12, -2.97846271e-12, -2.97852982e-12,\n",
       "       -3.04109914e-12, -3.08697701e-12, -3.14215997e-12, -3.14549570e-12,\n",
       "       -3.14775398e-12, -3.19015564e-12, -3.20628070e-12, -3.21674448e-12,\n",
       "       -3.29929594e-12, -3.31465619e-12, -3.33898001e-12, -3.34492249e-12,\n",
       "       -3.38814094e-12, -3.40073157e-12, -3.41237491e-12, -3.43531742e-12,\n",
       "       -3.47055022e-12, -3.50894830e-12, -3.53025771e-12, -3.57273512e-12,\n",
       "       -3.68473937e-12, -3.71967712e-12, -3.72757757e-12, -3.75020771e-12,\n",
       "       -3.75058938e-12, -3.75879514e-12, -3.81215034e-12, -3.82061718e-12,\n",
       "       -3.83177612e-12, -3.87699547e-12, -3.91420076e-12, -3.93584102e-12,\n",
       "       -3.96238868e-12, -3.97612962e-12, -4.04444708e-12, -4.12468469e-12,\n",
       "       -4.12720938e-12, -4.16963127e-12, -4.23040090e-12, -4.23857068e-12,\n",
       "       -4.29586241e-12, -4.36614156e-12, -4.36879277e-12, -4.39455255e-12,\n",
       "       -4.41274433e-12, -4.49181065e-12, -4.49374575e-12, -4.50345809e-12,\n",
       "       -4.51040985e-12, -4.52955367e-12, -4.61694297e-12, -4.62622926e-12,\n",
       "       -4.63083295e-12, -4.64237003e-12, -4.64373348e-12, -4.67213055e-12,\n",
       "       -4.67563799e-12, -4.70489527e-12, -4.74481496e-12, -4.74765178e-12,\n",
       "       -4.82273566e-12, -4.83023961e-12, -4.83809042e-12, -4.90763087e-12,\n",
       "       -4.90809020e-12, -4.91806117e-12, -4.94550157e-12, -5.12556516e-12,\n",
       "       -5.19072851e-12, -5.19288044e-12, -5.21493832e-12, -5.24546901e-12,\n",
       "       -5.26039788e-12, -5.30101812e-12, -5.31819427e-12, -5.41091868e-12,\n",
       "       -5.41967937e-12, -5.51762301e-12, -5.54078677e-12, -5.58969989e-12,\n",
       "       -5.60621456e-12, -5.67722920e-12, -5.71734754e-12, -5.73136398e-12,\n",
       "       -5.74555016e-12, -5.76032687e-12, -5.80656828e-12, -5.83609283e-12,\n",
       "       -5.92013910e-12, -5.92352936e-12, -5.92738375e-12, -6.00575969e-12,\n",
       "       -6.05786197e-12, -6.11620208e-12, -6.11640315e-12, -6.16055717e-12,\n",
       "       -6.21417545e-12, -6.23234740e-12, -6.30179169e-12, -6.31935926e-12,\n",
       "       -6.31985808e-12, -6.36955366e-12, -6.49461282e-12, -6.50607690e-12,\n",
       "       -6.50910444e-12, -6.54930115e-12, -6.61773955e-12, -6.63291920e-12,\n",
       "       -6.68246033e-12, -6.70608164e-12, -6.95283387e-12, -6.97035791e-12,\n",
       "       -7.01303265e-12, -7.04621663e-12, -7.04748417e-12, -7.06126858e-12,\n",
       "       -7.10886178e-12, -7.12133323e-12, -7.12194193e-12, -7.12753085e-12,\n",
       "       -7.13761261e-12, -7.15416435e-12, -7.21898423e-12, -7.22161618e-12,\n",
       "       -7.22769450e-12, -7.25336330e-12, -7.29563683e-12, -7.54449938e-12,\n",
       "       -7.56320517e-12, -7.65460744e-12, -7.69167011e-12, -7.70533814e-12,\n",
       "       -7.73138244e-12, -7.81812735e-12, -7.82537873e-12, -7.85397803e-12,\n",
       "       -7.88219684e-12, -7.90222126e-12, -7.93401526e-12, -8.03050021e-12,\n",
       "       -8.08834848e-12, -8.27699736e-12, -8.36950438e-12, -8.38790830e-12,\n",
       "       -8.40694597e-12, -8.41435784e-12, -8.44499165e-12, -8.48601377e-12,\n",
       "       -8.52171612e-12, -8.65201733e-12, -8.70798744e-12, -8.77948775e-12,\n",
       "       -8.81583882e-12, -8.83271382e-12, -8.84887252e-12, -8.97152311e-12,\n",
       "       -9.01374552e-12, -9.04347839e-12, -9.06414306e-12, -9.10126051e-12,\n",
       "       -9.22626515e-12, -9.23629599e-12, -9.25504085e-12, -9.31457984e-12,\n",
       "       -9.32369087e-12, -9.35615757e-12, -9.60173370e-12, -9.62768682e-12,\n",
       "       -9.69416776e-12, -9.75612180e-12, -9.82693006e-12, -9.82732010e-12,\n",
       "       -9.89904444e-12, -1.00489774e-11, -1.01576370e-11, -1.01720079e-11,\n",
       "       -1.02615629e-11, -1.03413747e-11, -1.03746466e-11, -1.05779047e-11,\n",
       "       -1.06360891e-11, -1.06934900e-11, -1.07460046e-11, -1.07863496e-11,\n",
       "       -1.10035030e-11, -1.10405541e-11, -1.10633914e-11, -1.11190055e-11,\n",
       "       -1.11348247e-11, -1.11749425e-11, -1.12110228e-11, -1.13584385e-11,\n",
       "       -1.13710140e-11, -1.14073854e-11, -1.14566702e-11, -1.14860096e-11,\n",
       "       -1.16014794e-11, -1.16580338e-11, -1.17427834e-11, -1.17460024e-11,\n",
       "       -1.17937492e-11, -1.18734818e-11, -1.18950336e-11, -1.23098400e-11,\n",
       "       -1.23715299e-11, -1.25096764e-11, -1.25420120e-11, -1.26092181e-11,\n",
       "       -1.26482218e-11, -1.27504181e-11, -1.29132309e-11, -1.29148665e-11,\n",
       "       -1.29993654e-11, -1.31128427e-11, -1.31337708e-11, -1.31705894e-11,\n",
       "       -1.34831609e-11, -1.37030279e-11, -1.37213282e-11, -1.37668372e-11,\n",
       "       -1.38665680e-11, -1.39710668e-11, -1.44380322e-11, -1.44729452e-11,\n",
       "       -1.45295287e-11, -1.46679208e-11, -1.47100852e-11, -1.49180601e-11,\n",
       "       -1.49397129e-11, -1.50572003e-11, -1.50877878e-11, -1.53237849e-11,\n",
       "       -1.54517362e-11, -1.55909343e-11, -1.58421252e-11, -1.58868589e-11,\n",
       "       -1.59647408e-11, -1.59899548e-11, -1.62570009e-11, -1.62813831e-11,\n",
       "       -1.65709682e-11, -1.65902658e-11, -1.71055645e-11, -1.71446845e-11,\n",
       "       -1.71821632e-11, -1.75980304e-11, -1.76207761e-11, -1.78089871e-11,\n",
       "       -1.83949066e-11, -1.85643548e-11, -1.85653512e-11, -1.86024602e-11,\n",
       "       -1.88759709e-11, -1.91730937e-11, -1.98410266e-11, -2.00621308e-11,\n",
       "       -2.06494059e-11, -2.14077903e-11, -2.15906341e-11, -2.19870424e-11,\n",
       "       -2.33770603e-11, -2.38163007e-11, -2.41265066e-11, -2.56451570e-11])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infinite width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nthudatalab1/yurong/ntk-env/lib/python3.6/site-packages/neural_tangents/utils/batch.py:616: UserWarning: Batch size is reduced from requested 256 to effective 64 to fit the dataset.\n",
      "  'fit the dataset.' % (batch_size, n2_batch_size))\n"
     ]
    }
   ],
   "source": [
    "batch_inf_kernel_fn = nt.batch(kernel_fn, batch_size=256, store_on_device=False)\n",
    "\n",
    "kernel_train_m = batch_inf_kernel_fn(x_train_down, None, 'ntk')\n",
    "\n",
    "eigval_inf, eigv_inf = np.linalg.eigh(kernel_train_m + np.eye(train_size)*diag_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_samples(arr, attack_type, layer):\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(6, 3), sharex=True)\n",
    "    for row, ax in enumerate(axs):\n",
    "        for idx, a in enumerate(ax):\n",
    "            img = arr[idx + row*4].reshape(image_shape)\n",
    "            a.axis('off')\n",
    "            a.xaxis.set_visible(False)\n",
    "            a.yaxis.set_visible(False)\n",
    "            a.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(arr, attack_type, layer):\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(6, 3), sharex=True)\n",
    "    for row, ax in enumerate(axs):\n",
    "        for idx, a in enumerate(ax):\n",
    "            img = arr[idx + row*4].reshape(image_shape)\n",
    "            a.axis('off')\n",
    "            a.xaxis.set_visible(False)\n",
    "            a.yaxis.set_visible(False)\n",
    "            a.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./fig-%s-untargeted/%s_layer_%d.png\"%(DATASET ,attack_type, layer+1), dpi=150)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
