{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "DATASET = 'cifar10'\n",
    "class_num   = 10\n",
    "test_size   = None\n",
    "train_size  = 45000\n",
    "image_shape = None\n",
    "\n",
    "if DATASET =='mnist':\n",
    "    image_shape = (28, 28, 1)\n",
    "elif DATASET == 'cifar10':\n",
    "    image_shape = (32, 32, 3)\n",
    "\n",
    "#training\n",
    "batch_size = 256\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    }
   ],
   "source": [
    "x_train_all, y_train_all, x_test_all, y_test_all = tuple(onp.array(x) for x in get_dataset(DATASET, None, None, \n",
    "                                                                                  do_flatten_and_normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "seed = 0\n",
    "x_train_all, y_train_all = shaffle(x_train_all, y_train_all, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sample\n",
    "x_train = x_train_all[:train_size]\n",
    "y_train = y_train_all[:train_size]\n",
    "\n",
    "x_valid = x_train_all[train_size:]\n",
    "y_valid = y_train_all[train_size:]\n",
    "\n",
    "x_test = x_test_all[:test_size]\n",
    "y_test = y_test_all[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test = x_train.reshape((-1, *image_shape)), x_valid.reshape((-1, *image_shape)), x_test.reshape((-1, *image_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will not automatically renormalize input data since input and output dtypes are both floating point formats.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will not automatically renormalize input data since input and output dtypes are both floating point formats.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will not automatically renormalize input data since input and output dtypes are both floating point formats.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will not automatically renormalize input data since input and output dtypes are both floating point formats.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.map(\n",
    "    lambda image, label: (tf.image.random_flip_left_right(image), label)\n",
    ").map(\n",
    "    lambda image, label: (tf.image.resize_with_crop_or_pad(image, image_shape[0]+6, image_shape[1]+6), label)\n",
    ").map(\n",
    "    lambda image, label: (tf.image.random_crop(image, (image_shape[0], image_shape[1], image_shape[2])), label)\n",
    ").map(\n",
    "    lambda image, label: (tf.image.random_contrast(image, lower=0.2, upper=1.0), label)\n",
    ").shuffle(\n",
    "    100000\n",
    ").batch(\n",
    "    batch_size\n",
    ").prefetch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, filter_num, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            strides=stride,\n",
    "                                            padding=\"same\")\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            strides=1,\n",
    "                                            padding=\"same\")\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        if stride != 1:\n",
    "            self.downsample = tf.keras.Sequential()\n",
    "            self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                                       kernel_size=(1, 1),\n",
    "                                                       strides=stride))\n",
    "            self.downsample.add(tf.keras.layers.BatchNormalization())\n",
    "        else:\n",
    "            self.downsample = lambda x: x\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        residual = self.downsample(inputs)\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "\n",
    "        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
    "\n",
    "        return output\n",
    "\n",
    "def make_basic_block_layer(filter_num, blocks, stride=1):\n",
    "    res_block = tf.keras.Sequential()\n",
    "    res_block.add(BasicBlock(filter_num, stride=stride))\n",
    "\n",
    "    for _ in range(1, blocks):\n",
    "        res_block.add(BasicBlock(filter_num, stride=1))\n",
    "\n",
    "    return res_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetTypeI(tf.keras.Model):\n",
    "    def __init__(self, layer_params):\n",
    "        super(ResNetTypeI, self).__init__()\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            padding=\"same\")\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.layer1 = make_basic_block_layer(filter_num=16,\n",
    "                                             blocks=layer_params[0])\n",
    "        self.layer2 = make_basic_block_layer(filter_num=32,\n",
    "                                             blocks=layer_params[1],\n",
    "                                             stride=2)\n",
    "        self.layer3 = make_basic_block_layer(filter_num=64,\n",
    "                                             blocks=layer_params[2],\n",
    "                                             stride=2)\n",
    "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = tf.keras.layers.Dense(10)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.layer1(x, training=training)\n",
    "        x = self.layer2(x, training=training)\n",
    "        x = self.layer3(x, training=training)\n",
    "        x = self.avgpool(x)\n",
    "        output = self.fc(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetTypeI([5, 5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(batch_size,*image_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_net_type_i\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  448       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  64        \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (256, 32, 32, 16)         23840     \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (256, 16, 16, 32)         89824     \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (256, 8, 8, 64)           355776    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  650       \n",
      "=================================================================\n",
      "Total params: 470,602\n",
      "Trainable params: 468,138\n",
      "Non-trainable params: 2,464\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return 1e-3\n",
    "    elif epoch < 90:\n",
    "        return 1e-2\n",
    "    elif epoch < 150:\n",
    "        return 1e-3\n",
    "    else:\n",
    "        return 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(momentum=0.9),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "176/176 [==============================] - 27s 152ms/step - loss: 2.1149 - accuracy: 0.2270 - val_loss: 2.2247 - val_accuracy: 0.1564\n",
      "Epoch 2/200\n",
      "176/176 [==============================] - 14s 77ms/step - loss: 1.8595 - accuracy: 0.3116 - val_loss: 1.8745 - val_accuracy: 0.3112\n",
      "Epoch 3/200\n",
      "176/176 [==============================] - 25s 142ms/step - loss: 1.7580 - accuracy: 0.3472 - val_loss: 2.0402 - val_accuracy: 0.2644\n",
      "Epoch 4/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 1.6891 - accuracy: 0.3729 - val_loss: 1.7577 - val_accuracy: 0.3434\n",
      "Epoch 5/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 1.6376 - accuracy: 0.3941 - val_loss: 1.6380 - val_accuracy: 0.3972\n",
      "Epoch 6/200\n",
      "176/176 [==============================] - 13s 77ms/step - loss: 1.5801 - accuracy: 0.4211 - val_loss: 1.6468 - val_accuracy: 0.4076\n",
      "Epoch 7/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 1.5302 - accuracy: 0.4397 - val_loss: 1.5326 - val_accuracy: 0.4422\n",
      "Epoch 8/200\n",
      "176/176 [==============================] - 13s 77ms/step - loss: 1.4816 - accuracy: 0.4583 - val_loss: 1.6021 - val_accuracy: 0.4320\n",
      "Epoch 9/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 1.4364 - accuracy: 0.4777 - val_loss: 1.6394 - val_accuracy: 0.4322\n",
      "Epoch 10/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 1.3978 - accuracy: 0.4936 - val_loss: 1.5060 - val_accuracy: 0.4596\n",
      "Epoch 11/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 1.4495 - accuracy: 0.4762 - val_loss: 2.5482 - val_accuracy: 0.3216\n",
      "Epoch 12/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 1.2102 - accuracy: 0.5627 - val_loss: 2.0606 - val_accuracy: 0.4314\n",
      "Epoch 13/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 1.0720 - accuracy: 0.6161 - val_loss: 1.9206 - val_accuracy: 0.5130\n",
      "Epoch 14/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.9663 - accuracy: 0.6538 - val_loss: 1.2047 - val_accuracy: 0.5958\n",
      "Epoch 15/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.8862 - accuracy: 0.6816 - val_loss: 1.4632 - val_accuracy: 0.5858\n",
      "Epoch 16/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.8158 - accuracy: 0.7124 - val_loss: 1.3295 - val_accuracy: 0.5892\n",
      "Epoch 17/200\n",
      "176/176 [==============================] - 13s 77ms/step - loss: 0.7668 - accuracy: 0.7291 - val_loss: 0.9423 - val_accuracy: 0.6772\n",
      "Epoch 18/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.7180 - accuracy: 0.7439 - val_loss: 1.0583 - val_accuracy: 0.6444\n",
      "Epoch 19/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.6778 - accuracy: 0.7618 - val_loss: 0.9045 - val_accuracy: 0.6942\n",
      "Epoch 20/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.6415 - accuracy: 0.7757 - val_loss: 0.8963 - val_accuracy: 0.7072\n",
      "Epoch 21/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.6193 - accuracy: 0.7829 - val_loss: 1.1275 - val_accuracy: 0.6462\n",
      "Epoch 22/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.5943 - accuracy: 0.7926 - val_loss: 0.7609 - val_accuracy: 0.7480\n",
      "Epoch 23/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.5703 - accuracy: 0.8010 - val_loss: 1.0710 - val_accuracy: 0.6746\n",
      "Epoch 24/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.5488 - accuracy: 0.8084 - val_loss: 1.3000 - val_accuracy: 0.6454\n",
      "Epoch 25/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.5318 - accuracy: 0.8143 - val_loss: 1.1702 - val_accuracy: 0.6504\n",
      "Epoch 26/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.5079 - accuracy: 0.8229 - val_loss: 1.0122 - val_accuracy: 0.7058\n",
      "Epoch 27/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.4902 - accuracy: 0.8294 - val_loss: 0.9879 - val_accuracy: 0.7014\n",
      "Epoch 28/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.4789 - accuracy: 0.8318 - val_loss: 0.8108 - val_accuracy: 0.7452\n",
      "Epoch 29/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.4621 - accuracy: 0.8379 - val_loss: 1.3097 - val_accuracy: 0.6660\n",
      "Epoch 30/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.4465 - accuracy: 0.8442 - val_loss: 0.7168 - val_accuracy: 0.7710\n",
      "Epoch 31/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.4343 - accuracy: 0.8479 - val_loss: 0.9113 - val_accuracy: 0.7302\n",
      "Epoch 32/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.4218 - accuracy: 0.8522 - val_loss: 1.1484 - val_accuracy: 0.6932\n",
      "Epoch 33/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.4086 - accuracy: 0.8563 - val_loss: 1.2119 - val_accuracy: 0.6712\n",
      "Epoch 34/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.4072 - accuracy: 0.8554 - val_loss: 0.6643 - val_accuracy: 0.7814\n",
      "Epoch 35/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.3925 - accuracy: 0.8610 - val_loss: 0.7452 - val_accuracy: 0.7608\n",
      "Epoch 36/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.3797 - accuracy: 0.8674 - val_loss: 0.6628 - val_accuracy: 0.7848\n",
      "Epoch 37/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.3686 - accuracy: 0.8699 - val_loss: 0.8098 - val_accuracy: 0.7648\n",
      "Epoch 38/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.3594 - accuracy: 0.8732 - val_loss: 0.6413 - val_accuracy: 0.7884\n",
      "Epoch 39/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.3506 - accuracy: 0.8766 - val_loss: 0.9651 - val_accuracy: 0.7200\n",
      "Epoch 40/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.3495 - accuracy: 0.8780 - val_loss: 0.9539 - val_accuracy: 0.7252\n",
      "Epoch 41/200\n",
      "176/176 [==============================] - 13s 77ms/step - loss: 0.3329 - accuracy: 0.8836 - val_loss: 0.6350 - val_accuracy: 0.8104\n",
      "Epoch 42/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.3257 - accuracy: 0.8858 - val_loss: 0.7316 - val_accuracy: 0.7682\n",
      "Epoch 43/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.3177 - accuracy: 0.8890 - val_loss: 0.7619 - val_accuracy: 0.7594\n",
      "Epoch 44/200\n",
      "176/176 [==============================] - 13s 77ms/step - loss: 0.3163 - accuracy: 0.8884 - val_loss: 0.6667 - val_accuracy: 0.8018\n",
      "Epoch 45/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.3051 - accuracy: 0.8932 - val_loss: 1.4742 - val_accuracy: 0.6534\n",
      "Epoch 46/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2937 - accuracy: 0.8950 - val_loss: 0.8103 - val_accuracy: 0.7682\n",
      "Epoch 47/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2933 - accuracy: 0.8969 - val_loss: 0.7293 - val_accuracy: 0.7978\n",
      "Epoch 48/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2909 - accuracy: 0.8975 - val_loss: 0.7290 - val_accuracy: 0.7864\n",
      "Epoch 49/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2784 - accuracy: 0.9025 - val_loss: 0.6304 - val_accuracy: 0.8110\n",
      "Epoch 50/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2686 - accuracy: 0.9039 - val_loss: 0.6731 - val_accuracy: 0.7966\n",
      "Epoch 51/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2701 - accuracy: 0.9052 - val_loss: 0.7912 - val_accuracy: 0.7720\n",
      "Epoch 52/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2619 - accuracy: 0.9081 - val_loss: 0.6456 - val_accuracy: 0.8014\n",
      "Epoch 53/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2557 - accuracy: 0.9092 - val_loss: 0.7152 - val_accuracy: 0.8026\n",
      "Epoch 54/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2523 - accuracy: 0.9099 - val_loss: 1.0391 - val_accuracy: 0.7396\n",
      "Epoch 55/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2524 - accuracy: 0.9112 - val_loss: 0.7217 - val_accuracy: 0.7956\n",
      "Epoch 56/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2445 - accuracy: 0.9122 - val_loss: 0.8748 - val_accuracy: 0.7614\n",
      "Epoch 57/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2401 - accuracy: 0.9155 - val_loss: 0.7679 - val_accuracy: 0.8006\n",
      "Epoch 58/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2311 - accuracy: 0.9181 - val_loss: 0.7261 - val_accuracy: 0.7890\n",
      "Epoch 59/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2286 - accuracy: 0.9196 - val_loss: 0.6952 - val_accuracy: 0.8126\n",
      "Epoch 60/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2191 - accuracy: 0.9214 - val_loss: 0.8744 - val_accuracy: 0.7610\n",
      "Epoch 61/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2213 - accuracy: 0.9209 - val_loss: 0.7817 - val_accuracy: 0.7950\n",
      "Epoch 62/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2107 - accuracy: 0.9248 - val_loss: 0.7412 - val_accuracy: 0.7948\n",
      "Epoch 63/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2072 - accuracy: 0.9268 - val_loss: 0.7719 - val_accuracy: 0.7934\n",
      "Epoch 64/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2083 - accuracy: 0.9266 - val_loss: 0.7365 - val_accuracy: 0.7928\n",
      "Epoch 65/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.2056 - accuracy: 0.9271 - val_loss: 0.9041 - val_accuracy: 0.7830\n",
      "Epoch 66/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1933 - accuracy: 0.9314 - val_loss: 0.7037 - val_accuracy: 0.8196\n",
      "Epoch 67/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1965 - accuracy: 0.9306 - val_loss: 0.7770 - val_accuracy: 0.8002\n",
      "Epoch 68/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1964 - accuracy: 0.9302 - val_loss: 0.8035 - val_accuracy: 0.7894\n",
      "Epoch 69/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1834 - accuracy: 0.9344 - val_loss: 0.6844 - val_accuracy: 0.8090\n",
      "Epoch 70/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1841 - accuracy: 0.9342 - val_loss: 0.6078 - val_accuracy: 0.8290\n",
      "Epoch 71/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1799 - accuracy: 0.9353 - val_loss: 1.0901 - val_accuracy: 0.7462\n",
      "Epoch 72/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1735 - accuracy: 0.9374 - val_loss: 0.7737 - val_accuracy: 0.8160\n",
      "Epoch 73/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1728 - accuracy: 0.9373 - val_loss: 0.8786 - val_accuracy: 0.7906\n",
      "Epoch 74/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1690 - accuracy: 0.9397 - val_loss: 0.7445 - val_accuracy: 0.8134\n",
      "Epoch 75/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1677 - accuracy: 0.9399 - val_loss: 0.8736 - val_accuracy: 0.7844\n",
      "Epoch 76/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1633 - accuracy: 0.9417 - val_loss: 0.6371 - val_accuracy: 0.8358\n",
      "Epoch 77/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1649 - accuracy: 0.9418 - val_loss: 0.7399 - val_accuracy: 0.8136\n",
      "Epoch 78/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1567 - accuracy: 0.9439 - val_loss: 0.7041 - val_accuracy: 0.8194\n",
      "Epoch 79/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1551 - accuracy: 0.9448 - val_loss: 0.9530 - val_accuracy: 0.7796\n",
      "Epoch 80/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1525 - accuracy: 0.9450 - val_loss: 0.7089 - val_accuracy: 0.8134\n",
      "Epoch 81/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1485 - accuracy: 0.9472 - val_loss: 0.6722 - val_accuracy: 0.8264\n",
      "Epoch 82/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1533 - accuracy: 0.9451 - val_loss: 0.6230 - val_accuracy: 0.8504\n",
      "Epoch 83/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1407 - accuracy: 0.9493 - val_loss: 0.9701 - val_accuracy: 0.7856\n",
      "Epoch 84/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1410 - accuracy: 0.9490 - val_loss: 0.6433 - val_accuracy: 0.8358\n",
      "Epoch 85/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1388 - accuracy: 0.9503 - val_loss: 1.4087 - val_accuracy: 0.7138\n",
      "Epoch 86/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1363 - accuracy: 0.9514 - val_loss: 0.6536 - val_accuracy: 0.8416\n",
      "Epoch 87/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1289 - accuracy: 0.9530 - val_loss: 0.9703 - val_accuracy: 0.7900\n",
      "Epoch 90/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1269 - accuracy: 0.9541 - val_loss: 0.8381 - val_accuracy: 0.8130\n",
      "Epoch 91/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.1043 - accuracy: 0.9643 - val_loss: 0.4953 - val_accuracy: 0.8640\n",
      "Epoch 92/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0778 - accuracy: 0.9753 - val_loss: 0.4866 - val_accuracy: 0.8668\n",
      "Epoch 93/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0711 - accuracy: 0.9769 - val_loss: 0.4871 - val_accuracy: 0.8740\n",
      "Epoch 94/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0664 - accuracy: 0.9795 - val_loss: 0.4858 - val_accuracy: 0.8706\n",
      "Epoch 95/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0649 - accuracy: 0.9792 - val_loss: 0.4987 - val_accuracy: 0.8736\n",
      "Epoch 96/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0628 - accuracy: 0.9798 - val_loss: 0.4745 - val_accuracy: 0.8778\n",
      "Epoch 97/200\n",
      "176/176 [==============================] - 13s 77ms/step - loss: 0.0617 - accuracy: 0.9806 - val_loss: 0.4859 - val_accuracy: 0.8778\n",
      "Epoch 98/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0608 - accuracy: 0.9802 - val_loss: 0.5050 - val_accuracy: 0.8726\n",
      "Epoch 99/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0585 - accuracy: 0.9815 - val_loss: 0.4888 - val_accuracy: 0.8760\n",
      "Epoch 100/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0577 - accuracy: 0.9822 - val_loss: 0.4968 - val_accuracy: 0.8732\n",
      "Epoch 101/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0565 - accuracy: 0.9817 - val_loss: 0.4903 - val_accuracy: 0.8762\n",
      "Epoch 102/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0562 - accuracy: 0.9818 - val_loss: 0.4979 - val_accuracy: 0.8792\n",
      "Epoch 103/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0545 - accuracy: 0.9829 - val_loss: 0.5009 - val_accuracy: 0.8772\n",
      "Epoch 104/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0536 - accuracy: 0.9824 - val_loss: 0.4997 - val_accuracy: 0.8786\n",
      "Epoch 105/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0522 - accuracy: 0.9836 - val_loss: 0.4980 - val_accuracy: 0.8784\n",
      "Epoch 106/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0521 - accuracy: 0.9839 - val_loss: 0.5151 - val_accuracy: 0.8718\n",
      "Epoch 107/200\n",
      "176/176 [==============================] - 13s 77ms/step - loss: 0.0514 - accuracy: 0.9835 - val_loss: 0.5162 - val_accuracy: 0.8740\n",
      "Epoch 108/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0504 - accuracy: 0.9841 - val_loss: 0.5045 - val_accuracy: 0.8772\n",
      "Epoch 109/200\n",
      "176/176 [==============================] - 13s 76ms/step - loss: 0.0493 - accuracy: 0.9844 - val_loss: 0.5336 - val_accuracy: 0.8710\n",
      "Epoch 110/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0513 - accuracy: 0.9838 - val_loss: 0.5123 - val_accuracy: 0.8788\n",
      "Epoch 111/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0488 - accuracy: 0.9843 - val_loss: 0.5245 - val_accuracy: 0.8766\n",
      "Epoch 112/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0481 - accuracy: 0.9850 - val_loss: 0.5119 - val_accuracy: 0.8734\n",
      "Epoch 113/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0473 - accuracy: 0.9851 - val_loss: 0.5186 - val_accuracy: 0.8754\n",
      "Epoch 114/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0496 - accuracy: 0.9840 - val_loss: 0.5040 - val_accuracy: 0.8778\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0474 - accuracy: 0.9855 - val_loss: 0.5388 - val_accuracy: 0.8716\n",
      "Epoch 116/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0481 - accuracy: 0.9850 - val_loss: 0.5244 - val_accuracy: 0.8758\n",
      "Epoch 117/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0456 - accuracy: 0.9860 - val_loss: 0.5227 - val_accuracy: 0.8766\n",
      "Epoch 118/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0461 - accuracy: 0.9855 - val_loss: 0.5227 - val_accuracy: 0.8798\n",
      "Epoch 119/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0437 - accuracy: 0.9868 - val_loss: 0.5358 - val_accuracy: 0.8746\n",
      "Epoch 120/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0435 - accuracy: 0.9864 - val_loss: 0.5276 - val_accuracy: 0.8764\n",
      "Epoch 121/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0432 - accuracy: 0.9865 - val_loss: 0.5287 - val_accuracy: 0.8782\n",
      "Epoch 122/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0429 - accuracy: 0.9867 - val_loss: 0.5437 - val_accuracy: 0.8754\n",
      "Epoch 123/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0426 - accuracy: 0.9862 - val_loss: 0.5366 - val_accuracy: 0.8760\n",
      "Epoch 124/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0420 - accuracy: 0.9869 - val_loss: 0.5509 - val_accuracy: 0.8724\n",
      "Epoch 125/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0414 - accuracy: 0.9866 - val_loss: 0.5383 - val_accuracy: 0.8764\n",
      "Epoch 126/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0430 - accuracy: 0.9864 - val_loss: 0.5371 - val_accuracy: 0.8770\n",
      "Epoch 127/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 0.5404 - val_accuracy: 0.8794\n",
      "Epoch 128/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0414 - accuracy: 0.9874 - val_loss: 0.5373 - val_accuracy: 0.8782\n",
      "Epoch 129/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0417 - accuracy: 0.9868 - val_loss: 0.5434 - val_accuracy: 0.8758\n",
      "Epoch 130/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0413 - accuracy: 0.9873 - val_loss: 0.5406 - val_accuracy: 0.8746\n",
      "Epoch 131/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0409 - accuracy: 0.9873 - val_loss: 0.5505 - val_accuracy: 0.8746\n",
      "Epoch 132/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0398 - accuracy: 0.9873 - val_loss: 0.5501 - val_accuracy: 0.8726\n",
      "Epoch 133/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0395 - accuracy: 0.9882 - val_loss: 0.5413 - val_accuracy: 0.8766\n",
      "Epoch 134/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0400 - accuracy: 0.9875 - val_loss: 0.5432 - val_accuracy: 0.8738\n",
      "Epoch 135/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0383 - accuracy: 0.9887 - val_loss: 0.5551 - val_accuracy: 0.8728\n",
      "Epoch 136/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0385 - accuracy: 0.9884 - val_loss: 0.5492 - val_accuracy: 0.8786\n",
      "Epoch 137/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0392 - accuracy: 0.9883 - val_loss: 0.5523 - val_accuracy: 0.8740\n",
      "Epoch 138/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0391 - accuracy: 0.9878 - val_loss: 0.5550 - val_accuracy: 0.8750\n",
      "Epoch 139/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0368 - accuracy: 0.9887 - val_loss: 0.5678 - val_accuracy: 0.8740\n",
      "Epoch 140/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 0.5516 - val_accuracy: 0.8758\n",
      "Epoch 141/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 0.5548 - val_accuracy: 0.8738\n",
      "Epoch 142/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0379 - accuracy: 0.9880 - val_loss: 0.5623 - val_accuracy: 0.8740\n",
      "Epoch 143/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0380 - accuracy: 0.9886 - val_loss: 0.5667 - val_accuracy: 0.8792\n",
      "Epoch 144/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0355 - accuracy: 0.9892 - val_loss: 0.5747 - val_accuracy: 0.8762\n",
      "Epoch 145/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0361 - accuracy: 0.9888 - val_loss: 0.5629 - val_accuracy: 0.8762\n",
      "Epoch 146/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0369 - accuracy: 0.9889 - val_loss: 0.5692 - val_accuracy: 0.8766\n",
      "Epoch 147/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 0.5627 - val_accuracy: 0.8780\n",
      "Epoch 148/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 0.5617 - val_accuracy: 0.8722\n",
      "Epoch 149/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.5531 - val_accuracy: 0.8792\n",
      "Epoch 150/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.5588 - val_accuracy: 0.8770\n",
      "Epoch 151/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0348 - accuracy: 0.9897 - val_loss: 0.5551 - val_accuracy: 0.8784\n",
      "Epoch 152/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0334 - accuracy: 0.9897 - val_loss: 0.5541 - val_accuracy: 0.8774\n",
      "Epoch 153/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.5554 - val_accuracy: 0.8780\n",
      "Epoch 154/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0323 - accuracy: 0.9902 - val_loss: 0.5566 - val_accuracy: 0.8780\n",
      "Epoch 155/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 0.5589 - val_accuracy: 0.8778\n",
      "Epoch 156/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.5580 - val_accuracy: 0.8774\n",
      "Epoch 157/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0333 - accuracy: 0.9897 - val_loss: 0.5586 - val_accuracy: 0.8776\n",
      "Epoch 158/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0320 - accuracy: 0.9910 - val_loss: 0.5596 - val_accuracy: 0.8770\n",
      "Epoch 159/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0319 - accuracy: 0.9901 - val_loss: 0.5616 - val_accuracy: 0.8762\n",
      "Epoch 160/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0347 - accuracy: 0.9894 - val_loss: 0.5602 - val_accuracy: 0.8760\n",
      "Epoch 161/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0327 - accuracy: 0.9899 - val_loss: 0.5595 - val_accuracy: 0.8770\n",
      "Epoch 162/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0324 - accuracy: 0.9906 - val_loss: 0.5609 - val_accuracy: 0.8770\n",
      "Epoch 163/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0324 - accuracy: 0.9903 - val_loss: 0.5633 - val_accuracy: 0.8760\n",
      "Epoch 164/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0312 - accuracy: 0.9914 - val_loss: 0.5625 - val_accuracy: 0.8758\n",
      "Epoch 165/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0316 - accuracy: 0.9904 - val_loss: 0.5619 - val_accuracy: 0.8778\n",
      "Epoch 166/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0325 - accuracy: 0.9905 - val_loss: 0.5616 - val_accuracy: 0.8770\n",
      "Epoch 167/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0332 - accuracy: 0.9901 - val_loss: 0.5613 - val_accuracy: 0.8758\n",
      "Epoch 168/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 0.5619 - val_accuracy: 0.8774\n",
      "Epoch 169/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0335 - accuracy: 0.9900 - val_loss: 0.5615 - val_accuracy: 0.8780\n",
      "Epoch 170/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0321 - accuracy: 0.9907 - val_loss: 0.5617 - val_accuracy: 0.8780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      "176/176 [==============================] - 14s 77ms/step - loss: 0.0319 - accuracy: 0.9905 - val_loss: 0.5625 - val_accuracy: 0.8778\n",
      "Epoch 172/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0326 - accuracy: 0.9901 - val_loss: 0.5635 - val_accuracy: 0.8770\n",
      "Epoch 173/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0322 - accuracy: 0.9908 - val_loss: 0.5638 - val_accuracy: 0.8764\n",
      "Epoch 174/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0329 - accuracy: 0.9907 - val_loss: 0.5642 - val_accuracy: 0.8766\n",
      "Epoch 175/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0317 - accuracy: 0.9905 - val_loss: 0.5659 - val_accuracy: 0.8762\n",
      "Epoch 176/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0325 - accuracy: 0.9906 - val_loss: 0.5641 - val_accuracy: 0.8764\n",
      "Epoch 177/200\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.0324 - accuracy: 0.9904 - val_loss: 0.5656 - val_accuracy: 0.8770\n",
      "Epoch 178/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0315 - accuracy: 0.9906 - val_loss: 0.5633 - val_accuracy: 0.8770\n",
      "Epoch 179/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0323 - accuracy: 0.9904 - val_loss: 0.5631 - val_accuracy: 0.8766\n",
      "Epoch 180/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0330 - accuracy: 0.9902 - val_loss: 0.5641 - val_accuracy: 0.8766\n",
      "Epoch 181/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0312 - accuracy: 0.9908 - val_loss: 0.5630 - val_accuracy: 0.8756\n",
      "Epoch 182/200\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.0350 - accuracy: 0.9892 - val_loss: 0.5654 - val_accuracy: 0.8756\n",
      "Epoch 183/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0321 - accuracy: 0.9903 - val_loss: 0.5643 - val_accuracy: 0.8772\n",
      "Epoch 184/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0320 - accuracy: 0.9908 - val_loss: 0.5651 - val_accuracy: 0.8770\n",
      "Epoch 185/200\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.0314 - accuracy: 0.9906 - val_loss: 0.5658 - val_accuracy: 0.8764\n",
      "Epoch 186/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0329 - accuracy: 0.9902 - val_loss: 0.5664 - val_accuracy: 0.8772\n",
      "Epoch 187/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0312 - accuracy: 0.9906 - val_loss: 0.5645 - val_accuracy: 0.8776\n",
      "Epoch 188/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.5648 - val_accuracy: 0.8778\n",
      "Epoch 189/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0329 - accuracy: 0.9900 - val_loss: 0.5656 - val_accuracy: 0.8778\n",
      "Epoch 190/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0304 - accuracy: 0.9913 - val_loss: 0.5645 - val_accuracy: 0.8784\n",
      "Epoch 191/200\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.0304 - accuracy: 0.9913 - val_loss: 0.5643 - val_accuracy: 0.8776\n",
      "Epoch 192/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0327 - accuracy: 0.9904 - val_loss: 0.5651 - val_accuracy: 0.8778\n",
      "Epoch 193/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0320 - accuracy: 0.9904 - val_loss: 0.5650 - val_accuracy: 0.8780\n",
      "Epoch 194/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0309 - accuracy: 0.9911 - val_loss: 0.5666 - val_accuracy: 0.8784\n",
      "Epoch 195/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0311 - accuracy: 0.9914 - val_loss: 0.5666 - val_accuracy: 0.8790\n",
      "Epoch 196/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0295 - accuracy: 0.9914 - val_loss: 0.5646 - val_accuracy: 0.8774\n",
      "Epoch 197/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0307 - accuracy: 0.9909 - val_loss: 0.5661 - val_accuracy: 0.8780\n",
      "Epoch 198/200\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.0299 - accuracy: 0.9917 - val_loss: 0.5659 - val_accuracy: 0.8792\n",
      "Epoch 199/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.5645 - val_accuracy: 0.8784\n",
      "Epoch 200/200\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0305 - accuracy: 0.9914 - val_loss: 0.5637 - val_accuracy: 0.8796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f953c7d4550>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_ds, validation_data=valid_ds, epochs=epochs, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model_weights/resnet32_train=all_ce.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5649635086476803, 0.87200004]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test_all, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('./model_weights/resnet32_train=all_ce.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pooling, acc can reach 72.2%\n",
    "# w.o. pooling, acc is at most 67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========NTK============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4168568849563599, 0.734375]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./npy/cifar-eps-time-any-npy/cifar-fgsm-eps-0.03-time-None.npy')\n",
    "print(\"==========NTK============\")\n",
    "model.evaluate(tmp, y_test[:128], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========CE============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7829372922424227, 0.8383789]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./npy/cifar-untargeted-cifar-nn-grey-box-train=4096-ce.npy')\n",
    "print(\"==========CE============\")\n",
    "model.evaluate(tmp, y_test[:2048], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========MSE============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9031526042381302, 0.8071289]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./npy/cifar-untargeted-cifar-nn-grey-box-train=4096-mse.npy')\n",
    "print(\"==========MSE============\")\n",
    "model.evaluate(tmp, y_test[:2048], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.589853584766388, 0.7109375]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./npy/cifar-fgsm-eps-0.03-time-None-nngp.npy')\n",
    "model.evaluate(tmp, y_test[:128], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8903837203979492, 0.81201171875]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./batch_NTK_simple.npy')\n",
    "model.evaluate(tmp, y_test[:2048], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========small============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.136065125465393, 0.77587890625]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./npy/cifar-untargeted-cifar-nn-grey-box-train=all-ce.npy')\n",
    "print(\"==========small============\")\n",
    "model.evaluate(tmp, y_test[:2048], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8085411190986633, 0.828125]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./batch_NTK_cnn_19.npy')\n",
    "model.evaluate(tmp, y_test[:2048], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.027262568473816, 0.7900390625]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = onp.load('./npy/cifar-untargeted-cifar-nn-grey-box-cnn19-train=all-ce.npy')\n",
    "model.evaluate(tmp, y_test[:2048], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
