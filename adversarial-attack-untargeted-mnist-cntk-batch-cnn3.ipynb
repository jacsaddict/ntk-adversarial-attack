{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.0\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "\n",
    "import numpy as onp\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "\n",
    "from jax import lax, random\n",
    "from jax.api import grad, jit, vmap\n",
    "from jax.config import config\n",
    "from jax.experimental import optimizers\n",
    "from jax.experimental.stax import logsoftmax\n",
    "\n",
    "config.update('jax_enable_x64', True)\n",
    "\n",
    "from neural_tangents import stax\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "# Attacking\n",
    "from cleverhans.utils import clip_eta, one_hot\n",
    "\n",
    "# Plotting\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from utils import *\n",
    "\n",
    "sns.set_style(style='white')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\"\"\"\n",
    "diag_reg:\n",
    "    a scalar representing the strength of the diagonal regularization for\n",
    "    `k_train_train`, i.e. computing `k_train_train + diag_reg * I` during\n",
    "    Cholesky factorization or eigendecomposition.\n",
    "\"\"\"\n",
    "diag_reg = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'mnist'\n",
    "class_num   = 10\n",
    "image_shape = None\n",
    "\n",
    "train_size = 512\n",
    "test_size = 512\n",
    "test_batch_size = 1\n",
    "eps = 0.03\n",
    "\n",
    "if DATASET =='mnist':\n",
    "    image_shape = (28, 28, 1)\n",
    "elif DATASET == 'cifar10':\n",
    "    image_shape = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_all, y_train_all, x_test_all, y_test_all = tuple(onp.array(x) for x in get_dataset(DATASET, None, None, \n",
    "                                                                                  do_flatten_and_normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "seed = 0\n",
    "x_train_all, y_train_all = shaffle(x_train_all, y_train_all, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sample\n",
    "x_train = x_train_all[:train_size]\n",
    "y_train = y_train_all[:train_size]\n",
    "\n",
    "x_test = x_test_all[:test_size]\n",
    "y_test = y_test_all[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train.reshape((-1, *image_shape)), x_test.reshape((-1, *image_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(mean, ys):\n",
    "    return onp.argmax(mean, axis=-1) == onp.argmax(ys, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(channels, W_std, b_std, strides=(1,1)):\n",
    "    return stax.serial(stax.Conv(out_chan=channels, filter_shape=(3,3), strides=strides, padding='SAME',\n",
    "                                 W_std=W_std, b_std=b_std), \n",
    "                       stax.Relu(do_backprop=True))\n",
    "\n",
    "def ConvGroup(n, channels, stride, W_std, b_std, last_stride=False):\n",
    "    blocks = []\n",
    "    if last_stride:\n",
    "        for i in range(n-1):\n",
    "            blocks += [ConvBlock(channels, W_std, b_std, stride)]\n",
    "        blocks += [ConvBlock(channels, W_std, b_std, (2, 2))]\n",
    "    \n",
    "    else:\n",
    "        for i in range(n):\n",
    "            blocks += [ConvBlock(channels, W_std, b_std, stride)]\n",
    "        \n",
    "    return stax.serial(*blocks)\n",
    "        \n",
    "def VGG19(class_num=class_num):\n",
    "    return stax.serial(\n",
    "        ConvGroup(n=2, channels=64 , stride=(1,1), W_std=1.414, b_std=0.18, last_stride=False),\n",
    "        ConvGroup(n=2, channels=128, stride=(1,1), W_std=1.414, b_std=0.18, last_stride=False),\n",
    "        ConvGroup(n=4, channels=256, stride=(1,1), W_std=1.414, b_std=0.18, last_stride=False),\n",
    "        ConvGroup(n=4, channels=512, stride=(1,1), W_std=1.414, b_std=0.18, last_stride=False),\n",
    "        ConvGroup(n=4, channels=512, stride=(1,1), W_std=1.414, b_std=0.18, last_stride=False),\n",
    "        stax.Flatten(),\n",
    "        stax.Dense(512), stax.Relu(do_backprop=True),\n",
    "        stax.Dense(class_num))\n",
    "\n",
    "def simple_net(class_num=class_num):\n",
    "    return stax.serial(\n",
    "        ConvGroup(n=3, channels=64 , stride=(2,2), W_std=1.414, b_std=0.18, last_stride=False),\n",
    "        stax.Flatten(),\n",
    "        stax.Dense(512, W_std=1.414), stax.Relu(do_backprop=True),\n",
    "        stax.Dense(class_num, W_std=1.414))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_fn, apply_fn, kernel_fn = simple_net(class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_kernel_fn = nt.batch(kernel_fn, batch_size=256, store_on_device=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel_train_m = batch_kernel_fn(x_train, None, 'ntk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict_fn = nt.predict.gradient_descent_mse(kernel_train_m, y_train[:8192], diag_reg=diag_reg)\n",
    "# kernel_test_train = batch_kernel_fn(x_test[:32], x_train[:8192], 'ntk')\n",
    "# pred = predict_fn(None, 0, 0 , kernel_test_train)\n",
    "# ans = onp.argmax(pred[1], axis=1)==onp.argmax(y_test[:32], axis=1)\n",
    "\n",
    "# print(\"testing accuracy: %.4f\"%(sum(ans)/ans.shape[0]))\n",
    "\n",
    "# plt.figure(dpi=100)\n",
    "# plt.imshow(kernel_train_m[:128, :128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(kernel_fn, x_train=None, x_test=None, fx_train_0=0., fx_test_0=0., t=None, ntk_train_train=None):\n",
    "    # Kernel\n",
    "    if ntk_train_train is None:\n",
    "        ntk_train_train = kernel_fn(x_train, x_train, 'ntk')\n",
    "    \n",
    "    ntk_test_train = kernel_fn(x_test, x_train, 'ntk')\n",
    "    # Prediction\n",
    "    predict_fn = nt.predict.gradient_descent_mse(ntk_train_train, y_train, diag_reg=diag_reg) # no convariance\n",
    "    \n",
    "    return predict_fn(t, fx_train_0, fx_test_0, ntk_test_train) # fx_train_0, fx_test_0 = (0, 0) for infinite width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def l2_loss_v1(logits, labels, weighting=1):\n",
    "    \"\"\"\n",
    "    Tensorflow version of L2 loss (without sqrt)\n",
    "    \"\"\"\n",
    "    return np.sum(((logits - labels)**2) * weighting) / 2\n",
    "    \n",
    "@jit\n",
    "def l2_loss_v2(logits, lables):\n",
    "    \"\"\"\n",
    "    Normal L2 loss\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(logits - labels)\n",
    "\n",
    "@jit\n",
    "def cross_entropy_loss(logits, lables):\n",
    "    return -np.sum(logsoftmax(logits) * lables)\n",
    "    \n",
    "@jit\n",
    "def mse_loss(logits, lables):\n",
    "    return 0.5 * np.mean((logits - lables) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attack algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_gradient_method(model_fn, kernel_fn, obj_fn, grads_fn, x_train=None, y_train=None, x_test=None, \n",
    "                         y=None, t=None, loss_weighting=None, fx_train_0=0., fx_test_0=0., eps=0.3, \n",
    "                         norm=np.inf, clip_min=None, clip_max=None, targeted=False):\n",
    "    \n",
    "    if norm not in [np.inf, 2]:\n",
    "        raise ValueError(\"Norm order must be either np.inf or 2.\")\n",
    "        \n",
    "    x = x_test\n",
    "        \n",
    "    # test independent\n",
    "    if obj_fn == 'untargeted':\n",
    "        grads = grads_fn(x_train, x_test, y_train, y, kernel_fn, t)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Objective function must be either train(ntk_train_train) or test(predict_fn)\")\n",
    "\n",
    "    axis = list(range(1, len(grads.shape)))\n",
    "    eps_div = 1e-12\n",
    "    \n",
    "    if norm == np.inf:\n",
    "        perturbation = eps * np.sign(grads)\n",
    "    elif norm == 1:\n",
    "        raise NotImplementedError(\"L_1 norm has not been implemented yet.\")\n",
    "    elif norm == 2:\n",
    "        square = np.maximum(eps_div, np.sum(np.square(grads), axis=axis, keepdims=True))\n",
    "        perturbation = grads / np.sqrt(square)\n",
    "    \n",
    "    adv_x = x + perturbation\n",
    "    \n",
    "    # If clipping is needed, reset all values outside of [clip_min, clip_max]\n",
    "    if (clip_min is not None) or (clip_max is not None):\n",
    "        # We don't currently support one-sided clipping\n",
    "        assert clip_min is not None and clip_max is not None\n",
    "        adv_x = np.clip(adv_x, a_min=clip_min, a_max=clip_max)\n",
    "    \n",
    "    return adv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_gradient_method_batch(model_fn, kernel_fn, obj_fn, grads_fn, ntk_train_train, x_train=None, y_train=None, \n",
    "                               x_test=None, y=None, t=None, loss_weighting=None, fx_train_0=0., fx_test_0=0., eps=0.3, \n",
    "                               norm=np.inf, clip_min=None, clip_max=None, targeted=False):\n",
    "    \n",
    "    if norm not in [np.inf, 2]:\n",
    "        raise ValueError(\"Norm order must be either np.inf or 2.\")\n",
    "        \n",
    "    x = x_test\n",
    "        \n",
    "    # test independent\n",
    "    if obj_fn == 'untargeted':\n",
    "        grads = grads_fn(x_train, x_test, y_train, y, kernel_fn, ntk_train_train, t)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Objective function must be either train(ntk_train_train) or test(predict_fn)\")\n",
    "\n",
    "    axis = list(range(1, len(grads.shape)))\n",
    "    eps_div = 1e-12\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_fast_gradient_method(model_fn, kernel_fn, obj_fn, grads_fn, x_train=None, y_train=None,\n",
    "                               x_test=None, y=None, t=None, loss_weighting=None, fx_train_0=0., fx_test_0=0., \n",
    "                               eps=0.3, eps_iter=0.03, nb_iter=10, norm=np.inf, clip_min=None, clip_max=None, \n",
    "                               targeted=False, rand_init=None, rand_minmax=0.3):\n",
    "\n",
    "    assert eps_iter <= eps, (eps_iter, eps)\n",
    "    if norm == 1:\n",
    "        raise NotImplementedError(\"It's not clear that FGM is a good inner loop\"\n",
    "                                  \" step for PGD when norm=1, because norm=1 FGM \"\n",
    "                                  \" changes only one pixel at a time. We need \"\n",
    "                                  \" to rigorously test a strong norm=1 PGD \"\n",
    "                                  \"before enabling this feature.\")\n",
    "    if norm not in [np.inf, 2]:\n",
    "        raise ValueError(\"Norm order must be either np.inf or 2.\")\n",
    "        \n",
    "    x = x_test\n",
    "    \n",
    "    # Initialize loop variables\n",
    "    if rand_init:\n",
    "        rand_minmax = eps\n",
    "        eta = random.uniform(new_key, x.shape, minval=-rand_minmax, maxval=rand_minmax)\n",
    "    else:\n",
    "        eta = np.zeros_like(x)\n",
    "\n",
    "    # Clip eta\n",
    "    eta = clip_eta(eta, norm, eps)\n",
    "    adv_x = x + eta\n",
    "    if clip_min is not None or clip_max is not None:\n",
    "        adv_x = np.clip(adv_x, a_min=clip_min, a_max=clip_max)\n",
    "        \n",
    "    for i in range(nb_iter):\n",
    "        adv_x = fast_gradient_method(model_fn, kernel_fn, obj_fn, grads_fn, x_train, y_train, adv_x, \n",
    "                                        y, t, loss_weighting, fx_train_0, fx_test_0, eps_iter, norm, \n",
    "                                        clip_min, clip_max, targeted)\n",
    "\n",
    "        # Clipping perturbation eta to norm norm ball\n",
    "        eta = adv_x - x\n",
    "        eta = clip_eta(eta, norm, eps)\n",
    "        adv_x = x + eta\n",
    "\n",
    "        # Redo the clipping.\n",
    "        # FGM already did it, but subtracting and re-adding eta can add some\n",
    "        # small numerical error.\n",
    "        if clip_min is not None or clip_max is not None:\n",
    "            adv_x = np.clip(adv_x, a_min=clip_min, a_max=clip_max)\n",
    "    \n",
    "    return adv_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'mnist':\n",
    "    eps = 0.3\n",
    "    eps_iter_10 = (eps/10)*1.1\n",
    "    eps_iter_100 = (eps/100)*1.1\n",
    "    eps_iter_1000 = (eps/1000)*1.1\n",
    "    \n",
    "elif DATASET == 'cifar10':\n",
    "    eps = 0.03\n",
    "    eps_iter_10 = (eps/10)*1.1\n",
    "    eps_iter_100 = (eps/100)*1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(x_train, x_test, y_test, model_fn, kernel_fn, t=None, attack_type=None, ntk_train_train=None):\n",
    "    \n",
    "    y_train_predict, y_test_predict = model_fn(kernel_fn, x_train, x_test, \n",
    "                                               t=t, ntk_train_train=ntk_train_train)\n",
    "    \n",
    "    selected_table = correct(y_test_predict, y_test)\n",
    "    print(\"Accuray({:s}): {:.2f}\".format(attack_type, onp.mean(selected_table)))\n",
    "    \n",
    "    return selected_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_robustness(x_train, x_test, y_test, model_fn, kernel_fn, selected_table, t=None, \n",
    "                        attack_type=None, ntk_train_train=None):\n",
    "    \n",
    "    y_train_predict, y_test_predict = model_fn(kernel_fn, x_train, x_test,\n",
    "                                               t=t, ntk_train_train=ntk_train_train)\n",
    "    \n",
    "    y_test_predict = onp.asarray(y_test_predict)\n",
    "    y_test_predict_select = y_test_predict[onp.asarray(selected_table)]\n",
    "    y_test_select = y_test[onp.asarray(selected_table)]\n",
    "    print(\"Robustness({:s}): {:.2f}\".format(attack_type, onp.mean(correct(y_test_predict_select, y_test_select))))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adv_x generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv(k):\n",
    "        #inverse with diag_reg\n",
    "        return onp.linalg.inv(k + diag_reg * onp.eye(k.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel_train_inv_m = inv(kernel_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss_adv_mse(x_train, x_test, y_train, y, kernel_fn, ntk_train_train, t=None, diag_reg=diag_reg):\n",
    "    \n",
    "    ntk_test_train = kernel_fn(x_test[None], x_train, 'ntk')\n",
    "\n",
    "    predict_fn = nt.predict.gradient_descent_mse(ntk_train_train, y_train, diag_reg=diag_reg)\n",
    "    # predict_fn(t, train_0, test_0, kernel_matrix)\n",
    "    pred = predict_fn(t, 0., 0., ntk_test_train)[1]\n",
    "\n",
    "    # loss = -mse_loss(pred, y)\n",
    "    loss = -np.sum(logsoftmax(pred) * y)\n",
    "    return loss\n",
    "    \n",
    "test_mse_grads_fn = jit(vmap(grad(test_loss_adv_mse, argnums=1), in_axes=(None, 0, None, 0, None, None, None), \n",
    "                             out_axes=0), static_argnums=(4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adv_x(kernel_fn, x_train, x_test, y_test, t=None, train_batch=256):\n",
    "    \n",
    "    \n",
    "    # for building matrix\n",
    "    kernel_fn = jit(kernel_fn, static_argnums=(2,))\n",
    "    \n",
    "    def inv(k):\n",
    "        #inverse with diag_reg\n",
    "        return onp.linalg.inv(k + diag_reg * onp.eye(k.shape[0]))\n",
    "    \n",
    "    num_iter = x_train.shape[0] // train_batch\n",
    "    \n",
    "    grads = 0\n",
    "    # print('generating FGSM data...')\n",
    "    for idx in range(num_iter):\n",
    "        \n",
    "        x_train_batch = x_train[idx*train_batch: (idx+1)*train_batch]\n",
    "        y_train_batch = y_train[idx*train_batch: (idx+1)*train_batch]\n",
    "        \n",
    "        ntk_train_train     = kernel_fn(x_train_batch, None, 'ntk')\n",
    "        # ntk_train_train_inv = inv(ntk_train_train)\n",
    "    \n",
    "        # FGSM\n",
    "        grads += fast_gradient_method_batch(model_fn=model_fn, kernel_fn=kernel_fn, obj_fn='untargeted', \n",
    "                                           grads_fn=test_mse_grads_fn, x_train=x_train_batch, y_train=y_train_batch, \n",
    "                                           x_test=x_test, y=y_test, t=t, eps=eps, clip_min=0, clip_max=1, ntk_train_train=ntk_train_train)\n",
    "    \n",
    "    perturbation = eps * np.sign(grads)\n",
    "    adv_x_FGSM = x_test + perturbation\n",
    "    adv_x_FGSM = np.clip(adv_x_FGSM, a_min=0, a_max=1)\n",
    "\n",
    "    return adv_x_FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time opt: 131072\n",
    "time = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [09:35<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "adv_x_FGSM, adv_x_IFGSM_100 = {}, {}\n",
    "for t in time:\n",
    "    adv_x_FGSM[t] = []\n",
    "    adv_x_IFGSM_100[t] = []\n",
    "    # print(\"generating time:\", t)\n",
    "    \n",
    "    for batch_id in tqdm(range(test_size//test_batch_size)):\n",
    "        fgsm = gen_adv_x(kernel_fn,\n",
    "                         x_train,\n",
    "                         x_test[batch_id*test_batch_size:(batch_id+1)*test_batch_size], \n",
    "                         y_test[batch_id*test_batch_size:(batch_id+1)*test_batch_size],\n",
    "                         t, 512)\n",
    "        \n",
    "        adv_x_FGSM[t].append(fgsm)\n",
    "        # adv_x_IFGSM_100[t].append(ifgsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "onp.save('./batch_NTK_simple_mnist.npy', onp.concatenate(adv_x_FGSM[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = onp.concatenate(adv_x_FGSM[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_samples(arr, attack_type, layer):\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(6, 3), sharex=True)\n",
    "    for row, ax in enumerate(axs):\n",
    "        for idx, a in enumerate(ax):\n",
    "            img = arr[idx + row*4].reshape(image_shape[:2])\n",
    "            a.axis('off')\n",
    "            a.xaxis.set_visible(False)\n",
    "            a.yaxis.set_visible(False)\n",
    "            a.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(arr, attack_type, layer):\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(6, 3), sharex=True)\n",
    "    for row, ax in enumerate(axs):\n",
    "        for idx, a in enumerate(ax):\n",
    "            img = arr[idx + row*4].reshape(image_shape)\n",
    "            a.axis('off')\n",
    "            a.xaxis.set_visible(False)\n",
    "            a.yaxis.set_visible(False)\n",
    "            a.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./fig-%s-untargeted/%s_layer_%d.png\"%(DATASET ,attack_type, layer+1), dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_samples(x_test, 'clean', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_samples(tmp, 'clean', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
