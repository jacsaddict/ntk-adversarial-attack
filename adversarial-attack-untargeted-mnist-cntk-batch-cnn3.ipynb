{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.0\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "\n",
    "import numpy as onp\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "\n",
    "from jax import lax, random\n",
    "from jax.api import grad, jit, vmap\n",
    "from jax.config import config\n",
    "from jax.experimental import optimizers\n",
    "from jax.experimental.stax import logsoftmax\n",
    "\n",
    "config.update('jax_enable_x64', True)\n",
    "\n",
    "from neural_tangents import stax\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "# Attacking\n",
    "from cleverhans.utils import clip_eta, one_hot\n",
    "\n",
    "# Plotting\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from utils import *\n",
    "\n",
    "sns.set_style(style='white')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\"\"\"\n",
    "diag_reg:\n",
    "    a scalar representing the strength of the diagonal regularization for\n",
    "    `k_train_train`, i.e. computing `k_train_train + diag_reg * I` during\n",
    "    Cholesky factorization or eigendecomposition.\n",
    "\"\"\"\n",
    "diag_reg = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'mnist'\n",
    "class_num   = 10\n",
    "image_shape = None\n",
    "\n",
    "train_size = 512\n",
    "test_size = 512\n",
    "test_batch_size = 1\n",
    "eps = 0.03\n",
    "\n",
    "if DATASET =='mnist':\n",
    "    image_shape = (28, 28, 1)\n",
    "elif DATASET == 'cifar10':\n",
    "    image_shape = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_all, y_train_all, x_test_all, y_test_all = tuple(onp.array(x) for x in get_dataset(DATASET, None, None, \n",
    "                                                                                  do_flatten_and_normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "seed = 0\n",
    "x_train_all, y_train_all = shaffle(x_train_all, y_train_all, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sample\n",
    "x_train = x_train_all[:train_size]\n",
    "y_train = y_train_all[:train_size]\n",
    "\n",
    "x_test = x_test_all[:test_size]\n",
    "y_test = y_test_all[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train.reshape((-1, *image_shape)), x_test.reshape((-1, *image_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(mean, ys):\n",
    "    return onp.argmax(mean, axis=-1) == onp.argmax(ys, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(channels, W_std, b_std, strides=(1,1)):\n",
    "    return stax.serial(stax.Conv(out_chan=channels, filter_shape=(3,3), strides=strides, padding='SAME',\n",
    "                                 W_std=W_std, b_std=b_std), \n",
    "                       stax.Relu(do_backprop=True))\n",
    "\n",
    "def ConvGroup(n, channels, stride, W_std, b_std, last_stride=False):\n",
    "    blocks = []\n",
    "    if last_stride:\n",
    "        for i in range(n-1):\n",
    "            blocks += [ConvBlock(channels, W_std, b_std, stride)]\n",
    "        blocks += [ConvBlock(channels, W_std, b_std, (2, 2))]\n",
    "    \n",
    "    else:\n",
    "        for i in range(n):\n",
    "            blocks += [ConvBlock(channels, W_std, b_std, stride)]\n",
    "        \n",
    "    return stax.serial(*blocks)\n",
    "        \n",
    "def VGG19(class_num=class_num):\n",
    "    return stax.serial(\n",
    "        ConvGroup(n=2, channels=64 , stride=(1,1), W_std=1.414, b_std=0.18, last_stride=False),\n",
    "        ConvGroup(n=2, channels=128, stride=(1,1), W_std=1.414, b_std=0.18, last_stride=False),\n",
    "        ConvGroup(n=4, channels=256, stride=(1,1), W_std=1.414, b_std=0.18, last_stride=False),\n",
    "        ConvGroup(n=4, channels=512, stride=(1,1), W_std=1.414, b_std=0.18, last_stride=False),\n",
    "        ConvGroup(n=4, channels=512, stride=(1,1), W_std=1.414, b_std=0.18, last_stride=False),\n",
    "        stax.Flatten(),\n",
    "        stax.Dense(512), stax.Relu(do_backprop=True),\n",
    "        stax.Dense(class_num))\n",
    "\n",
    "def simple_net(class_num=class_num):\n",
    "    return stax.serial(\n",
    "        ConvGroup(n=3, channels=64 , stride=(1,1), W_std=1.414, b_std=0.18, last_stride=False),\n",
    "        stax.Flatten(),\n",
    "        stax.Dense(512, W_std=1.414), stax.Relu(do_backprop=True),\n",
    "        stax.Dense(class_num, W_std=1.414))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_fn, apply_fn, kernel_fn = simple_net(class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_kernel_fn = nt.batch(kernel_fn, batch_size=256, store_on_device=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel_train_m = batch_kernel_fn(x_train, None, 'ntk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict_fn = nt.predict.gradient_descent_mse(kernel_train_m, y_train[:8192], diag_reg=diag_reg)\n",
    "# kernel_test_train = batch_kernel_fn(x_test[:32], x_train[:8192], 'ntk')\n",
    "# pred = predict_fn(None, 0, 0 , kernel_test_train)\n",
    "# ans = onp.argmax(pred[1], axis=1)==onp.argmax(y_test[:32], axis=1)\n",
    "\n",
    "# print(\"testing accuracy: %.4f\"%(sum(ans)/ans.shape[0]))\n",
    "\n",
    "# plt.figure(dpi=100)\n",
    "# plt.imshow(kernel_train_m[:128, :128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(kernel_fn, x_train=None, x_test=None, fx_train_0=0., fx_test_0=0., t=None, ntk_train_train=None):\n",
    "    # Kernel\n",
    "    if ntk_train_train is None:\n",
    "        ntk_train_train = kernel_fn(x_train, x_train, 'ntk')\n",
    "    \n",
    "    ntk_test_train = kernel_fn(x_test, x_train, 'ntk')\n",
    "    # Prediction\n",
    "    predict_fn = nt.predict.gradient_descent_mse(ntk_train_train, y_train, diag_reg=diag_reg) # no convariance\n",
    "    \n",
    "    return predict_fn(t, fx_train_0, fx_test_0, ntk_test_train) # fx_train_0, fx_test_0 = (0, 0) for infinite width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def l2_loss_v1(logits, labels, weighting=1):\n",
    "    \"\"\"\n",
    "    Tensorflow version of L2 loss (without sqrt)\n",
    "    \"\"\"\n",
    "    return np.sum(((logits - labels)**2) * weighting) / 2\n",
    "    \n",
    "@jit\n",
    "def l2_loss_v2(logits, lables):\n",
    "    \"\"\"\n",
    "    Normal L2 loss\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(logits - labels)\n",
    "\n",
    "@jit\n",
    "def cross_entropy_loss(logits, lables):\n",
    "    return -np.sum(logsoftmax(logits) * lables)\n",
    "    \n",
    "@jit\n",
    "def mse_loss(logits, lables):\n",
    "    return 0.5 * np.mean((logits - lables) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attack algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_gradient_method(model_fn, kernel_fn, obj_fn, grads_fn, x_train=None, y_train=None, x_test=None, \n",
    "                         y=None, t=None, loss_weighting=None, fx_train_0=0., fx_test_0=0., eps=0.3, \n",
    "                         norm=np.inf, clip_min=None, clip_max=None, targeted=False):\n",
    "    \n",
    "    if norm not in [np.inf, 2]:\n",
    "        raise ValueError(\"Norm order must be either np.inf or 2.\")\n",
    "        \n",
    "    x = x_test\n",
    "        \n",
    "    # test independent\n",
    "    if obj_fn == 'untargeted':\n",
    "        grads = grads_fn(x_train, x_test, y_train, y, kernel_fn, t)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Objective function must be either train(ntk_train_train) or test(predict_fn)\")\n",
    "\n",
    "    axis = list(range(1, len(grads.shape)))\n",
    "    eps_div = 1e-12\n",
    "    \n",
    "    if norm == np.inf:\n",
    "        perturbation = eps * np.sign(grads)\n",
    "    elif norm == 1:\n",
    "        raise NotImplementedError(\"L_1 norm has not been implemented yet.\")\n",
    "    elif norm == 2:\n",
    "        square = np.maximum(eps_div, np.sum(np.square(grads), axis=axis, keepdims=True))\n",
    "        perturbation = grads / np.sqrt(square)\n",
    "    \n",
    "    adv_x = x + perturbation\n",
    "    \n",
    "    # If clipping is needed, reset all values outside of [clip_min, clip_max]\n",
    "    if (clip_min is not None) or (clip_max is not None):\n",
    "        # We don't currently support one-sided clipping\n",
    "        assert clip_min is not None and clip_max is not None\n",
    "        adv_x = np.clip(adv_x, a_min=clip_min, a_max=clip_max)\n",
    "    \n",
    "    return adv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_gradient_method_batch(model_fn, kernel_fn, obj_fn, grads_fn, ntk_train_train, x_train=None, y_train=None, \n",
    "                               x_test=None, y=None, t=None, loss_weighting=None, fx_train_0=0., fx_test_0=0., eps=0.3, \n",
    "                               norm=np.inf, clip_min=None, clip_max=None, targeted=False):\n",
    "    \n",
    "    if norm not in [np.inf, 2]:\n",
    "        raise ValueError(\"Norm order must be either np.inf or 2.\")\n",
    "        \n",
    "    x = x_test\n",
    "        \n",
    "    # test independent\n",
    "    if obj_fn == 'untargeted':\n",
    "        grads = grads_fn(x_train, x_test, y_train, y, kernel_fn, ntk_train_train, t)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Objective function must be either train(ntk_train_train) or test(predict_fn)\")\n",
    "\n",
    "    axis = list(range(1, len(grads.shape)))\n",
    "    eps_div = 1e-12\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_fast_gradient_method(model_fn, kernel_fn, obj_fn, grads_fn, x_train=None, y_train=None,\n",
    "                               x_test=None, y=None, t=None, loss_weighting=None, fx_train_0=0., fx_test_0=0., \n",
    "                               eps=0.3, eps_iter=0.03, nb_iter=10, norm=np.inf, clip_min=None, clip_max=None, \n",
    "                               targeted=False, rand_init=None, rand_minmax=0.3):\n",
    "\n",
    "    assert eps_iter <= eps, (eps_iter, eps)\n",
    "    if norm == 1:\n",
    "        raise NotImplementedError(\"It's not clear that FGM is a good inner loop\"\n",
    "                                  \" step for PGD when norm=1, because norm=1 FGM \"\n",
    "                                  \" changes only one pixel at a time. We need \"\n",
    "                                  \" to rigorously test a strong norm=1 PGD \"\n",
    "                                  \"before enabling this feature.\")\n",
    "    if norm not in [np.inf, 2]:\n",
    "        raise ValueError(\"Norm order must be either np.inf or 2.\")\n",
    "        \n",
    "    x = x_test\n",
    "    \n",
    "    # Initialize loop variables\n",
    "    if rand_init:\n",
    "        rand_minmax = eps\n",
    "        eta = random.uniform(new_key, x.shape, minval=-rand_minmax, maxval=rand_minmax)\n",
    "    else:\n",
    "        eta = np.zeros_like(x)\n",
    "\n",
    "    # Clip eta\n",
    "    eta = clip_eta(eta, norm, eps)\n",
    "    adv_x = x + eta\n",
    "    if clip_min is not None or clip_max is not None:\n",
    "        adv_x = np.clip(adv_x, a_min=clip_min, a_max=clip_max)\n",
    "        \n",
    "    for i in range(nb_iter):\n",
    "        adv_x = fast_gradient_method(model_fn, kernel_fn, obj_fn, grads_fn, x_train, y_train, adv_x, \n",
    "                                        y, t, loss_weighting, fx_train_0, fx_test_0, eps_iter, norm, \n",
    "                                        clip_min, clip_max, targeted)\n",
    "\n",
    "        # Clipping perturbation eta to norm norm ball\n",
    "        eta = adv_x - x\n",
    "        eta = clip_eta(eta, norm, eps)\n",
    "        adv_x = x + eta\n",
    "\n",
    "        # Redo the clipping.\n",
    "        # FGM already did it, but subtracting and re-adding eta can add some\n",
    "        # small numerical error.\n",
    "        if clip_min is not None or clip_max is not None:\n",
    "            adv_x = np.clip(adv_x, a_min=clip_min, a_max=clip_max)\n",
    "    \n",
    "    return adv_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'mnist':\n",
    "    eps = 0.3\n",
    "    eps_iter_10 = (eps/10)*1.1\n",
    "    eps_iter_100 = (eps/100)*1.1\n",
    "    eps_iter_1000 = (eps/1000)*1.1\n",
    "    \n",
    "elif DATASET == 'cifar10':\n",
    "    eps = 0.03\n",
    "    eps_iter_10 = (eps/10)*1.1\n",
    "    eps_iter_100 = (eps/100)*1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(x_train, x_test, y_test, model_fn, kernel_fn, t=None, attack_type=None, ntk_train_train=None):\n",
    "    \n",
    "    y_train_predict, y_test_predict = model_fn(kernel_fn, x_train, x_test, \n",
    "                                               t=t, ntk_train_train=ntk_train_train)\n",
    "    \n",
    "    selected_table = correct(y_test_predict, y_test)\n",
    "    print(\"Accuray({:s}): {:.2f}\".format(attack_type, onp.mean(selected_table)))\n",
    "    \n",
    "    return selected_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_robustness(x_train, x_test, y_test, model_fn, kernel_fn, selected_table, t=None, \n",
    "                        attack_type=None, ntk_train_train=None):\n",
    "    \n",
    "    y_train_predict, y_test_predict = model_fn(kernel_fn, x_train, x_test,\n",
    "                                               t=t, ntk_train_train=ntk_train_train)\n",
    "    \n",
    "    y_test_predict = onp.asarray(y_test_predict)\n",
    "    y_test_predict_select = y_test_predict[onp.asarray(selected_table)]\n",
    "    y_test_select = y_test[onp.asarray(selected_table)]\n",
    "    print(\"Robustness({:s}): {:.2f}\".format(attack_type, onp.mean(correct(y_test_predict_select, y_test_select))))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adv_x generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv(k):\n",
    "        #inverse with diag_reg\n",
    "        return onp.linalg.inv(k + diag_reg * onp.eye(k.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel_train_inv_m = inv(kernel_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss_adv_mse(x_train, x_test, y_train, y, kernel_fn, ntk_train_train, t=None, diag_reg=diag_reg):\n",
    "    \n",
    "    ntk_test_train = kernel_fn(x_test[None], x_train, 'ntk')\n",
    "\n",
    "    predict_fn = nt.predict.gradient_descent_mse(ntk_train_train, y_train, diag_reg=diag_reg)\n",
    "    # predict_fn(t, train_0, test_0, kernel_matrix)\n",
    "    pred = predict_fn(t, 0., 0., ntk_test_train)[1]\n",
    "\n",
    "    # loss = -mse_loss(pred, y)\n",
    "    loss = -np.sum(logsoftmax(pred) * y)\n",
    "    return loss\n",
    "    \n",
    "test_mse_grads_fn = jit(vmap(grad(test_loss_adv_mse, argnums=1), in_axes=(None, 0, None, 0, None, None, None), \n",
    "                             out_axes=0), static_argnums=(4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adv_x(kernel_fn, x_train, x_test, y_test, t=None, train_batch=256):\n",
    "    \n",
    "    \n",
    "    # for building matrix\n",
    "    kernel_fn = jit(kernel_fn, static_argnums=(2,))\n",
    "    \n",
    "    def inv(k):\n",
    "        #inverse with diag_reg\n",
    "        return onp.linalg.inv(k + diag_reg * onp.eye(k.shape[0]))\n",
    "    \n",
    "    num_iter = x_train.shape[0] // train_batch\n",
    "    \n",
    "    grads = 0\n",
    "    # print('generating FGSM data...')\n",
    "    for idx in range(num_iter):\n",
    "        \n",
    "        x_train_batch = x_train[idx*train_batch: (idx+1)*train_batch]\n",
    "        y_train_batch = y_train[idx*train_batch: (idx+1)*train_batch]\n",
    "        \n",
    "        ntk_train_train     = kernel_fn(x_train_batch, None, 'ntk')\n",
    "        # ntk_train_train_inv = inv(ntk_train_train)\n",
    "    \n",
    "        # FGSM\n",
    "        grads += fast_gradient_method_batch(model_fn=model_fn, kernel_fn=kernel_fn, obj_fn='untargeted', \n",
    "                                           grads_fn=test_mse_grads_fn, x_train=x_train_batch, y_train=y_train_batch, \n",
    "                                           x_test=x_test, y=y_test, t=t, eps=eps, clip_min=0, clip_max=1, ntk_train_train=ntk_train_train)\n",
    "    \n",
    "    perturbation = eps * np.sign(grads)\n",
    "    adv_x_FGSM = x_test + perturbation\n",
    "    adv_x_FGSM = np.clip(adv_x_FGSM, a_min=0, a_max=1)\n",
    "\n",
    "    return adv_x_FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time opt: 131072\n",
    "time = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/512 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating time: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [10:29<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "adv_x_FGSM, adv_x_IFGSM_100 = {}, {}\n",
    "for t in time:\n",
    "    adv_x_FGSM[t] = []\n",
    "    adv_x_IFGSM_100[t] = []\n",
    "    print(\"generating time:\", t)\n",
    "    \n",
    "    for batch_id in tqdm(range(test_size//test_batch_size)):\n",
    "        fgsm = gen_adv_x(kernel_fn,\n",
    "                         x_train,\n",
    "                         x_test[batch_id*test_batch_size:(batch_id+1)*test_batch_size], \n",
    "                         y_test[batch_id*test_batch_size:(batch_id+1)*test_batch_size],\n",
    "                         t, 512)\n",
    "        \n",
    "        adv_x_FGSM[t].append(fgsm)\n",
    "        # adv_x_IFGSM_100[t].append(ifgsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "onp.save('./batch_NTK_simple_mnist.npy', onp.concatenate(adv_x_FGSM[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = onp.concatenate(adv_x_FGSM[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_samples(arr, attack_type, layer):\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(6, 3), sharex=True)\n",
    "    for row, ax in enumerate(axs):\n",
    "        for idx, a in enumerate(ax):\n",
    "            img = arr[idx + row*4].reshape(image_shape[:2])\n",
    "            a.axis('off')\n",
    "            a.xaxis.set_visible(False)\n",
    "            a.yaxis.set_visible(False)\n",
    "            a.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(arr, attack_type, layer):\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(6, 3), sharex=True)\n",
    "    for row, ax in enumerate(axs):\n",
    "        for idx, a in enumerate(ax):\n",
    "            img = arr[idx + row*4].reshape(image_shape)\n",
    "            a.axis('off')\n",
    "            a.xaxis.set_visible(False)\n",
    "            a.yaxis.set_visible(False)\n",
    "            a.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./fig-%s-untargeted/%s_layer_%d.png\"%(DATASET ,attack_type, layer+1), dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_samples(x_test, 'clean', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_samples(tmp, 'clean', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
